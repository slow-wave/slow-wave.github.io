[{"content":"5-1. 사용자 레벨 관리 기능 추가 정해진 조건에 따라 사용자의 레벨을 변경하는 기능 추가 5.1.1 필드 추가 Level 이늄 사용자 레벨을 이늄(enum)으로 정의\npublic enum Level { Basic(1), SILVER(2), GOLD(3); private final int value; Level(int value) { this.value=value; } public int intValue() { return value; } public static Level valueOf(int value) { switch(value) { case 1: return BASIC; case 2: return SILVER; case 3: return GOLD; default: throw new AssertionError(\u0026#34;Unknown value: \u0026#34;+ value\u0026#34;); } } } User 필드 추가 public class User { ... Level level; int login; int recommend; public Level getLevel() { return level; } public void setLevel(Level level) { this.level=level; } } UserDaoTest 테스트 수정\nUserDaoJdbc 수정\n빠르게 실행 가능한 포괄적인 테스트를 만드는 것이 중요하다. 5.1.2 사용자 수정 기능 추가 사용자 관리 비즈니스 로직에 따르면 사용자 정보는 여러번 수정 될 수 있음. 수정 기능 테스트 추가 수정할 정보가 담긴 User 오브젝트를 전달하면 id를 참고해서 사용자를 찾아 필드 정보 UPDATE해주는 메소드 추가 UserDao와 UserDaoJdbc 수정 update() 메소드 추가 public interface UserDao { ... public void update(User user1); } 사용자 정보 수정용 update() 메소드 public void update(User user) { this.jdbcTemplate.update( \u0026#34;update users set name=?, password=?, level=?, login=?,\u0026#34; + \u0026#34;recommend=? where id=?\u0026#34;, user.getName(), user.getPassword()), user.getLevel().intValue, user.getLogin(), user.getRecommend(), user.getId()); } 수정 테스트 보완 위의 update() 메소드의 문제점 UPDATE 문에서 WHERE 절을 빼먹는 경우는 검증하지 못함. 해결법 첫번째 방법) JdbcTemplate의 update()가 돌려주는 리턴 값(영향 주는 로우 개수)이 1인지 확인. 두번째 방법) 테스트를 보강해서 원하는 사용자 외의 정보는 변경되지 않았음을 확인. 사용자를 2명 등록해서 하나만 수정한 뒤에 두사람의 정보를 확인해본다. 5.1.3 UserService.upgradeLevels() 사용자 관리 로직의 경우 UserDaoJdbc에 두는 것은 적합하지 않음. (DAO는 비즈니스 로직을 두는 곳이 아니다.) 사용자 관리 비즈니스 로직을 담을 클래스 추가. → UserService UserDao 인터페이스 타입으로 UserDao 빈을 DI 받아 사용한다. UserService는 UserDao의 구현 클래스가 바뀌어도 영향받지 않도록 해야함. UserService를 위한 테스트 클래스도 추가 → UserServiceTest UserService 클래스와 빈 등록 UserService클래스 만들고 사용할 UserDao 오브젝트를 저장해둘 인스턴스 변수 선언 스프링 설정파일에 userService 아이디로 빈 추가 \u0026lt;bean id=\u0026#34;userService\u0026#34; class=\u0026#34;springbook.user.service.UserService\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;userDao\u0026#34; ref=\u0026#34;userDao\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;userDao\u0026#34; class=\u0026#34;springbook.dao.UserDaoJdbc\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dataSource\u0026#34; ref=\u0026#34;dataSource\u0026#34; /\u0026gt; \u0026lt;/bean\u0026gt; UserServiceTest 테스트 클래스 테스트 대상인 UserService 빈을 제공받을 수 있도록 @Autowired가 붙은 인스턴스 변수로 선언. package springbook.user.service; ... @RunWith(SpringJUnit4ClassRunner.class) @ContextCongifuration(locations=\u0026#34;/test-applicationContext.xml\u0026#34;) public class UserServiceTest { @Autowired UserService userService; } 테스트 메소드 추가 upgradeLevels() 메소드 public void upgradeLevels() { List\u0026lt;User\u0026gt; users=userdao.getAll(); for(User user: users) { Boolean changes=null; //레벨 변화 확인 //BASIC 레벨 업그레이드 if(user.getLevel()==Level.BASIC\u0026amp;\u0026amp;user.getLogin()\u0026gt;=50) { user.setLevel(Level.SILVER); changed=true; } //SILVER 레벨 업그레이드 else if(user.getLevel()==Level.SILVER\u0026amp;\u0026amp;user.getRecommend()\u0026gt;=30) { user.setLevel(Level.GOLD); changes=true; } //GOLD 레벨 업그레이드 else if (user.getLevel()==Level.GOLD) {changed=false;} if (changed) {userDao.update(user);} //변경 있는 경우에만 update() 호출 } } upgradeLevels() 테스트 경계가 되는 값으로 설정해 테스트를 진행한다. 5.1.4 UserService.add() 처음 가입하는 사용자의 경우 BASIC 레벨로 설정하는 것 구현해야함. UserDaoJdbc의 add()메소드는 적합하지 않음. 비즈니스 적인 의미를 지닌 정보를 설정하는 책임을 지는 것은 적합하지 않음. 방법1) User클래스에서 level 필드를 Level.BASIC으로 초기화 처음 가입할 떄를 제외하면 무의미한 필드이기 때문에 문제가 있어 보임. 방법2) 사용자 관리에 대한 비즈니스 로직을 담고 있는 UserService에 넣기 UserServcie의 add()를 호출하면 레벨이 BASIC으로 설정 테스트 케이스 레벨이 미리 정해진 경우에는 레벨 초기화 불필요 레벨이 비어있는 경우에는 BASIC 레벨로 설정 5.1.5 코드 개선 코드에 중복된 부분은 없는가? 코드가 무엇을 하는 것인지 이해하기 불편하지 않은가? 앞으로 변경이 일어난다면 어떤 것이 있을 수 있고, 그 변화에 쉽게 대응할 수 있는가? upgradeLevels() 메소드 코드의 문제점 문제점 if/elseif/else 블록들이 읽기 불편함. 로직을 이해하기 쉽지 않음. 레벨 확인 → 각 레벨별로 조건 판단하는 조건식 넣는 로직으로 바꿔야함. upgradeLevels() 리팩토링 기본 작업 흐름만 남겨둔 upgradeLevels() public void upgradeLevels() { List\u0026lt;User\u0026gt; users = userDao.getAll(); for(User user: users) { if( canUpgradeLevel(user)) { upgradeLevel(user); } } } canUpgradeLevel() 메소드 private boolean canUpgradeLevel(User user) { Level currentLevel=user.getLevel(); switch(currentLevel) { case BASIC: return (user.getLogin() \u0026gt;= 50); case SILVER: return (user.getRecommend()\u0026gt;=30); case GOLD: return false; //현재 로직에서 다룰 수 없는 레벨이라면 예외 발생 시킴. default: throw new IllegalArgumentException(\u0026#34;Unknown Level:\u0026#34;+currentLevel); } } upgradeLevel() 메소드\nprivate void upgradeLevel(User user) { if (user.getLevel()==Level.BASIC) user.setLevel(Level.SILVER); else if (user.getLevel() == Level.SILVER) usre.setLevel(Level.GOLD); userDao.update(user); } 다음 단계가 무엇인가 하는 로직과 그때 사용자 object의 level 필드를 변경해준다는 로직이 함께 있고, 노골적으로 들어남. 예외상황 처리도 없음. 업그레이드 순서를 담고 있도록 수정한 Level\n레벨의 순서와 다음 단계 레벨이 무엇이 있는지는 Level에 정의 public enum Level { Basic(1, SILVER), SILVER(2, GOLD), GOLD(3, null); private final int value; private final Level next; Level(int value, Level next) { this.value=value; this.next=next; } ... public Level nextLevel() { return this.next; } ... } User의 레벨 업그레이드 작업용 메소드 public void upgradeLevel(User user) { Level nextlevel=this.level.nextLevel(); if(nextlvel == null) { throw new IllegalStateException(this.level+\u0026#34;은 업그레이드가 불가능합니다.\u0026#34;); } else { this.level=nextLevel; } } upgradeLevel() private void upgradeLevel(User user) { user.upgradeLevel(); userDao.update(user); } 오브젝트에게 데이터를 요구하지말고 작업을 요청하라는 것이 객체지향 프로그래밍의 가장 기본이 되는 원리이기도 하다. UserService는 User에게 ‘레벨 업그레이드 작업’ 요청하고, 또 User는 Level에게 ‘다음 레벨이 무엇인지 알려달라’고 요청하는 방식이 바람직하다. User 테스트 upgradeLevel() 테스트는 Level 이늄을 가져와서 User에 설정해두고 User의 upgraeLevel()을 실행해서 다음 레벨로 바뀌는지 확인 UserServiceTest 개선 업그레이드 조건 (로그인 횟수, 추천 횟수)숫자가 중복돼서 나타남. → 정수형 상수로 변경한다. 무슨 의도로 어떤 값을 넣었는지 이해하기 쉬워짐. 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_5/","summary":"5-1. 사용자 레벨 관리 기능 추가 정해진 조건에 따라 사용자의 레벨을 변경하는 기능 추가 5.1.1 필드 추가 Level 이늄 사용자 레벨을 이늄(enum)으로 정의\npublic enum Level { Basic(1), SILVER(2), GOLD(3); private final int value; Level(int value) { this.value=value; } public int intValue() { return value; } public static Level valueOf(int value) { switch(value) { case 1: return BASIC; case 2: return SILVER; case 3: return GOLD; default: throw new AssertionError(\u0026#34;Unknown value: \u0026#34;+ value\u0026#34;); } } } User 필드 추가 public class User { .","title":"[토비의 스프링 3.1] 5장 정리"},{"content":"4.1 사라진 SQLException 4.1.1 초난감 예외처리 예외 블랙홀 - catch 문에 아무것도 넣지 않는 경우 무의미하고 무책임한 throws 예외 처리시 핵심 원칙 모든 예외는 적절하게 복구되거나 작업을 중단시키고 개발자에게 통보되어야 함. 4.1.2 예외의 종류와 특징 체크 예외(checked exception) - 명시적인 처리가 필요한 예외를 사용하고 다루는 법 자바에서 throw를 통해서 발생시킬 수 있는 예외 Error - java.lang.Error 클래스의 서브클래스들 시스템 레벨에서 특별한 작업을 하는게 아니라면 애플리케이션에서는 신경 쓰지 않아도 됨. Exception과 체크 예외 체크 예외 - Exception 클래스의 서브클래스이면서 RuntimeException 클래스를 상속하지 않은 것. 언체크 예외(unchecked exception) - RuntimeException을 상속한 클래스들 일반적으로 예외라고 하면 체크 예외라고 생각해도 됨. 체크 예외가 발생할 수 있는 메소드를 사용할 경우 반드시 예외 처리 코드 작성해야함. RuntimeException과 언체크/런타임 예외 런타임 예외는 주로 프로그램의 오류가 있을 때 발생하도록 의도된 것임. 예) NullPointerException - 오브젝트를 할당하지 않은 레퍼런스 변수 사용 시도시 발생하는 에러 4.1.3 예외처리 방법 예외 복구 - 예외상황을 파악하고 문제를 해결해서 정상 상태로 돌려놓기 예외처리 회피 - 예외처리를 자신이 담당하지 않고 자신을 호출한 쪽으로 던지기 throws 문으로 선언하거나 catch 문으로 잡은 후 rethrow 예외 복구처럼 회피의 의도가 분명해야함. 예외 전환 - 예외를 그대로 넘기지 않고 적절한 예외로 전화해서 던지기 목적 예외 던지기가 예외 상황에 대한 적절한 의미를 부여해주지 못해서 의미를 분명하게 해줄 수 있는 예외로 바꿔줌. 중첩 예외로 만드는 것이 좋음. 예외를 처리하기 쉽게 포장 주로 예외 처리를 강제하는 체크 예외를 언체크 예외인 런타임 예외로 바꾸는 경우에 사용 복구 불가능한 예외라면 애플리케이션 코드에서는 런타임 예외로 포장해서 던지는 것이 나음. 4.1.4 예외처리 전략 런타임 예외의 보편화 - 항상 복구할 수 있는 예외가 아니라면 일단 언체크 예외로 만드는 경향이 있음. 낙관적인 예외처리 기법임. 복구할 수 있는 예외는 없음. 예외 발생해도 런타임 예외이므로 시스템 레벨에서 알아서 처리해줄 것이고, 꼭 필요한 경우는 런타임 예외라도 잡아서 복구하거나 대응해줄 수 있으니 문제될 것 없음. 애플리케이션 예외 시스템 또는 외부의 예외상황이 원인이 아니라 애플리케이션 자체의 로직에 의해 의도적으로 발생시키고, 반드시 catch해서 무엇인가 조취를 취하도록 요구함. 예) 사용자가 요청한 금액을 은행계좌에서 출금하는 기능을 가진 메소드를 설계하는 법 첫번째 방법) 정상적인 출금처리 했을 경우, 잔고 부족이 발생했을 경우에 각각 다른 종류의 리턴 값 돌려줌. 두번째 방법) 정상적인 흐름 코드는 그대로 두고, 잔고 부족과 같은 예외 상황에서는 비즈니스적인 의미를 띤 예외 던지기 4.1.5 SQLException은 어떻게 됐나? JdbcTemplate과 콜백안에서 발생하는 모든 SQLException을 런타임 예외인 DataAccessException으로 포장해서 던져줌. 스프링의 API 메소드에 정의되어 있는 대부분의 예외는 런타임 예외임. 따라서 발생 가능한 예외가 있더라도 처리하도록 강제하지 않음. 4.2 예외 전환 JdbcTemplate이 던지는 DataAccessException은 일단 런타임 예외로 SQLException을 포장해주는 역할을 함.\n→ 복구 불가능한 예외인 SQLException에 대해 애플리케이션 레벨에서 신경쓰지 않도록 해줌.\n4.2.1 JDBC의 한계 비표준 SQL - 대부분의 DB는 표준을 따르지 않는 비표준 문법과 기능도 제공함. DAO를 DB별로 만들어 사용하거나 SQL을 독립시켜서 바꿔 쓸 수 있게하는 식으로 해결 가능 호환성 없는 SQLException의 DB 에러 정보 DB마다 에러의 종류와 원인이 제각각임. 4.2.2 DB 에러 코드 매핑을 통한 전환 스프링은 DB별 에러 코드를 분류해서 스프링이 정의한 예외 클래스와 매핑해놓은 에러 코드 매핑정보 테이블을 만들어두고 이용함. 4.2.3 DAO 인터페이스와 DataAccessException 계층구조 DataAccessException은 데이터 엑세스 기술에서 발생하는 예외에도 적용됨. DAO의 사용 기술과 구현 코드는 전략 패턴과 DI를 통해 DAO를 사용하는 클라이언트에게 감출 수 있지만, 메소드 선언에 나타나는 예외정보가 문제가 될 수 있음. 데이터 액세스 기술이 달라지면 같은 상황에서도 다른 종류의 예외가 던져짐. → DAO의 사용기술에 따라 예외 처리 방법 달라짐. 데이터 액세스 예외 추상화와 DataAccessException 계층구조 스프링은 자바의 다양한 데이터 액세스 기술을 사용할 떄 발생하는 예외들을 추상화해서 DataAcessException 계층구조에 정리함. 4.2.4 기술에 독립적인 UserDao 만들기 DataAccessException 활용 시 주의사항 DataAccessException이 기술에 상관없이 추상화된 공통 예외로 변환해주지만 완벽하진 않음. 학습 테스트를 만들어서 실제로 전환되는 예외의 종류 확인해야함. 스프링에서의 방법 - DB 에러 코드 사용 SQLException을 코드에서 직접 전환하고 싶다면 SQLExceptionTranslator 인터페이스를 구현한 클래스 중에서 SQLErrorCodeExceptionTranslator 사용하면 됨. 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_4/","summary":"4.1 사라진 SQLException 4.1.1 초난감 예외처리 예외 블랙홀 - catch 문에 아무것도 넣지 않는 경우 무의미하고 무책임한 throws 예외 처리시 핵심 원칙 모든 예외는 적절하게 복구되거나 작업을 중단시키고 개발자에게 통보되어야 함. 4.1.2 예외의 종류와 특징 체크 예외(checked exception) - 명시적인 처리가 필요한 예외를 사용하고 다루는 법 자바에서 throw를 통해서 발생시킬 수 있는 예외 Error - java.lang.Error 클래스의 서브클래스들 시스템 레벨에서 특별한 작업을 하는게 아니라면 애플리케이션에서는 신경 쓰지 않아도 됨. Exception과 체크 예외 체크 예외 - Exception 클래스의 서브클래스이면서 RuntimeException 클래스를 상속하지 않은 것.","title":"[토비의 스프링 3.1] 4장 정리"},{"content":"Intro 개방 폐쇄 원칙(OCP) : 변화의 특성이 다른 부분을 구분해주고, 각각 다른 목적과 다른 이유에 의해 다른 시점에 독립적으로 변경될 수 있는 효율적인 구조를 만들어주는 것 템플릿 : 일정한 패턴으로 유지되는 특성을 가진 부분을 자유롭게 변경되는 성질을 가진 부분으로부터 독립시켜서 효과적으로 활용할 수 있도록하는 방법 3.1 다시 보는 초난감 DAO 3.1.1 예외처리 기능을 갖춘 DAO DB 커넥션이라는 제한적인 리소스를 공유해 사용하는 서버에서 동작하는 JDBC 코드에는 반드시 지켜야 할 원칙이 있음. → 예외처리 (예외가 발생할 경우 리소스를 반환하도록 만들어야함.) 일반적으로 서버에서는 제한된 개수의 DB 커넥션을 만들어서 재사용 가능한 풀로 관리함. getConnection()으로 가져간 커넥션을 close()해서 돌려줘야지만 다시 풀에 넣었다가 다음 커넥션 요청이 있을 때 재사용할 수 있음. Connection, PreparedStatement close() 메소드 - 만들어진 걸 종료하는 것이라고 볼 수 있지만 보통 리소스를 반환한다는 의미로 이해하는 것이 좋음. 풀 방식으로 운영됨. (미리 정해진 풀 안에 제한된 수의 리소스를 만들어두고 필요할 때 할당, 반환하면 다시 풀에 넣는 방식임.) 요청이 매우 서버 환경에서는 풀 방식 선호. JDBC 코드에서는 리소스를 반환하도록 try/catch/finally 구문 사용을 권장함. 3.2 변하는 것과 변하지 않는 것 3.2.1 JDBC try/catch/finally 코드의 문제점 코드가 복잡하고 중첩되어 있음. → 변하지 않는, 그러나 많은 곳에서 중복되는 코드와 로직에 따라 자꾸 확장되고 자주 변하는 코드를 분리\n3.2.2 분리와 재사용을 위한 디자인 패턴 적용 템플릿 메소드 패턴의 적용\n상속을 통해 기능 확장해서 사용. 변하지 않는 부분은 슈퍼클래스에 두고 변하는 부분은 추상 메소드로 정의해둬서 서브클래스에서 오버라이드하여 새롭게 정의해 쓰도록 하는 것임. 문제점 DAO 로직마다 상속 통해 새로운 클래스 만들어야함. 확장구조가 클래스를 설계하는 시점에서 고정되어 버림. 전략 패턴의 적용\n개방폐쇄원칙(OCP)을 잘 지키는 구조이면서도 템플릿 메소드 패턴보다 유연하고 확장성이 뛰어난 것이, 오브젝트를 둘로 분리하고 클래스 레벨에서는 인터페이스를 통해서만 의존하도록 만드는 전략 패턴임. DI 적용을 위한 클라이언트/컨텍스트 분리\n전략 패턴에 따르면 Context가 어떤 전략을 사용하게 할 것인가는 Context를 사용하는 앞단의 Client가 결정하는게 일반적임. DI란 전략 패턴의 장점을 일반적으로 활용할 수 있도록 만든 구조임. 마이크로 DI DI의 가장 중요한 개념은 제3자의 도움을 통해 두 오브젝트 사이의 유연한 관계가 설정되도록 만든다는 것임. DI의 장점을 단순화해서 IoC 컨테이너의 도움 없이 코드 내에서 적용한 경우를 마이크로 DI라고 함. 3.3 JDBC 전략 패턴의 최적화 문제 상황\nDAO 메소드마다 새로운 StatementStrategy 구현 클래스를 만들어야 함. → 클래스 파일의 수 증가 DAO 메소드에서 StatementStrategy에 전달할 User와 같은 부가적인 정보가 있는 경우, 이를 위해 오브젝트를 전달받는 생성자와 이를 저장해둘 인스턴스 변수를 번거롭게 만들어야 함. 3.3.2 전략과 클라이언트의 동거 로컬 클래스\n해결법 - StatementStrategy 전략 클래스를 매번 독립된 파일로 만들지 말고 UserDao 클래스 안에 내부 클래스로 정의하기. 중첩 클래스(nested class)의 종류 스태틱 클래스 - 독립적으로 오브젝트로 만들어질 수 있음. 내부 클래스 - 자신이 정의된 클래스의 오브젝트 안에서만 만들어질 수 있음. 범위에 따라 구분 멤버 내부 클래스 - 멤버 필드처럼 오브젝트 레벨에 정의 로컬 클래스 - 메소드 레벨에 정의 익명 내부 클래스 - 이름을 갖지 않는 클래스. 클래스를 재사용할 필요가 없고, 구현한 인터페이스 타입으로만 사용할 경우에 유용함. 3.4 컨텍스트와 DI 3.4.2 JDBCContext의 특별한 DI 스프링 빈으로 DI\n인터페이스를 사용하지 않고 DI를 적용하는 것은 문제가 있지 않을까? 스프링 DI의 기본 의도에 맞게 JdbcContext의 메소드를 인터페이스를 뽑아내어 정의해두고, 이를 UserDao에서 사용해야 하지 않을까? 꼭 인터페이스 사용안해도 됨. 스프링의 DI는 객체의 생성과 관계설정에 대한 제어권한을 오브젝트에서 제거하고 외부로 위임했다는 IoC 개념을 포괄함. → JdbcContext를 스프링을 이용해 UserDao 객체에서 사용하게 주입했다는 건 DI 따른 것임. JdbcContext를 UserDao와 DI 구조로 만들어야 할 이유 JdbcContext가 스프링 컨테이너의 싱글톤 레지스트리에서 관리되는 싱글톤빈이 되기 때문임. JdbcContext가 DI를 통해 다른 빈에 의존하고 있음. DI를 위해서는 주입되는 오브젝트와 주입받는 오브젝트 양쪽 모두 스프링 빈으로 등록돼야 함. 클래스를 바로 사용하는 코드 구성을 DI에 적용하는 것은 가장 마지막 단계에서 고려해볼 사항임. 장점 - 오브젝트 사이의 실제 의존관계가 설정파일에 명확하게 드러남. 단점 - DI의 근본적인 원칙에 부합하지 않은 구체적인 클래스와의 관계가 설정에 직접 노출됨. 코드를 이용하는 수동 DI\n장점 - JdbcContext가 UserDao의 내부에서 만들어지고 사용되면서 관계를 외부에는 드러내지 않아도 됨. 단점 - JdbcContext를 여러 오브젝트가 사용하더라도 싱글톤으로 만들 수 없고, DI 작업을 위한 부가적인 코드가 필요함. 3.5 템플릿과 콜백 템플릿/콜백 패턴 템플릿 - 전략 패턴의 컨텍스트 템플릿 메소드 패턴은 고정된 틀의 로직을 가진 템플릿 메소드를 슈퍼클래스에 두고, 바뀌는 부분을 서브클래스의 메소드에 두는 구조로 이루어짐. 콜백 - 익명 내부 클래스로 만들어지는 오브젝트 실행되는 것을 목적으로 다른 오브젝트의 메소드에 전달되는 오브젝트를 말함. 파라미터로 전달되지만 값을 참조하기 위한 것이 아니라 특정 로직을 담은 메소드를 실행시키기 위해 사용함. 3.5.1 템플릿/콜백의 동작원리 템플릿/콜백의 특징\n템플릿/콜백의 작업 흐름 [1] 클라이언트는 템플릿 안에서 실행될 로직을 담은 콜백 오브젝트 생성. (콜백은 클라이언트가 템플릿의 메소드를 호출할 때 파라미터로 전달함.) [2] 클라이언트는 콜백 전달 및 template 호출 [3] 템플릿 workflow 시작 [4] 템플릿은 참조 정보 생성 [5] 템플릿은 콜백 오브젝트의 메소드를 호출함. [6] 콜백은 client final 변수를 참조 [7] 콜백은 참조정보를 이용해 작업 수행 [8] 콜백은 콜백 작업 결과를 템플릿에 돌려줌. [9] 템플릿은 콜백이 돌려준 정보를 사용해 작업 마저 수행 [10] 템플릿은 경우에 따라 최종결과를 클라이언트에 돌려줌. 템플릿/콜백 방식의 특징 콜백은 단일 메소드 인터페이스를 사용함. 콜백 인터페이스의 메소드에는 보통 파라미터가 있음. 파라미터는 템플릿의 작업 흐름 중에 만들어지는 컨텍스트 정보를 전달받을 때 사용됨 템플릿/콜백 방식에서는 매번 메소드 단위로 사용할 오브젝트를 새롭게 전달받음. 일반 DI라면 템플릿에 인스턴스 변수를 만들어두고 사용할 의존 오브젝트를 수정자 메소드로 받아서 사용함. 콜백 오브젝트가 내부 클래스로서 자신을 생성한 클라이언트 메소드 내의 정보를 직접 참조. 클라이언트와 콜백이 강하게 결합됨. 템플릿/콜백 방식은 전략 패턴과 DI의 장점을 익명 내부 클래스 사용 전략과 결합한 독특한 활용법임. 3.5.3 템플릿/콜백의 응용 스프링의 기본이 되는 전략 패턴과 DI는 물론이고 템플릿/콜백 패턴도 익숙해지도록 학습할 필요가 있다. 고정된 작업 흐름을 갖고 있으면서 반복되는 코드가 있다면, 중복되는 코드를 분리할 방법을 생각해보는 습관을 기르자. 가장 전형적인 템플릿/콜백 패턴의 후보는 try/catch/finally 블록을 사용하는 코드임. 중복의 제거와 템플릿/콜백 설계\n템플릿에 담을 작업 흐름은 어떤 것인지 살펴보기. 템플릿이 콜백에게 전달해줄 내부의 정보는 무엇인가? 콜백이 템플릿에게 돌려줄 내용은 무엇인가? 템플릿과 콜백의 경계를 정하고 템플릿이 콜백에게, 콜백이 템플릿에게 각각 전달하는 내용이 무엇인지 파악하는 게 가장 중요함. 이에 따라 콜백의 인터페이스를 정의해야하기 때문임. 제네릭스를 이용한 콜백 인터페이스\n파일을 라인 단위로 처리해서 만드는 결과의 타입을 다양하게 가져가고 싶다면, 자바 언어에 타입 파라미터라는 개념을 도입한 제네릭스를 이용하면 됨. 3.6 스프링의 JdbcTemplate public class UserDao { public void setDataSource(DataSource dataSource) { this.jdbcTemplate = new JdbcTemplate(dataSource); } private JdbcTemplate jdbcTemplate; private RowMapper\u0026lt;User\u0026gt; userMapper = new RowMapper\u0026lt;User\u0026gt;() { public User mapRow(ResultSet rs, int rowNum) throws SQLException { User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); return user; } }; public void add(final User user) { this.jdbcTemplate.update(\u0026#34;insert into users(id, name, password)values(?,?,?)\u0026#34;, user.getId(), user.getName(), user.getPassword()); } public User get(String id) { return this.jdbcTemplate.queryForObject(\u0026#34;select * from users where id = ?\u0026#34;, new Object[] {id}, this.userMapper); } public void deleteAll() { this.jdbcTemplate.update(\u0026#34;delete from users\u0026#34;); } public int getCount() { return this.jdbcTemplate.queryForInt(\u0026#34;select count(*) from users\u0026#34;); } public List\u0026lt;User\u0026gt; getAll() { return this.jdbcTemplate.query(\u0026#34;select * from users order by id\u0026#34;, this.userMapper); } } 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_3/","summary":"Intro 개방 폐쇄 원칙(OCP) : 변화의 특성이 다른 부분을 구분해주고, 각각 다른 목적과 다른 이유에 의해 다른 시점에 독립적으로 변경될 수 있는 효율적인 구조를 만들어주는 것 템플릿 : 일정한 패턴으로 유지되는 특성을 가진 부분을 자유롭게 변경되는 성질을 가진 부분으로부터 독립시켜서 효과적으로 활용할 수 있도록하는 방법 3.1 다시 보는 초난감 DAO 3.1.1 예외처리 기능을 갖춘 DAO DB 커넥션이라는 제한적인 리소스를 공유해 사용하는 서버에서 동작하는 JDBC 코드에는 반드시 지켜야 할 원칙이 있음. → 예외처리 (예외가 발생할 경우 리소스를 반환하도록 만들어야함.","title":"[토비의 스프링 3.1] 3장 정리"},{"content":"Intro 스프링의 핵심 = 객체지향 \u0026amp; 테스트 테스트 = 의도했던 대로 코드가 동작하는지를 확인해서, 만든 코드를 확신할 수 있게 해주는 작업임. 2.1 UserDaoTest 다시 보기 2.1.2 UserDaoTest의 특징 작은 단위의 테스트\n테스트하고자 하는 대상이 명확하면 대상에만 집중해서 테스트하는 것이 바람직함. → 테스트는 작은 단위로 쪼개서 집중 (관심사의 분리)\n→ 단위 테스트(unit test)\n자동수행 테스트 코드\n테스트는 자동으로 수행되도록 코드로 만들어지는 것이 중요함. (자주 반복할 수 있다는 장점이 있음.) 2.1.3 UserDaoTest의 문제점 수동 확인 작업의 번거로움 테스트의 수행은 코드에의해 자동으로 진행되지만 확인하는 일은 사람의 책임. 실행 작업의 번거로움 main() 메소드 이용하는 것보다 편리하고 체계적인 방법 필요함. 2.2 UserDaoTest 개선 2.2.1 테스트 검증의 자동화 테스트 실패 테스트 에러 : 에러가 발생해서 실패 테스트 실패 : 에러가 발생하진 않지만 기대한 답이 아님 빠르게 실행 가능하고 스스로 테스트 수행과 기대하는 결과에 대한 확인까지 해주는 코드로된 자동화된 테스트 만들어두는 것이 좋음. 2.2.2 테스트의 효율적인 수행과 결과 관리 실용적인 테스트를 위한 도구 - JUnit 프레임워크 JUnit 프레임워크 요구 조건 메소드가 public으로 선언되어야 함. 메소드에 @Test 추가 2.3 개발자를 위한 테스팅 프레임워크 JUnit 스프링 학습을 위해서는 최소한의 JUnit 테스트 작성 \u0026amp; 실행 방법 알아야 함. 2.3.1 JUnit 테스트 실행 방법 IDE\n@Test가 들어있는 테스트 클래스 선택 → eclipse run 메뉴의 JUnit Test 선택 2.3.3 포괄적인 테스트 JUnit은 하나의 클래스 안에 여러 개의 테스트 메소드가 들어가는 것을 허용함. @Test 붙어있고 public 접근자가 있으며 리턴 값이 void형이고 파라미터가 없다는 조건 지키면 됨. JUnit은 특정한 테스트 메소드의 실행 순서를 보장하지 않음. (테스트 결과가 실행 순서에 영향을 받는다면 테스트를 잘못 만든 것임.) 테스트를 작성할 때 부정적인 케이스를 먼저 만드는 것이 좋음. 2.3.4 테스트가 이끄는 개발 기능설계를 위한 테스트\n기능설계, 구현, 테스트라는 일반적인 개발 흐름의 기능설계에 해당하는 부분을 이 테스트 코드가 일부분 담당하고 있다고 볼 수 있음. 테스트 주도 개발(TDD, Test Driven Development)\n만들고자 하는 기능의 내용을 담고 있으면서 만들어진 코드를 검증도 해줄 수 있도록 테스트 코드를 먼저 만들고, 테스트를 성공하게 해주는 코드를 작성하는 방식의 개발 방법 TDD의 기본 원칙 - 실패한 테스트를 성공시키기 위한 목적이 아닌 코드는 만들지 않는다 TDD에서는 테스즈 작성하고 코드를 만드는 작업의 주기를 짧게하는 것을 권장함 2.3.5 테스트 코드 개선 Junit의 테스트 수행 방식\n테스트 클래스에서 @Test가 붙은 public이고 void형이며 파라미터가 없는 테스트 메소드를 모두 찾음. 테스트 클래스의 오브젝트를 하나 만든다. @Before 메소드 있으면 실행 @Test 메소드 하나 호출하고 테스트 결과 저장 @After 메소드 있으면 실행 나머지 테스트 메소드에 대해 2~5번 반복 모든 테스트의 결과를 종합해서 돌려줌 각 테스트 메소드 실행시마다 테스트 클래스의 오브젝트를 새로 만든다.\n왜일까? JUnit 개발자는 각 테스트가 서로 영향을 주지 않고 독립적으로 실행됨을 보장해주기 위해서 매번 새로운 오브젝트를 만들게 함. 픽스처(fixture)\n테스트를 수행하는 데 필요한 정보나 오브젝트 2.4 스프링 테스트 적용 애플리케이션 생성 방식 빈이 많아지고 복잡해지면 애플리케이션 컨텍스트 생성에 적지 않은 시간이 걸릴 수 있음. 애플리케이션 컨텍스트가 초기화될 때 어떤 빈은 독자적으로 많은 리소스를 할당하거나 독립적인 스레드를 띄우기도 함. 애플리케이션 컨텍스트 처럼 생성에 많은 자원이 소모되는 경우 테스트 전체가 공유하는 오브젝트 생성함. JUnit은 @BeforeClass 스태틱 메소드를 지원함. 이 메소드에서 애플리케이션 컨텍스트를 만들어 스태틱 변수에 저장해두고 테스트 메소드에서 사용하게 할 수 있음. 스프링이 제공하는 애플리케이션 컨텍스트 테스트 지원 기능이 더 편리함. 2.4.1 테스트를 위한 애플리케이션 컨텍스트 관리 스프링은 JUnit을 이용하는 테스트 컨텍스트 프레임워크를 제공함. 스프링 테스트 컨텍스트 프레임워크 적용\n@Autowired @RunWith - 스프링의 테스트 컨텍스트 프레임워크의 Junit 확장기능 지정 @ContextConfiguration - 테스트 컨텍스트가 자동으로 만들어줄 애플리케이션 컨텍스트의 위치 지정 테스트 메소드의 컨텍스트 공유\nJUnit은 테스트 메소드 실행시마다 새로운 테스트 오브젝트 생성 → context 변수에 어떻게 애플리케이션 컨텍스트가 들어있을까?\n→ 스프링의 JUnit 확장기능은 테스트가 실행되기 전에 딱 한 번만 애플리케이션 컨텍스트를 만들어두고, 테스트 오브젝트가 만들어질 때마다 특별한 방법을 이용해 애플리케이션 컨텍스트 자신을 테스트 오브젝트의 특정 필드에 주입해주는 것임.\n→ 스프링이 애플리케이션 컨텍스트 개수에 상관없이 한 번만 만들어서 공유해줬기 때문에 테스트 수행 속도 빨라짐.\n테스트 클래스의 컨텍스트 공유\n스프링은 테스트 클래스 사이에서도 애플리케이션 컨텍스트를 공유하게 해준다. @Autowired가 붙은 인스턴스 변수가 있으면, 테스트 컨텍스트 프레임워크는 변수 타입과 일치하는 컨텍스트 내의 빈을 찾음. 타입이 일치하는 빈이 있으면 인스턴스 변수에 주입. 별도의 DI 설정 없이 필드의 타입 정보를 이용해 빈을 자동으로 가져올 수 있음. → 타입에 의한 자동와이어링 변수에 할당 가능한 타입을 가진 빈을 자동으로 찾음. 테스트에서도 가능한 한 인터페이스를 사용해서 애플리케이션 코드와 느슨하게 연결해두는 편이 좋음. 2.4.2 DI와 테스트 인터페이스를 두고 DI를 적용해야 하는 이유 소프트웨어 개발에서 절대로 바뀌지 않는 것은 없다. 클래스의 구현 방식은 바뀌지 않는다고 하더라도 인터페이스를 두고 DI를 적용하게 해두면 다른 차원의 서비스 기능을 도입할 수 있음. 효율적인 테스트를 만들기 위해서임. 테스트 코드에 의한 DI\n@DirtiesContext - 스프링의 테스트 컨텍스트 프레임워크에게 해당 클래스의 테스트에서 애플리케이션 컨텍스트의 상태를 변경한다는 것을 알려줌. DI를 이용한 테스트 방법 선택\n항상 스프링 컨테이너 없이 테스트할 수 있는 방법을 최우선으로 여러 오브젝트와 복잡한 의존관계를 갖고 있는 오브젝트 테스트 → 스프링의 설정을 이용한 DI 방식의 테스트\n2.5 학습 테스트로 배우는 스프링 학습 테스트(learning test) 학습테스트의 목적은 자신이 사용할 API나 프레임워크의 기능을 테스트로 보면서 사용법 익히는 것. 2.5.1 학습 테스트의 장점 다양한 조건에 따른 기능을 손쉽게 확인 프레임워크나 제품을 업그레이드할 때 호환성 검증 도와줌. 테스트 작성에 대한 좋은 훈련 새로운 기술을 공부하는 과정이 즐거워짐 스프링 학습 테스트를 만들 때 참고할 수 있는 좋은 소스는 스프링 자신에 대한 테스트 코드임. 2.5.3 버그 테스트(bug test) 코드에 오류가 있을 때 그 오류를 가장 잘 드러내줄 수 있는 테스트 버그테스트는 실패하도록 만들어야 함. 테스트 방법 동등분할 - 같은 결과를 내는 값의 범위를 구분해서 각 대표값으로 테스트 경계값 분석 - 에러는 동등분할 범위의 경계에서 주로 발생. 경계의 근처에 있는 값을 이용해 테스트하는 방법임. 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_2/","summary":"Intro 스프링의 핵심 = 객체지향 \u0026amp; 테스트 테스트 = 의도했던 대로 코드가 동작하는지를 확인해서, 만든 코드를 확신할 수 있게 해주는 작업임. 2.1 UserDaoTest 다시 보기 2.1.2 UserDaoTest의 특징 작은 단위의 테스트\n테스트하고자 하는 대상이 명확하면 대상에만 집중해서 테스트하는 것이 바람직함. → 테스트는 작은 단위로 쪼개서 집중 (관심사의 분리)\n→ 단위 테스트(unit test)\n자동수행 테스트 코드\n테스트는 자동으로 수행되도록 코드로 만들어지는 것이 중요함. (자주 반복할 수 있다는 장점이 있음.) 2.1.3 UserDaoTest의 문제점 수동 확인 작업의 번거로움 테스트의 수행은 코드에의해 자동으로 진행되지만 확인하는 일은 사람의 책임.","title":"[토비의 스프링 3.1] 2장 정리"},{"content":" 문제(link) DP로 해결하는 문제입니다.\n풀이 방법 기본 조건 : 계단의 개수는 300이하의 자연수 arr = [0 for i in range(301)] dp = [0 for i in range(301)] 계단 오르기 규칙 1)1칸 or 2칸 오르기 가능 2)연속 3칸 밟기 불가능 3)마지막 칸 반드시 밟아야 함. → DP는 큰 문제를 작은 문제로 나누어 푸는 문제임.\n어떤 큰 문제가 있을 때 그것의 가장 작은 문제부터 생각해야함.\n→ 마지막 칸은 반드시 밟아야 하므로 다음과 같은 두 개의 경우의 수 존재함.\n| END-3 | END-2 | END-1 | END | - [case 1] (END-3) ➡️ (END-1) ➡️ (END) - [case 2] (END-2) ➡️ (END) → case1 or case2 중 max값 찾기.\ndp[i] = max(dp[i-3] + arr[i-1] + arr[i], dp[i-2] + arr[i]) Code (python) import sys n = int(sys.stdin.readline()) arr = [0 for i in range(301)] dp = [0 for i in range(301)] for i in range(n): arr[i] = int(sys.stdin.readline()) # 0~2까지 초기값 설정 dp[0] = arr[0] dp[1] = max(arr[0] + arr[1], arr[1]) dp[2] = max(arr[0] + arr[2], arr[1] + arr[2]) #각 step까지의 최댓값 구하기 for i in range(3, n): dp[i] = max(dp[i-3] + arr[i-1] + arr[i], dp[i-2] + arr[i]) #마지막 계단의 최댓값 출력 print(dp[n-1]) 출처 [blog] [백준] 2579번(python 파이썬) [blog] [백준] 2579번 계단오르기 파이썬 해설 ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_dp_1/","summary":"문제(link) DP로 해결하는 문제입니다.\n풀이 방법 기본 조건 : 계단의 개수는 300이하의 자연수 arr = [0 for i in range(301)] dp = [0 for i in range(301)] 계단 오르기 규칙 1)1칸 or 2칸 오르기 가능 2)연속 3칸 밟기 불가능 3)마지막 칸 반드시 밟아야 함. → DP는 큰 문제를 작은 문제로 나누어 푸는 문제임.\n어떤 큰 문제가 있을 때 그것의 가장 작은 문제부터 생각해야함.\n→ 마지막 칸은 반드시 밟아야 하므로 다음과 같은 두 개의 경우의 수 존재함.","title":"[백준] DP 1 - 2579번 계단 오르기"},{"content":"1.5 스프링의 IoC 스프링의 핵심 → 애플리케이션 컨텍스트(빈 팩토리) 1.5.1 오브젝트 팩토리를 이용한 스프링 IoC 어플리케이션 컨텍스트와 설정정보\n빈(bean) : 스프링이 제어권을 가지고 직접 만들고 관계를 부여하는 오브젝트 스프링 빈은 스프링 컨테이너가 생성과 관계설정, 사용 등을 제어해주는 제어의 역전이 적용된 오브젝트를 가리키는 말 빈 팩토리(bean factory) : 빈의 생성과 관계 설정과 같은 제어를 담당하는 IoC 오브젝트 애플리케이션 컨텍스트 : 별도의 정보를 참고해서 빈의 생성, 관계설정 등의 제어 작업 총괄. IoC엔진이라는 의미가 부각됨. 애플리케이션은 컨텍스트와 설정 정보를 따라 만들어지고 구성됨. DaoFactory를 사용하는 애플리케이션 컨텍스트\n@Configuration 애플리케이션 컨텍스트 또는 빈 팩토리가 사용할 설정정보 표시 @Bean 오브젝트 생성을 담당하는 IoC용 메소드 표시 1.5.2 애플리케이션 컨텍스트의 동작 방식 오브젝트 팩토리 - 스프링의 애플리케이션 컨텍스트 (=IoC 컨테이너, 빈 팩토리) 애플리케이션 컨텍스트는 애플리케이션에서 IoC를 적용해서 관리할 모든 오브젝트에 대한 생성과 관계설정을 담당한다. 애플리케이션 컨텍스트 사용시 장점 클라이언트는 구체적인 팩토리 클래스를 알 필요가 없음. 오브젝트 팩토리가 많아져도 이를 알아야 하거나 직접 사용할 필요가 없음. 애플리케이션 컨텍스트는 종합 IoC 서비스를 제공 오브젝트 생성과 다른 오브젝트와의 관계 설정 뿐만 아니라 다양한 기능 제공(오브젝트가 만들어지는 방식, 시점과 전략을 다르게 가져갈 수 있음.) 애플리케이션 컨텍스는 빈을 검색하는 다양한 방법 제공 1.5.3 스프링 IoC의 용어 정리 빈(bean) : 스프링이 IoC 방식으로 관리하는 오브젝트. 스프링에서 사용하는 애플리케이션에서 만들어지는 모든 오브젝트가 다 빈은 아님. 빈 팩토리(bean factory) : 스프링의 IoC를 담당하는 핵심 컨테이너를 가리킴. 빈 동륵, 생성, 조회, 돌려주기 등의 빈 관리 기능 담당 애플리케이션 컨텍스트(application context) : 빈 팩토리를 확장한 IoC 컨테이너. 빈 팩토리의 빈 관리하는 기본 기능 + 스프링이 제공하는 부가 서비스 빈 팩토리보다 애플리케이션 컨텍스트라는 이름을 더 많이 사용함. 설정정보/설정 메타 정보(configuration metadata) 애플리케이션 컨텍스트 또는 빈 팩토리가 IoC를 적용하기 위해 사용하는 메타정보 스프링의 설정정보는 컨테이너에 어떤 기능을 세팅하거나 조정하는 경우에도 사용하지만, 그보다는 IoC 컨테이너에 의해 관리되는 애플리케이션 오브젝트를 생성하고 구성할 때 사용 컨테이너(or IoC 컨테이너) IoC 방식으로 빈을 관리한다는 의미에서 애플리케이션 컨텍스트나 빈 팩토리를 컨테이너 또는 IoC 컨테이너라고 함. 컨테이너 → 애플리케이션 컨텍스트 / IoC 컨테이너 → 빈 팩토리 관점 스프링 프레임워크 : IoC 컨테이너, 애플리케이션 컨텍스트를 포함해서 스프링이 제공하는 모든 기능을 통틀어 말할 때 주로 사용한다. 1.6 싱글톤 레지스트리와 오브젝트 스코프 오브젝트의 동일성과 동등성 동일성(identify) - 두 개의 오브젝트가 완전히 같은 동일한 오브젝트 하나의 오브젝트만 존재. (두 개의 오브젝트 레퍼런스 변수) 동등성(equality) - 동일한 정보를 담고 있는 오브젝트 두 개의 각기 다른 오브젝트 스프링은 여러 번 빈을 요청해도 매번 동일한 오브젝트를 돌려줌. 1.6.1 싱글톤 레지스트리로서의 애플리케이션 컨텍스트 애플리케이션 컨텍스트는 싱글톤을 저장하고 관리하는 싱글톤 레지스트리(singleton registry)이기도 함. 서버 애플리케이션과 싱글톤\n스프링이 싱글톤으로 빈을 만드는 이유\n→ 주 적용 대상이 자바 엔터프라이즈 기술을 사용하는 서버환경 → 높은 성능 요구됨.\n→ 클라이언트에서 요청이 올 때마다 각 로직을 담당하는 오브젝트를 새로 만든다면?\n→ 부하가 걸리면 서버가 감당하기 어려움.\n엔터프라이즈 분야에서는 서비스 오브젝트 개념을 일찍부터 사용함.\n서블릿\n자바 엔터프라이즈 기술의 기본이 되는 서비스 오브젝트임. 대부분 멀티스레드 환경에서 싱글톤으로 동작함. 서블릿 클래스 하나당 하나의 오브젝트 생성, 사용자의 요청을 담당하는 여러 스레드에서 하나의 오브젝트를 공유해 동시 사용. 애플리케이션 안에 제한 된 수의 오브젝트만 만들어서 사용하는 것이 싱글톤 패턴의 원리임.\n싱글톤 패턴의 한계\nprivate 생성자를 갖고 있기 때문에 상속할 수 없음. 객체지향의 장점인 상속과 이를 이용한 다형성을 적용할 수 없음. 싱글톤은 테스트하기가 힘듦. 서버환경에서는 싱글톤이 하나만 만들어지는 것을 보장 못함. 싱글톤의 사용은 전역 상태를 만들 수 있기 때문에 바람직하지 못함. 싱글톤의 스태틱 메소드를 이용해 언제든지 싱글톤에 쉽게 접근할 수 있기 때문에 전역 상태로 사용되기 쉬움. → 전역 상태를 갖는 것은 객체지향 프로그래밍에서는 권장되지 않는 프로그래밍 모델임. 싱글톤 레지스트리\n싱글톤 레지스트리(singleton registry) → 싱글톤 패턴에는 여러 가지 단점이 있기 때문에, 스프링은 직접 싱글톤 형태의 오브젝트를 만들고 관리하는 기능을 제공함. 장점 스태틱 메소드와 private 생성자를 사용해야 하는 비정상적인 클래스가 아니라 평범한 자바 클래스를 싱글톤으로 활용하게 해줌. 스프링이 빈을 싱글톤으로 만드는 것은 오브젝트의 생성 방법을 제어하는 IoC 컨테이너로서의 역할임. 1.6.2 싱글톤과 오브젝트의 상태 싱글톤은 멀티스레드 환경이라면 여러 스레드가 동시에 접근해서 사용할 수 있음. → 상태 관리에 주의를 기울여야함.\n기본적으로 싱글톤이 멀티스레드 환경에서 서비스 형태의 오브젝트로 사용되는 경우에는 무상태(stateless)방식으로 만들어져야 함.\n→ 다중 사용자의 요청을 한꺼번에 처리하는 스레드들이 동시에 싱글톤 오브젝트의 인스턴스 변수를 수정하는 것은 위험함.\n1.6.3 스프링 빈의 스코프 스프링이 관리하는 오브젝트 → 빈의 스코프(scope) 스프링 빈의 기본 스코프 → 싱글톤 1.7 의존관계 주입(DI) 1.7.1 제어의 역전(IoC)과 의존관계 주입 객체지향적인 설계나, 디자인 패턴, 컨테이너에서 동작하는 서버 기술을 사용하면 자연스럽게 IoC를 적용하거나 그 원리로 동작하는 기술을 사용하게 됨. 스프링 IoC 기능의 대표적인 동작원리는 주로 의존관계 주입(dependency injection)이라고 불림. 스프링은 DI 컨테이너 라고 불림. 1.7.2 런타임 의존관계 설정 의존관계(Dependency Relationship)\n두 개의 클래스 또는 모듈이 의존관계에 있다고 말할 때는 항상 방향성을 부여해줘야 한다.\n의존관계란?\n\u0026lt;클래스의 의존관계 다이어그램\u0026gt;\nA가 B에 의존하고 있음. B가 변하면 A에 영향을 미침. 한쪽의 변화가 다른 쪽에 영향을 주는 것임. UserDao의 의존관계\n인터페이스에 대해서만 의존관계를 만들어두면 인터페이스 구현 클래스와의 관계는 느슨해지면서 변화에 영향을 덜 받는 상태가 됨. → 결합도가 낮아짐. 클래스와 인터페이스를 통해 드러나는 의존관계 말고, 런타임 의존관계도 있음. DI ? 오브젝트 생성 후 런타임 시에 의존관계를 맺는 대상(실제 사용대상) 오브젝트를 의존 오브젝트(dependent object)라고 함.\n의존관계 주입은 다음의 세 조건 충족하는 작업임.\n클래스 모델이나 코드는 런타임 시점의 의존관계가 드러나지 않는다. 그러기 위해서는 인터페이스에만 의존하고 있어야 한다. 런타임 시점의 의존관계는 컨테이너나 팩토리 같은 제 3의 존재가 결정한다. 의존관계는 사용할 오브젝트에 대한 레퍼런스를 외부에서 제공해줌으로써 만들어진다. 의존관계 주입의 핵심은 설계 시점에는 알지 못했던 두 오브젝트의 관계를 맺도록 도와주는 제3의 존재가 있다는 것임.\nDI에서 말하는 제3의 존재는 바로 관계설정 책임을 가진 코드를 분리해서 만들어진 오브젝트임.\n→ 애플리케이션 컨텍스트, 빈 팩토리, IoC 컨테이너 등이 모두 외부에서 오브젝트 사이의 런타임 관계를 맺어주는 책임을 지는 제3의 존재임.\n1.7.3 의존관계 검색과 주입 의존관계 검색(dependency lookup) 외부 컨테이너에게 IoC로 맡기지만, 이를 가져올 때는 메소드나 생성자를 통한 주입 대신 스스로 컨테이너에게 요청하는 방법을 사용한다. 의존관계 검색 방법은 코드 안에 오브젝트 팩토리 클래스나 스프링 API가 나타남. → 의존관계 주입 방식 코드가 더 깔끔함. DI와 DL은 적용 방법에 차이가 있음. 의존관계 검색 방식에서는 검색하는 오브젝트는 자신이 스프링의 빈일 필요가 없음. 의존관계 주입을 원하는 오브젝트는 먼저 자기 자신이 컨테이너가 관리하는 빈이 돼야함. 스프링의 IoC 컨테이너인 애플리케이션 컨텍스트는 getBean() 메소드를 제공함. → 의존 관계 검색에 사용됨. DI 받는다? 단순한 오브젝트 주입이 아니라 DI 개념을 따르는 주입임을 이해해야함. 1.7.4 의존관계 주입의 응용 DI의 장점은 관심사의 분리(SoC)를 통해 얻어지는 높은 응집도에서 나옴. 스프링을 공부하는 건 DI를 어떻게 활용해야 할지 공부하는 것임. 1.7.5 메소드를 이용한 의존관계 주입 의존관계 주입 시 반드시 생성자를 사용해야하는 것은 아님. DI 방법 수정자 메소드를 이용한 주입\n외부에서 오브젝트 내부의 애트리뷰트 값을 변경하려는 용도로 주로 사용됨. 메소드 이름 정하는 것이 중요함. 가능한 의미있고 단순한 이름 사용하자. (e.g interface - ConnectionMaker → method - setConnectionMaker())\n일반 메소드를 이용한 주입\n1.8 XML을 이용한 설정 다양한 방법을 통해 DI 의존관계 설정정보를 만들 수 있음. XML 1.9 정리 스프링의 관심은 오브젝트와 그 관계임. 오브젝트를 어떻게 설계, 분리, 개선하고 어떤 의존관계를 가질지 결정하는 일은 스프링이 아니라 개발자의 역할이며 책임임. 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_1/","summary":"1.5 스프링의 IoC 스프링의 핵심 → 애플리케이션 컨텍스트(빈 팩토리) 1.5.1 오브젝트 팩토리를 이용한 스프링 IoC 어플리케이션 컨텍스트와 설정정보\n빈(bean) : 스프링이 제어권을 가지고 직접 만들고 관계를 부여하는 오브젝트 스프링 빈은 스프링 컨테이너가 생성과 관계설정, 사용 등을 제어해주는 제어의 역전이 적용된 오브젝트를 가리키는 말 빈 팩토리(bean factory) : 빈의 생성과 관계 설정과 같은 제어를 담당하는 IoC 오브젝트 애플리케이션 컨텍스트 : 별도의 정보를 참고해서 빈의 생성, 관계설정 등의 제어 작업 총괄. IoC엔진이라는 의미가 부각됨.","title":"[토비의 스프링 3.1] 1.5~1.9 정리"},{"content":" 문제(link) 브루트포스 알고리즘으로 해결하는 문제입니다. 땅의 높이는 256블록을 초과할 수 없습니다. 층을 기준으로해서모든 경우의 수를 계산합니다. 층(target)과 같은 높이만큼 블록을 제거하거나 추가해서 (작업 최소 시간, 높이)를 구할 수 있습니다.\n풀이 방법 [1] 0~256층까지 반복 [1-1] graph 좌표에 저장되어 있는 블록이 층 수보다 크거나 같으면 → 블록 제거, 인벤토리에 추가 [1-2] graph 좌표에 저장되어 있는 블록이 층 수보다 작으면 → 블록 추가, 인벤토리에서 제거 [1-3] 인벤토리 블록의 범위 안에서 작업했다면 [1-3-1] 최소 시간이라면 Update (작업 최소시간, 높이)\nCode (python) import sys n, m, b = map(int, sys.stdin.readline().split()) graph = [list(map(int, sys.stdin.readline().split())) for _ in range(n)] answer = sys.maxsize idx = 0 # 0층부터 256층까지 반복 for target in range(257): plus, minus = 0, 0 for i in range(n): for j in range(m): # 블록이 층 수보다 크거나 같으면 -\u0026gt; 인벤토리에 추가 if graph[i][j] \u0026gt;= target: plus += graph[i][j] - target # 블록이 층 수보다 작으면 -\u0026gt; 인벤토리에서 제거 else: minus += target - graph[i][j] #인벤토리 블록 수 이상으로 제거하지 않았다면 if plus + b \u0026gt;= minus: # 최저 시간이면 if minus + (plus * 2) \u0026lt;= answer: answer = minus + (plus * 2) idx = target print(answer, idx) 참고자료 [blog] [baekjoon] 백준 18111번(파이썬): 마인크래프트 [blog] [Python 3] BOJ - 18111 \u0026ldquo;마인크래프트\u0026rdquo; ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_bruteforce_1/","summary":"문제(link) 브루트포스 알고리즘으로 해결하는 문제입니다. 땅의 높이는 256블록을 초과할 수 없습니다. 층을 기준으로해서모든 경우의 수를 계산합니다. 층(target)과 같은 높이만큼 블록을 제거하거나 추가해서 (작업 최소 시간, 높이)를 구할 수 있습니다.\n풀이 방법 [1] 0~256층까지 반복 [1-1] graph 좌표에 저장되어 있는 블록이 층 수보다 크거나 같으면 → 블록 제거, 인벤토리에 추가 [1-2] graph 좌표에 저장되어 있는 블록이 층 수보다 작으면 → 블록 추가, 인벤토리에서 제거 [1-3] 인벤토리 블록의 범위 안에서 작업했다면 [1-3-1] 최소 시간이라면 Update (작업 최소시간, 높이)","title":"[백준] Brute Force 1- 18111번 마인크래프트"},{"content":"스프링이란 무엇인가? 스프링은 자바 엔터프라이즈 애플리케이션 개발에 사용되는 애플리케이션 프레임워크다. 스프링을 사용한다는 것은 다음의 세 가지 요소를 적극적으로 활용해서 애플리케이션을 개발한다는 뜻이다. 스프링 개발 철학 중 하나는 ‘항상 프레임워크 기반의 접근 방법을 사용하라’이다. 프레임워크의 가장 중요한 목적은 개발자가 일정한 틀을 따라 효과적으로 애플리케이션을 개발하도록 돕는 것이다. 따라서 프레임워크를 잘 이해하려면 프레임워크를 사용했을 때 애플리케이션 코드가 어떻게 만들어지는지 자세히 살펴봐야 한다. 1) 애플리케이션의 기본 틀 - 스프링 컨테이너 스프링은 스프링 컨테이너라고 불리는 스프링 런타임 엔진을 제공한다. 2) 공통 프로그래밍 모델 - IoC/DI, 서비스 추상화, AOP 스프링은 세 가지 핵심 프로그래밍 모델을 지원한다.\nIoC/DI : 오브젝트의 생명주기와 의존관계에 대한 프로그래밍 모델이다. 서비스 추상화 : 구체적인 기술과 환경에 종속되지 않도록 유연한 추상 계층을 두는 방법이다. AOP : 애플리케이션 코드에 산재해서 나타나는 부가적인 기능을 독립적으로 모듈화하는 프로그래밍 모델이다. 3) 기술 API 스프링의 성공 요인 단순함 스프링은 이 잃어버린 객체지향 언어의 장점을 다시 개발자들이 살릴 수 있도록 도와주는 도구다. 스프링이 강력하게 주장하는 것은 가장 단순한 객체지향적인 개발 모델인 POJO 프로그래밍이다. 유연성 스프링은 다른 많은 프레임워크와 편리하게 접목돼서 사용할 수 있다. 1장 오브젝트와 의존관계 스프링이 자바에서 가장 중요하게 가치를 두는 것은 바로 객체지향 프로그래밍이 가능한 언어라는 점이다. 스프링이 관심을 두는 대상은 오브젝트다. 애플리케이션에서 오브젝트가 생성되고 다른 오브젝트와 관계를 맺고, 사용되고, 소멸하기까지의 전 과정을 진지하게 생각해볼 필요가 있다. 오브젝트에 대한 관심은 오브젝트의 설계로 발전하게 된다. 객체지향 설계의 기초와 원칙을 비롯해서, 디자인 패턴, 리팩토링, 단위테스트와 같은 오브젝트 설계와 구현에 관한 여러 가지 응용 기술과 지식이 요구된다. 1.2 DAO의 분리 1.2.1 관심사의 분리 개발자가 객체를 설계할 때 가장 염두에 둬야 할 사항은 바로 미래의 변화를 어떻게 대비할 것인가이다. 객체지향 설계와 프로그래밍 이전의 절차적 프로그래밍 패러다임에 비해 초기에 좀 더 많은, 번거로운 작업을 요구하는 이유는 객체지향 기술 자체가 지니는, 변화에 효과적으로 대처할 수 있다는 기술적인 특징 때문이다. 어떻게 변경이 일어날 때 필요한 작업을 최소화하고, 그 변경이 다른 곳에 문제를 일으키지 않게 할 수 있을까? 그것은 분리와 확장을 고려한 설계가 있었기 때문이다. 모든 변경과 발전은 한 번에 한 가지 관심사항에 집중해서 일어난다. 프로그래밍의 기초 개념 중에 관심사의 분리라는게 있다. → 관심이 같은 것끼리는 하나의 객체 안으로 또는 친한 객체로 모이게 하고, 관심이 다른 것은 가능한 한 따로 떨어져서 서로 영향을 주지 않도록 분리하는 것이다. 1.2.2 커넥션 만들기의 추출 변경사항에 대한 검증: 리팩토링과 테스트\n여러 메소드에 중복돼서 등장하는 특정 관심사항이 담긴 코드를 별도의 메소드로 분리해냈다. → 리팩토링 공통의 기능을 담당하는 메소드로 중복된 코드를 뽑아내는 것을 리팩토링에서는 메소드 추출 기법이라고 한다. 1.2.3 DB 커텍션 만들기의 독립 상속을 통한 확장\n템플릿 메소드 패턴 - 슈퍼클래스에 기본적인 로직의 흐름을 만들고, 그 기능의 일부를 추상 메소드나 필요에 맞게 구현해서 사용하도록 하는 방법이다. 팩토리 메소드 패턴 - 서브클래스에서 구체적인 오브젝트 생성 방법을 결정하게하는 것이다. 디자인 패턴은 설계 전략이기도 하지만 커뮤니케이션 수단이기도 하다. 1.3 DAO의 확장 1.3.4 원칙과 패턴 개방 폐쇄 원칙(OCP, Open-Closed Principle)\n개방 폐쇄 원칙은 깔끔한 설계를 위해 적용 가능한 객체지향 설계 원칙 중 하나다. 간단히 정의하면 ‘클래스나 모듈은 확장에는 열려 있어야 하고 변경에는 닫혀 있어야 한다.’라고 할 수 있다. 높은 응집도와 낮은 결합도\n개방 폐쇄 원칙은 높은 응집도와 낮은 결합도(high coherence and low coupling)라는 소프트웨어 개발의 고전적인 원리로도 설명이 가능하다. 높은 응집도 하나의 모듈, 클래스가 하나의 책임 또는 관심사에만 집중되어 있다. 변화가 일어날 때 해당 모듈에서 변하는 부분이 크다. 낮은 결합도 결합도란 ‘하나의 오브젝트가 변경이 일어날 때에 관계를 맺고 있는 다른 오브젝트에게 변화를 요구하는 정도’라고 할 수 있다. 책임과 관심사가 다른 오브젝트 또는 모듈과는 낮은 결합도, 즉 느슨하게 연결된 형태를 유지하는 것이 바람직하다. 결합도가 낮아지면 변화에 대응하는 속도가 높아지고, 구성이 깔끔해진다. 확장도 편리하다. 전략 패턴\n전략 패턴은 자신의 기능 맥락에서, 필요에 따라 변경이 필요한 알고리즘을 인터페이스를 통해 통째로 외부로 분리시키고, 이를 구현한 구체적인 알고리즘 클래스를 필요에 따라 바꿔서 사용할 수 있게 하는 디자인 패턴이다. 스프링이란 객체지향적 설계 원칙과 디자인 패턴에 나타난 장점을 자연스럽게 개발자들이 활용할 수 있게 해주는 프레임워크다. 1.4 제어의 역전(IoC) 1.4.3 제어권의 이전을 통한 제어관계 역전 제어의 역적이라는 건, 간단히 프로그램의 제어 흐름 구조가 뒤바뀌는 것이라고 설명할 수 있다. 일반적인 프로그램의 흐름 main() 메소드와 같이 프로그램이 시작되는 지점에서 다음에 사용할 오브젝트 결정 → 결정한 오브젝트 생성 → 만들어진 오브젝트에 있는 메소드 호출 → 오브젝트 메소드 안에서 다음에 사용할 것을 결정하고 호출하는 식의 작업 반복 모든 오브젝트가 능동적으로 자신이 사용할 클래스를 결정하고, 언제 어떻게 오브젝트를 만들지를 스스로 관장한다. 제어의 역전에서는 오브젝트가 자신이 사용할 오브젝트를 스스로 선택하지 않는다. 당연히 생성하지도 않는다. 모든 제어 권한을 자신이 아닌 다른 대상에게 위임한다. 프레임워크도 제어의 역전 개념이 적용된 대표적인 기술이다. 라이브러리 vs. 프레임워크 라이브러리 : 라이브러리를 사용하는 애플리케이션 코드는 애플리케이션 흐름을 제어한다. 프레임워크 : 거꾸로 애플리케이션 코드가 프레임워크에 의해 사용된다. 스프링은 IoC를 모든 기능의 기초가 되는 기반기술로 삼고 있으며, IoC를 극한까지 적용하고 있는 프레임워크다. Code 1-1. 사용자 정보 저장용 자바빈 User 클래스 package springbook1; public class User { String id; String name; String password; public String getId() { return id; } public void setId(String id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } public String getPassword() { return password; } public void setPassword(String password) { this.password = password; } } 1-2. JDBC를 이용한 등록과 조회 기능이 있는 UserDao 클래스 다음 코드의 문제점 add()와 get() method 부분에 DB connection 부분이 중복되어있음. 예외 처리 package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public class UserDao { public void add(User user) throws ClassNotFoundException, SQLException { Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); Connection c = DriverManager.getConnection( \u0026#34;jdbc:mysql://localhost/test\u0026#34;, \u0026#34;spring\u0026#34;, \u0026#34;book\u0026#34;); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); Connection c = DriverManager.getConnection( \u0026#34;jdbc:mysql://localhost/test\u0026#34;, \u0026#34;spring\u0026#34;, \u0026#34;book\u0026#34;); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } } 1-3. 테스트용 main() 메소드 package springbook1; import java.sql.SQLException; public class UserDaoTest { public static void main(String[] args) throws ClassNotFoundException, SQLException { // TODO Auto-generated method stub UserDao dao = new UserDao(); User user = new User(); user.setId(\u0026#34;ground\u0026#34;); user.setName(\u0026#34;\u0026#34;); user.setPassword(\u0026#34;hi2\u0026#34;); dao.add(user); System.out.println(user.getId() + \u0026#34;등록 성공\u0026#34;); User user2 = dao.get(user.getId()); System.out.println(user2.getName()); System.out.println(user2.getPassword()); System.out.println(user2.getId() + \u0026#34;조회 성공\u0026#34;); } } [리팩토링1] 중복 코드의 메소드 추출을 통해 코드 분리 1-4. getConnection() 메소드를 추출해서 중복을 제거한 UserDao package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public class UserDao { public void add(User user) throws ClassNotFoundException, SQLException { Connection c = getConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Connection c = getConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } private Connection getConnection() throws ClassNotFoundException, SQLException { Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); Connection c = DriverManager.getConnection( \u0026#34;jdbc:mysql://localhost/test\u0026#34;, \u0026#34;spring\u0026#34;, \u0026#34;book\u0026#34;); return c; } } [리팩토링2] 상속을 통한 확장 (템플릿 메소드 패턴 \u0026amp; 팩토리 메소드 패턴 적용) 클래스 계층구조를 통해 두 개의 관심이 독립적으로 분리되면서 변경 작업이 용이해짐. 1.5. 상속을 통한 확장 방법이 제공되는 UserDao 다음 코드의 문제점 만약 이미 UserDao가 다른 목적을 위해 상속을 사용하고 있다면? 자바는 클래스의 다중상속을 허용하지 않는다. 상속을 통한 상하위 클래스의 관계는 생각보다 밀접하다. 확장된 기능인 DB 커넥션을 생성하는 코드를 다른 DAO 클래스에 적용할 수 없다. package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public abstract class UserDao { public void add(User user) throws ClassNotFoundException, SQLException { Connection c = getConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Connection c = getConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } // getConnection() 메소드는 Connection 타입 오브젝트를 생성한다는 기능을 정의해놓은 추상 메소드 public abstract Connection getConnection() throws ClassNotFoundException, SQLException; public class NUserDao extends UserDao { // 서브클래스의 getConnection() 메소드는 어떤 Connection 클래스의 오브젝트를 어떻게 생성할 것인지 결정하는 방법 public Connection getConnection() throws ClassNotFoundException, SQLException { //N사 DB connection code return c; } } public class DUserDao extends UserDao { public Connection getConnection() throws ClassNotFoundException, SQLException { //D사 DB connection code return c; } } } [리팩토링3] 클래스의 분리 1.6 독립된 SimpleConnectionMaker를 사용하게 만든 UserDao 1.7 독립시킨 DB연결 기능인 SimpleConnectionMaker 다음 코드의 문제점 고객이 DB 커넥션을 가져오는 방법을 자유롭게 확장하기가 어려움. → UserDao가 SimpleConnectionMaker라는 특정 클래스와 그 코드에 종속적임. package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public abstract class UserDao { private SimpleConnectionMaker simpleConnectionMaker; public UserDao() { simpleConnectionMaker = new SimpleConnectionMaker(); } public void add(User user) throws ClassNotFoundException, SQLException { Connection c = simpleConnectionMaker.makeNewConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Connection c = simpleConnectionMaker.makeNewConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } public class SimpleConnectionMaker { public Connection makeNewConnection() throws ClassNotFoundException, SQLException { Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); Connection c = DriverManager.getConnection( \u0026#34;jdbc:mysql://localhost/test\u0026#34;, \u0026#34;spring\u0026#34;, \u0026#34;book\u0026#34;); return c; } } } [리팩토링4] 인터페이스 도입 1-8. ConnectionMaker 인터페이스 1-9. ConnectionMaker 구현 클래스 1-10. ConnectionMaker 인터페이스를 사용하도록 개선한 UserDao 다음 코드의 문제점 UserDao의 다른 모든 곳에서는 인터페이스를 이용하게 만들어서 DB 커넥션을 제공하는 클래스에 대한 구체적인 정보는 모두 제거가 가능했지만, 초기에 한 번 어떤 클래스의 오브젝트를 생성할지를 결정하는 생성자의 코드는 제거 되지 않음. package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public abstract class UserDao { private ConnectionMaker connectionMaker; public UserDao() { connectionMaker = new DConnectionMaker(); } public void add(User user) throws ClassNotFoundException, SQLException { Connection c = connectionMaker.makeConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Connection c = connectionMaker.makeConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } public interface ConnectionMaker { public Connection makeConnection() throws ClassNotFoundException,SQLException; } public class DConnectionMaker implements ConnectionMaker { public Connection makeConnection() throws ClassNotFoundException, SQLException { //D사 connection code return null; } } } [리팩토링5] 관계설정 책임의 분리 인터페이스를 도입하고 클라이언트의 도움을 얻는 방법은 상속을 사용해 비슷한 시도를 했을 경우에 비해서 유연하다. 1-11. 수정한 생성자 1-12. 관계 설정 책임이 추가된 UserDao 클라이언트인 main() 메소드 다음 코드의 문제점 UserDaoTest는 기존에 UserDao가 담당하던 기능, 즉 어떤 ConnectionMaker 구현 클래스를 사용할지를 결정하는 기능을 떠맡았다. → 이렇게 분리될 기능은 UserDao와 ConnectionMaker 구현 클래스의 오브젝트를 만드는 것과, 그렇게 만들어진 두 개의 오브젝트가 연결돼서 사용될 수 있도록 관계를 맺어주는 것이다. package springbook1; import java.sql.Connection; import java.sql.DriverManager; import java.sql.PreparedStatement; import java.sql.ResultSet; import java.sql.SQLException; public class UserDao { private ConnectionMaker connectionMaker; public UserDao(ConnectionMaker connectionMaker) { this.connectionMaker = connectionMaker; } public void add(User user) throws ClassNotFoundException, SQLException { Connection c = connectionMaker.makeConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;insert into users(id, name, password) values(?,?,?)\u0026#34;); ps.setString(1, user.getId()); ps.setString(2, user.getName()); ps.setString(3, user.getPassword()); ps.executeUpdate(); ps.close(); c.close(); } public User get(String id) throws ClassNotFoundException, SQLException { Connection c = connectionMaker.makeConnection(); PreparedStatement ps = c.prepareStatement( \u0026#34;select * from users where id = ?\u0026#34;); ps.setString(1,id); ResultSet rs = ps.executeQuery(); rs.next(); User user = new User(); user.setId(rs.getString(\u0026#34;id\u0026#34;)); user.setName(rs.getString(\u0026#34;name\u0026#34;)); user.setPassword(rs.getString(\u0026#34;password\u0026#34;)); rs.close(); ps.close(); c.close(); return user; } } package springbook1; import java.sql.SQLException; public class UserDaoTest { public static void main(String[] args) throws ClassNotFoundException, SQLException { // TODO Auto-generated method stub ConnectionMaker connectionMaker = new DConnectionMaker(); UserDao dao = new UserDao(connectionMaker); User user = new User(); user.setId(\u0026#34;ocean\u0026#34;); user.setName(\u0026#34;zz\u0026#34;); user.setPassword(\u0026#34;hi3\u0026#34;); dao.add(user); System.out.println(user.getId() + \u0026#34;등록 성공\u0026#34;); User user2 = dao.get(user.getId()); System.out.println(user2.getName()); System.out.println(user2.getPassword()); System.out.println(user2.getId() + \u0026#34;조회 성공\u0026#34;); } } [리팩토링6] 오브젝트 팩토리 팩토리 클래스의 역할은 객체의 생성 방법을 정하고 그렇게 만들어진 오브젝트를 돌려주는 것이다. 1-14. UserDao의 생성 책임을 맡은 팩토리 클래스 1-15. 팩토리를 사용하도록 수정한 UserDaoTest 1-16. DAO 생성 메소드의 추가로 인해 발생하는 중복 1-17. 생성 오브젝트 코드 수정 package springbook1; public class DaoFactory { public UserDao userDao() { return new UserDao(connectionMaker()); } public AccountDao accountDao() { return new AccountDao(connectionMaker()); } public MessageDao messageDao() { return new MessageDao(connectionMaker()); } public ConnectionMaker connectionMaker() { return new DConnectionMaker(); } } package springbook1; import java.sql.SQLException; public class UserDaoTest { public static void main(String[] args) throws ClassNotFoundException, SQLException { // TODO Auto-generated method stub UserDao dao = new DaoFactory().userDao(); User user = new User(); user.setId(\u0026#34;ocean\u0026#34;); user.setName(\u0026#34;zz\u0026#34;); user.setPassword(\u0026#34;hi3\u0026#34;); dao.add(user); System.out.println(user.getId() + \u0026#34;등록 성공\u0026#34;); User user2 = dao.get(user.getId()); System.out.println(user2.getName()); System.out.println(user2.getPassword()); System.out.println(user2.getId() + \u0026#34;조회 성공\u0026#34;); } } 용어 Application Framework : 애플리케이션 개발을 빠르고 효율적으로 할 수 있도록 애프리케이션의 바탕이 되는 틀과 공통 프로그래밍 모델, 기술 API 등을 제공해준다. AOP : 애플리케이션 코드에 산재해서 나타나는 부가적인 기능을 독립적으로 모듈화하는 프로그래밍 모델이다. DAO (Data Access Object) : DB를 사용해 데이터를 조회하거나 조작하는 기능을 전담하도록 만든 오브젝트다. IoC/DI : 오브젝트의 생명주기와 의존관계에 대한 프로그래밍 모델이다. Refactoring : 기존의 코드를 외부의 동작방식에는 변화 없이 내부 구조를 변경해서 재구성하는 작업 또는 기술을 말한다. Service Abstraction : 구체적인 기술과 환경에 종속되지 않도록 유연한 추상 계층을 두는 방법이다. Framework : 애플리케이션을 구성하는 오브젝트가 생성되고 동작하는 방식에 대한 틀을 제공한다. 애플리케이션 코드가 어떻게 작성돼야 하는지에 대한 기준도 제시한다. 이런 틀을 프로그래밍 모델이라고 한다. SOLID : 객체지향 설계 원칙 SRP(The Single Responsibility Principle) - 단일 책임 원칙 OCP(The Open Closed Principle) - 개방 폐쇄 원칙 LSP(The Liskov Substitution Principle) - 리스코프 치환 원칙 ISP(The Interface Segregation Principle) - 인터페이스 분리 원칙 DIP(The Dependency Inversion Principle) - 의존관계 역전 원칙 책 속 자료 디자인 패턴 GoF의 디자인 패턴, 에릭 감마 외 Head First Design Patterns, 에릭 프리먼 객체지향 설계 원칙(SOLID) Java 프로그래머를 위한 UML 실전에서는 이것만 쓴다 (UML for Java Programmer), 밥 마틴 소프트웨어 개발의 지혜: 원칙, 디자인 패턴, 실천 방법 (Agile Software Development, Principles, Patterns, and Practices), 밥 마틴 SOLID 소개, 로버트 마틴 참고 자료 [book] 토비의 스프링 3.1 Vol 1: 스프링의 이해와 원리, 이일민 ","permalink":"http://slow-wave.github.io/post/spring/spring_toby_0/","summary":"스프링이란 무엇인가? 스프링은 자바 엔터프라이즈 애플리케이션 개발에 사용되는 애플리케이션 프레임워크다. 스프링을 사용한다는 것은 다음의 세 가지 요소를 적극적으로 활용해서 애플리케이션을 개발한다는 뜻이다. 스프링 개발 철학 중 하나는 ‘항상 프레임워크 기반의 접근 방법을 사용하라’이다. 프레임워크의 가장 중요한 목적은 개발자가 일정한 틀을 따라 효과적으로 애플리케이션을 개발하도록 돕는 것이다. 따라서 프레임워크를 잘 이해하려면 프레임워크를 사용했을 때 애플리케이션 코드가 어떻게 만들어지는지 자세히 살펴봐야 한다. 1) 애플리케이션의 기본 틀 - 스프링 컨테이너 스프링은 스프링 컨테이너라고 불리는 스프링 런타임 엔진을 제공한다.","title":"[토비의 스프링 3.1] 1.1~1.4 정리"},{"content":"소수 판별 Intro 코딩테스트 문제를 풀다보면 가끔 소수 판별하는 문제가 나옵니다. 소수는 간단하게 정의하자면 1보다 큰 자연수 중 1과 자기 자신만을 약수로 가지는 수입니다. 수학 시간에 소수를 많이 다뤘다보니 수를 보면 이 수는 소수인지 아닌지는 작은 수면 바로 판별이 가능하지만 이를 알고리즘으로 바꾸는 것은 좀 어려웠습니다.\n다행히 소수 판별 문제를 해결하기 위한 대표적인 방법이 의미 정의 되어있습니다. 에라토스테네스의 체 알고리즘을 활용하는 것입니다. 이는 다수의 자연수에 대하여 소수 여부를 판별할 때 사용하는 대표적인 알고리즘이며 N보다 작거나 같은 모두 소수를 찾을 때 사용할 수 있습니다.\n1) 과정 에라토스테네스의 체 알고리즘의 구체적인 동작 과정은 다음과 같습니다. 1. 2부터 𝑁까지의 모든 자연수를 나열한다 2. 남은 수 중에서 아직 처리하지 않은 가장 작은 수 𝑖를 찾는다 3. 남은 수 중에서 i의 배수를 모두 제거한다(𝑖는 제거하지 않는다) 4. 더 이상 반복할 수 없을 때까지 2번과 3번의 과정을 반복한다 2) code 위의 동작 과정을 코드로 구현하면 다음과 같습니다.\ndef prime(n): array = [True for i in range(n + 1)] # 처음엔 모든 수가 소수(True)인 것으로 초기화 # 에라토스테네스의 체 알고리즘 for i in range(2, int(n ** 0.5 + 1)): # 2부터 n의 제곱근까지의 모든 수를 확인하며 if array[i] == True: # i가 소수인 경우 (남은 수인 경우) # i를 제외한 i의 모든 배수를 지우기 j = 2 while i * j \u0026lt;= n: array[i * j] = False j += 1 return array 3) ‘소수 판별’ 관련 문제 백준 1920번 백준 1987번 참고 자료 [blog] [이것이 코딩 테스트다 with Python] 38강 에라토스테네스의 체 [wiki] 소수 [wiki] 에라토스테네스의 체 ","permalink":"http://slow-wave.github.io/post/algorithm/algo_prime/","summary":"소수 판별 Intro 코딩테스트 문제를 풀다보면 가끔 소수 판별하는 문제가 나옵니다. 소수는 간단하게 정의하자면 1보다 큰 자연수 중 1과 자기 자신만을 약수로 가지는 수입니다. 수학 시간에 소수를 많이 다뤘다보니 수를 보면 이 수는 소수인지 아닌지는 작은 수면 바로 판별이 가능하지만 이를 알고리즘으로 바꾸는 것은 좀 어려웠습니다.\n다행히 소수 판별 문제를 해결하기 위한 대표적인 방법이 의미 정의 되어있습니다. 에라토스테네스의 체 알고리즘을 활용하는 것입니다. 이는 다수의 자연수에 대하여 소수 여부를 판별할 때 사용하는 대표적인 알고리즘이며 N보다 작거나 같은 모두 소수를 찾을 때 사용할 수 있습니다.","title":"[algorithm] 소수 판별"},{"content":"Table간 Join을 수행해야할 때는 다음과 같이 집합의 개념을 활용해서 생각하면 좋습니다. MySQL 언어로 아래의 모든 집합 관계에 대해서 표현해보려고 합니다.\nMySQL JOINS 0. Full Outer Join [0] problem /* Input: Employees table: +-------------+----------+ | employee_id | name | +-------------+----------+ | 2 | Crew | | 4 | Haven | | 5 | Kristian | +-------------+----------+ Salaries table: +-------------+--------+ | employee_id | salary | +-------------+--------+ | 5 | 76071 | | 1 | 22517 | | 4 | 63539 | +-------------+--------+ Output: +-------------+ | employee_id | +-------------+ | 1 | | 2 | +-------------+ */ select Employees.employee_id from Employees left join Salaries on Employees.employee_id = Salaries.employee_id WHERE Salaries.employee_id is NULL union select Salaries.employee_id from Employees right join Salaries on Employees.employee_id = Salaries.employee_id WHERE Employees.employee_id is NULL order by employee_id; MySQL에는 FULL OUTER JOIN 없음 1. LEFT OUTER JOIN [0] problem /* Input: Person table: +----------+----------+-----------+ | personId | lastName | firstName | +----------+----------+-----------+ | 1 | Wang | Allen | | 2 | Alice | Bob | +----------+----------+-----------+ Address table: +-----------+----------+---------------+------------+ | addressId | personId | city | state | +-----------+----------+---------------+------------+ | 1 | 2 | New York City | New York | | 2 | 3 | Leetcode | California | +-----------+----------+---------------+------------+ Output: +-----------+----------+---------------+----------+ | firstName | lastName | city | state | +-----------+----------+---------------+----------+ | Allen | Wang | Null | Null | | Bob | Alice | New York City | New York | +-----------+----------+---------------+----------+ */ SELECT p.firstName, p.lastName, a.city, a.state FROM Person as p LEFT OUTER JOIN Address as a ON p.personId = a.personId; [1] problem /* Input: Visits +----------+-------------+ | visit_id | customer_id | +----------+-------------+ | 1 | 23 | | 2 | 9 | | 4 | 30 | | 5 | 54 | | 6 | 96 | | 7 | 54 | | 8 | 54 | +----------+-------------+ Transactions +----------------+----------+--------+ | transaction_id | visit_id | amount | +----------------+----------+--------+ | 2 | 5 | 310 | | 3 | 5 | 300 | | 9 | 5 | 200 | | 12 | 1 | 910 | | 13 | 2 | 970 | +----------------+----------+--------+ Output: +-------------+----------------+ | customer_id | count_no_trans | +-------------+----------------+ | 54 | 2 | | 30 | 1 | | 96 | 1 | +-------------+----------------+ */ # ANSWER1 - 처음에는 full outer join 해야한다고 생각함. SELECT d.customer_id, count(d.visit_id) as count_no_trans FROM ( SELECT v.customer_id, v.visit_id FROM Visits as v LEFT JOIN Transactions as t ON v.visit_id = t.visit_id WHERE t.visit_id is NULL UNION SELECT v.customer_id, v.visit_id FROM Transactions as t RIGHT JOIN Visits as v ON v.visit_id = t.visit_id WHERE t.visit_id is NULL) as d GROUP BY d.customer_id; #ANSWER2 (final) SELECT customer_id, COUNT(Visits.visit_id) AS count_no_trans FROM visits LEFT JOIN Transactions ON Visits.visit_id = Transactions.visit_id WHERE Transactions.visit_id IS NULL GROUP BY customer_id; 참고 자료 [blog] Mysql Join 해부(Left, Right, Outer, Inner Join) ","permalink":"http://slow-wave.github.io/post/database/db_mysql_2/","summary":"Table간 Join을 수행해야할 때는 다음과 같이 집합의 개념을 활용해서 생각하면 좋습니다. MySQL 언어로 아래의 모든 집합 관계에 대해서 표현해보려고 합니다.\nMySQL JOINS 0. Full Outer Join [0] problem /* Input: Employees table: +-------------+----------+ | employee_id | name | +-------------+----------+ | 2 | Crew | | 4 | Haven | | 5 | Kristian | +-------------+----------+ Salaries table: +-------------+--------+ | employee_id | salary | +-------------+--------+ | 5 | 76071 | | 1 | 22517 | | 4 | 63539 | +-------------+--------+ Output: +-------------+ | employee_id | +-------------+ | 1 | | 2 | +-------------+ */ select Employees.","title":"[MySQL] joins"},{"content":"0) Second Highest Salary (problem) Input: Employee table: +----+--------+ | id | salary | +----+--------+ | 1 | 100 | | 2 | 200 | | 3 | 300 | +----+--------+ Output: +---------------------+ | SecondHighestSalary | +---------------------+ | 200 | +---------------------+ solution 1\nSELECT max(Salary) as SecondHighestSalary FROM Employee WHERE Salary \u0026lt; (SELECT max(Salary) FROM Employee); solution 2 (n-th rank 구할 때 적절할 듯)\nWITH CTE AS (SELECT Salary, RANK () OVER (ORDER BY Salary desc) AS RANK_desc FROM Employee) SELECT MAX(salary) AS SecondHighestSalary FROM CTE WHERE RANK_desc = 2 with 절 동일한 SQL 문이 반복되어 성능을 높이기 위해 사용됨. table을 만들지 않아도 만든 것 같은 효과를 냄. → 메모리를 차지함. option materialize : 기본 with절 사용 시 적용. temp 사용함. inline : temp 테이블을 생성하지 않고 inline view로 수행함. view DB에 존재하는 가상 테이블임. 실제 행과 열은 있지만 데이터를 저장하고 있진 않는다. 테이블처럼 물리적으로 저장되어 있는 것은 아님. with 절 vs. view with 절 장점 : temp라는 임시 테이블을 사용해서 장시간 걸리는 쿼리의 결과를 저장해놓고 저장해놓은 데이터를 엑세스해서 성능이 좋음. 단점 : 메모리를 차지함. view 장점 : 특정 사용자에게 테이블 전체가 아닌 필요한 필드만 보여줄 수 있음. 복잡한 쿼리를 단순화해서 사용할 수 있음. 단점 : 삽입, 삭제, 갱신 작업에 많은 제한 사항을 가짐. 자신만의 인덱스를 가질 수 없음. 참고 자료 [blog] [MYSQL] 📚 WITH (임시 테이블 생성) [blog] [MySQL] 뷰 생성하기(VIEW 생성하기) ","permalink":"http://slow-wave.github.io/post/database/db_mysql_1/","summary":"0) Second Highest Salary (problem) Input: Employee table: +----+--------+ | id | salary | +----+--------+ | 1 | 100 | | 2 | 200 | | 3 | 300 | +----+--------+ Output: +---------------------+ | SecondHighestSalary | +---------------------+ | 200 | +---------------------+ solution 1\nSELECT max(Salary) as SecondHighestSalary FROM Employee WHERE Salary \u0026lt; (SELECT max(Salary) FROM Employee); solution 2 (n-th rank 구할 때 적절할 듯)\nWITH CTE AS (SELECT Salary, RANK () OVER (ORDER BY Salary desc) AS RANK_desc FROM Employee) SELECT MAX(salary) AS SecondHighestSalary FROM CTE WHERE RANK_desc = 2 with 절 동일한 SQL 문이 반복되어 성능을 높이기 위해 사용됨.","title":"[MySQL] 활용"},{"content":"코딩테스트 연습 할 때 Leetcode 플랫폼을 많이 이용합니다. discussion을 보면 문제에 대한 각자의 코드와 설명이 있는데 많은 사람들이 vote와 댓글 기능을 이용해 피드백을 줍니다. 보통은 칭찬이 많이 달려있는 글을 위주로 참고합니다. 별로인 것에 대해서는 가차없는 피드백이 적혀있다는 것도 도움이 되는 것 같습니다. 또 댓글로 시간복잡도 등에 대해서 토론하는 부분도 있어서 유용합니다.\n개인적으로 SQL을 공부 할 필요성을 느껴서 MySQL의 문법을 중심으로 problem과 code를 정리해봤습니다. discussion을 꼼꼼히 읽어서 어떻게 코딩하는 것이 좋은 방향인지도 알아보려고 합니다.\n0) SUBSTRING (problem) # 1667. Fix Names in a Table /* Input: Users table: +---------+-------+ | user_id | name | +---------+-------+ | 1 | aLice | | 2 | bOB | +---------+-------+ Output: +---------+-------+ | user_id | name | +---------+-------+ | 1 | Alice | | 2 | Bob | +---------+-------+ */ SELECT user_id, CONCAT(UPPER(SUBSTRING(name,1,1)), LOWER(SUBSTRING(name,2,LENGTH(name)))) as name FROM Users ORDER BY user_id; SUBSTRING(str,pos) pos ~ 위치까지의 문자열 반환 SUBSTRING(str,pos,len) pos ~ len 위치까지의 문자열 반환 1) GROUP_CONCAT (problem) /* Input: Activities table: +------------+------------+ | sell_date | product | +------------+------------+ | 2020-05-30 | Headphone | | 2020-06-01 | Pencil | | 2020-06-02 | Mask | | 2020-05-30 | Basketball | | 2020-06-01 | Bible | | 2020-06-02 | Mask | | 2020-05-30 | T-Shirt | +------------+------------+ Output: +------------+----------+------------------------------+ | sell_date | num_sold | products | +------------+----------+------------------------------+ | 2020-05-30 | 3 | Basketball,Headphone,T-shirt | | 2020-06-01 | 2 | Bible,Pencil | | 2020-06-02 | 1 | Mask | +------------+----------+------------------------------+ */ SELECT sell_date, COUNT(DISTINCT product) AS num_sold, GROUP_CONCAT(DISTINCT product ORDER BY product) AS products FROM Activities GROUP BY sell_date; 2) LIKE (problem) /* Input: Patients table: +------------+--------------+--------------+ | patient_id | patient_name | conditions | +------------+--------------+--------------+ | 1 | Daniel | YFEV COUGH | | 2 | Alice | | | 3 | Bob | DIAB100 MYOP | | 4 | George | ACNE DIAB100 | | 5 | Alain | DIAB201 | +------------+--------------+--------------+ Output: +------------+--------------+--------------+ | patient_id | patient_name | conditions | +------------+--------------+--------------+ | 3 | Bob | DIAB100 MYOP | | 4 | George | ACNE DIAB100 | +------------+--------------+--------------+ */ SELECT * FROM Patients WHERE conditions LIKE \u0026#39;DIAB1%\u0026#39; or conditions LIKE \u0026#39;% DIAB1%\u0026#39;; 3) UNION ALL (problem) /* Input: Products table: +------------+--------+--------+--------+ | product_id | store1 | store2 | store3 | +------------+--------+--------+--------+ | 0 | 95 | 100 | 105 | | 1 | 70 | null | 80 | +------------+--------+--------+--------+ Output: +------------+--------+-------+ | product_id | store | price | +------------+--------+-------+ | 0 | store1 | 95 | | 0 | store2 | 100 | | 0 | store3 | 105 | | 1 | store1 | 70 | | 1 | store3 | 80 | +------------+--------+-------+ */ SELECT product_id, \u0026#39;store1\u0026#39; store, store1 price FROM Products WHERE not store1 is null UNION ALL SELECT product_id, \u0026#39;store2\u0026#39; store, store2 price FROM Products WHERE not store2 is null UNION ALL SELECT product_id, \u0026#39;store3\u0026#39; store, store3 price FROM Products WHERE not store3 is null; 4) NOT IN, NOT EXISTS (problem) UNION vs. UNION ALL UNION만 사용하면 중복된 열 제거 \u0026amp; 데이터 정렬 UNION ALL만 사용하면 중복된 열까지 출력 문제에서 ‘product_id’는 PK라고 했으므로 중복된 것이 존재할 수 없음. 따라서 UNION ALL을 사용해서 중복 제거 과정을 거치지 않는 것이 맞다고 판단함. /* Input: Visits +----------+-------------+ | visit_id | customer_id | +----------+-------------+ | 1 | 23 | | 2 | 9 | | 4 | 30 | | 5 | 54 | | 6 | 96 | | 7 | 54 | | 8 | 54 | +----------+-------------+ Transactions +----------------+----------+--------+ | transaction_id | visit_id | amount | +----------------+----------+--------+ | 2 | 5 | 310 | | 3 | 5 | 300 | | 9 | 5 | 200 | | 12 | 1 | 910 | | 13 | 2 | 970 | +----------------+----------+--------+ Output: +-------------+----------------+ | customer_id | count_no_trans | +-------------+----------------+ | 54 | 2 | | 30 | 1 | | 96 | 1 | +-------------+----------------+ */ # ANSWER1 - NOT IN SELECT customer_id, COUNT(visit_id) as count_no_trans FROM Visits WHERE visit_id NOT IN ( SELECT visit_id FROM Transactions ) GROUP BY customer_id #ANSWER2 - NOT EXISTS SELECT customer_id, COUNT(visit_id) as count_no_trans FROM Visits v WHERE NOT EXISTS ( SELECT visit_id FROM Transactions t WHERE t.visit_id = v.visit_id ) GROUP BY customer_id in vs. exists in 연산자 : sub query → main query 순서로 처리 sub에서 main의 정보를 가져올 수 없기 때문에 조건을 각각 설정함. exists 연산자 : main query → sub query 순서로 처리 sub에서 main의 정보를 가져와 모든 조건을 한번에 설정함. 참고 자료 [blog] UNION과 UNION ALL 의 차이 및 주의 사항 [blog] [MS SQL Server] #11_ IN / EXISTS / NOT IN / NOT EXISTS 비교 [blog] [MySQL] in 연산자와 exists 연산자 의 차이 ","permalink":"http://slow-wave.github.io/post/database/db_mysql_0/","summary":"코딩테스트 연습 할 때 Leetcode 플랫폼을 많이 이용합니다. discussion을 보면 문제에 대한 각자의 코드와 설명이 있는데 많은 사람들이 vote와 댓글 기능을 이용해 피드백을 줍니다. 보통은 칭찬이 많이 달려있는 글을 위주로 참고합니다. 별로인 것에 대해서는 가차없는 피드백이 적혀있다는 것도 도움이 되는 것 같습니다. 또 댓글로 시간복잡도 등에 대해서 토론하는 부분도 있어서 유용합니다.\n개인적으로 SQL을 공부 할 필요성을 느껴서 MySQL의 문법을 중심으로 problem과 code를 정리해봤습니다. discussion을 꼼꼼히 읽어서 어떻게 코딩하는 것이 좋은 방향인지도 알아보려고 합니다.","title":"[MySQL] 문법/함수 정리"},{"content":"intro mac에서 virtualbox를 이용해 비교적 간단하게 ubuntu 환경을 구축하는 방법에 대한 글입니다.\nvirtualbox는 Oracle VM VirtualBox는 GPLv2 라이선스로 배포되는 오픈 소스 하드웨어 리소스 가상화 프로그램입니다. 일반 컴퓨터에 운영체제를 설치하고 프로그램을 실행할 수 있는 것처럼, 가상머신 위에도 운영체제를 설치하고 프로그램을 실행할 수 있습니다. Vagrant는 Mitchell Hashimoto가 Ruby로 개발하고 2010년 3월 처음 릴리스한 커맨드라인 인터페이스로 가상 머신 기반 개발 환경을 관리하는 도구입니다. 우분투(Ubuntu)는 가장 널리 쓰이는 오픈소스 리눅스 배포판 중 하나입니다.\n아래 태스크들을 실행하기 전에 homebrew를 먼저 설치해야 합니다. 설치 방법에 대한 설명은 이곳(homebrew install guide)에 서 확인 할 수 있습니다.\n로컬 가상 환경을 구축해야하는 이유는 다음과 같습니다.\n개발코드 및 컴파일 환경을 제외하고 불필요한 프로그램을 설치할 필요가 없음 개발 테스트 환경을 코드로 관리 가능 가상 머신 환경 구축 방법 [0] 개발 환경 desktop: macbook pro 13 2019 cpu: 1.4 GHz 쿼드 코어 Intel Core i5 memory: 16GB [1] Virtualbox 설치 [virtualbox] install $ brew install --cask virtualbox $ virtualbox //virtualbox 실행 [2] Vagrant 설치 https://github.com/hashicorp/vagrant $ brew cask install vagrant 시작 \u0026amp; 종료 $ vagrant up //vagrant를 provisioning 하기 위한 Vagrantfile 생성 $ vagrant ssh //vagrant에서 생성된 가상 머신에 ssh로 접속 $ exit $ vagrant halt //vagrant에서 관리하는 가상 머신 종료 [3] Ubuntu 설치 $ mkdir -p ~/vagrant/xenial64 //설치용 폴더 만들기 $ cd ~/vagrant/xenial64 //폴더로 이동 $ vagrant init ubuntu/xenial64 //가상 머신 설정 파일을 작성 $ vagrant up //부팅 가능 여부 확인 및 vagrant 가상 환경 부팅 참고 자료 [blog] **Mac에서 Virtualbox 설치하기** [geekconfig] **Mac에 VirtualBox와 vagrant를 넣어 우분투를 새로 설치** [blog] **Brew로 vagrant 설치하기** [medium] **Virtual Box, Vagrant를 이용한 가상 머신 환경 만들기** ","permalink":"http://slow-wave.github.io/post/etc/etc_vm_0/","summary":"intro mac에서 virtualbox를 이용해 비교적 간단하게 ubuntu 환경을 구축하는 방법에 대한 글입니다.\nvirtualbox는 Oracle VM VirtualBox는 GPLv2 라이선스로 배포되는 오픈 소스 하드웨어 리소스 가상화 프로그램입니다. 일반 컴퓨터에 운영체제를 설치하고 프로그램을 실행할 수 있는 것처럼, 가상머신 위에도 운영체제를 설치하고 프로그램을 실행할 수 있습니다. Vagrant는 Mitchell Hashimoto가 Ruby로 개발하고 2010년 3월 처음 릴리스한 커맨드라인 인터페이스로 가상 머신 기반 개발 환경을 관리하는 도구입니다. 우분투(Ubuntu)는 가장 널리 쓰이는 오픈소스 리눅스 배포판 중 하나입니다.\n아래 태스크들을 실행하기 전에 homebrew를 먼저 설치해야 합니다.","title":"[config]Virtual Box, Vagrant를 이용한 가상 머신 환경 구축"},{"content":" Web개발의 이해 1-1. HTTP 프로토콜의 이해 1-2. browser의 동작 1-3. 웹서버 1-4. WAS 이 글은 \u0026ldquo;How Browsers Work: Behind the scenes of modern web browsers\u0026ldquo;의 번역본을 정리한 것입니다.\n1. broswer 1) broswer의 주요 기능 브라우저의 주요 기능은 사용자가 선택한 자원을 서버에 요청하고 브라우저에 표시하는 것입니다. 자원은 보통 HTML 문서이지만 다른 형태일 수 있으며, 자원의 주소는 URI(Uniform Resource Identifier)에 의해 정해집니다.\n2) browser의 기본 구조 UI : 주소 표시줄, 이전/다음 버튼 등 요청한 페이지를 보여주는 창을 제외한 나머지 모든 부분입니다. Browser Engine : UI와 Rendering Engine 사이의 동작을 제어합니다. Rendering Engine : 요청한 컨텐츠를 표시합니다. HTML을 요청하면 HTML과 CSS를 파싱하여 화면에 표시합니다. Chrome의 경우 대부분의 브라우저와 달리 각 탭마다 별도의 렌더링 엔진 인스턴스를 유지합니다. 각 탭은 독립된 프로세스로 처리됩니다. Networking : HTTP 요청과 같은 네트워크 호출에 사용됩니다. 이는 플랫폼 독립적인 UI이고 각 플랫폼 하부에서 실행됩니다. UI Backend : 콤보 박스와 창 같은 기본적인 장치를 그립니다. 플랫폼에서 명시하지 않은 일반적은 인터페이스로서, OS UI 체계를 사용합니다. Javascript Interpreter : javascript 코드를 해석하고 실행합니다. Data Persistence : 자료를 저장하는 계층입니다. 쿠키를 저장하는 것과 같이 모든 종류의 자원을 하드디스크에 저장해야합니다. HTML5 명세에는 브라우저가 지원하는 ‘웹 데이터 베이스\u0026rsquo;가 정의되어있습니다. 2. Rendering Engine 렌더링 엔진은 요청 받은 내용을 브라우저 화면에 표시하는 역할을 합니다.\nfirefox는 Gecko engine chrome, safari는 webkit engine을 사용함. 1) Rendering Engine 동작 과정 렌더링 엔진은 통신으로부터 요청한 문서의 내용을 얻는 것으로 시작하는데 문서의 내용은 보통 8KB 단위로 전송됩니다.\n렌더링 엔진은 좀 더 나은 사용자 경험을 위해 가능하면 빠르게 내용을 표시하는데 모든 HTML을 파싱할 때까지 기다리지 않고 배치와 그리기 과정을 시작합니다. 네트워크로부터 나머지 내용이 전송되기를 기다리는 동시에 받은 내용의 일부를 먼저 화면에 표시하는 것입니다.\n[1] HTML 파싱\n렌더링 엔진은 HTML 문서를 파싱하고 콘텐츠 트리 내부에서 태그를 DOM 노드로 변환 [2] 렌더 트리 구축\n그 다음 외부 CSS파일과 함께 포함된 스타일 요소도 파싱한다. 스타일 정보와 HTML 표시 규칙은 렌더 트리라고 부르는 다른 트리를 생성 [3] 렌더 트리 배치\n배치란 각 노드가 화면의 정확한 위치에 표시되는 것을 의미한 [4] 렌더 트리 그리기\nUI 백엔드에서 렌더 트리의 각 노드를 가로지르며 형상을 만들어 내는 그리기 과정 3. Parsing - general 문서 파싱은 브라우저가 코드를 이해하고 사용할 수 있는 구조로 변환하는 것을 의미합니다. 파싱 결과는 보통 문서 구조를 나타내는 노드 트리인데 파싱 트리(parse tree) 또는 문법 트리(syntax tree)라고 합니다.\n1) 문법 파싱은 문서에 작성된 언어 또는 형식의 규칙에 따르는데 파싱할 수 있는 모든 형식은 정해진 용어와 구문 규칙에 따라야합니다. 이것을 context free grammar라고 합니다. context free grammar라면 언어는 정규 파서로 파싱할 수 있습니다.\n2) Parser - Lexer combination(파서-어휘 분석기 조합) 파싱은 어휘 분석과 구문 분석 두가지로 구분할 수 있습니다.\n[1] 어휘 분석 : 자료를 토큰으로 분해하는 과정\n공백과 같은 의미없는 문자 제거 [2] 구문 분석 : 언어의 구문 규칙을 적용하는 과정\n언어 구문 규칙에 따라 문서 구조 분석 파싱 과정은 반복됩니다. 파서는 보통 어휘 분석기로부터 새 토큰을 받아서 구문 규칙과 일치하는지 확인합니다.\n규칙에 맞으면 토큰에 해당하는 노드가 파싱 트리에 추가 \u0026amp; 파서는 다른 토큰 요청 규칙에 맞지 않으면 토큰을 내부적으로 저장하고 토큰과 일치하는 규칙이 발견될 때까지 요청 맞는 규칙이 없는 경우 예외로 처리하는데 이것은 문서가 유효하지 않고 구문 오류를 포함하고 있다는 것임 3) 변환 파서 트리는 최종 결과물이 아닙니다. 파싱은 보통 문서를 다른 양식으로 변환하는데 컴파일이 하나의 예가 됩니다. 소스 코드를 기계 코드로 만드는 컴파일러는 파싱 트리 생성 후 이를 기계 코드 문서로 변환합니다.\n4) parser의 종류 하향식 파서 : 구문의 상위 구조로부터 일치하는 부분을 찾음. 일치하는 다른 규칙을 점진적으로 찾아내면서 표현식을 찾음. 상향식 파서 : 낮은 수준에서 점차 높은 수준으로 찾음. 입력 값이 규칙에 맞을 때까지 찾아서 맞는 입력값을 규칙으로 바꾸는데 이 과정은 입력값의 끝까지 진행됨. 부분적으로 일치하는 표현식은 파서 스택에 쌓임. 5) 파서 자동 생성 파서를 생성해 줄 수 있는 도구를 파서 생성기라고 합니다. 언어에 구문 규칙 같은 문법을 부여하면 동작하는 파서를 만들어줍니다.\n4. HTML parser HTML은 파싱하기 어렵고 전통적인 구문 분석이 불가능하기 때문에 context free grammar가 아닙니다.\n1) HTML DTD HTML의 정의는 DTD 형식 안에 있는데 SGML 계열 언어의 정의를 이용한 것입니다.\n2) DOM(Document Object Model) 파싱 트리는 DOM 요소와 속성 노드의 트리로서 출력 트리가 됩니다. 이것은 HTML 문서의 객체 표현이고 외부를 향하는 자바스크립트와 같은 HTML 요소의 연결 지점입니다. 트리의 최상위 객체는 문서입니다.\nDOM은 마크업과 1:1 관계를 갖습니다. HTML과 마찬가지로 DOM은 W3C에 의해 명세(www.w3.org/DOM/DOMTR )가 정해져 있습니다. \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello World\u0026lt;/p\u0026gt; \u0026lt;div\u0026gt;\u0026lt;img src=\u0026#34;example.png\u0026#34; /\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 5. Render tree construction DOM 트리가 구축되는 동안 브라우저는 렌더 트리를 구축합니다. 표시해야 할 순서와 문서의 시각적인 구성 요소로써 올바른 순서로 내용을 그려낼 수 있도록 하기 위한 목적입니다.\nfirefox - frames webkit - renderer or render object renderer는 자신과 자식 요소를 어떻게 배치하고 그려내야 하는지 알고 있습니다.\n1) DOM tree와 Render tree의 관계 렌더러는 DOM 요소에 부합하지만 1:1로 대응하는 관계는 아닙니다. 예를 들어 head 요소와 같은 비시각적 DOM 요소는 렌더 트리에 추가되지 않습니다. 또한 display:none인 요소도 나타나지 않습니다.\n참고 자료 [1] [naver D2] 브라우저는 어떻게 동작하는가?\n[2] [web.dev] How browsers work\n","permalink":"http://slow-wave.github.io/post/fullstack_boostcourse/web_boostcourse_1/","summary":"Web개발의 이해 1-1. HTTP 프로토콜의 이해 1-2. browser의 동작 1-3. 웹서버 1-4. WAS 이 글은 \u0026ldquo;How Browsers Work: Behind the scenes of modern web browsers\u0026ldquo;의 번역본을 정리한 것입니다.\n1. broswer 1) broswer의 주요 기능 브라우저의 주요 기능은 사용자가 선택한 자원을 서버에 요청하고 브라우저에 표시하는 것입니다. 자원은 보통 HTML 문서이지만 다른 형태일 수 있으며, 자원의 주소는 URI(Uniform Resource Identifier)에 의해 정해집니다.\n2) browser의 기본 구조 UI : 주소 표시줄, 이전/다음 버튼 등 요청한 페이지를 보여주는 창을 제외한 나머지 모든 부분입니다.","title":"[boostcourse 웹프로그래밍 풀스택] 1-2. browser의 동작"},{"content":"0. Spanning Tree Spanning Tree란 그래프 내의 모든 정점을 포함하는 트리입니다. 즉, 그래프에서 일부 간선을 선택해서 만든 트리입니다. 이때 그래프에 사이클이 형성이 되면 안됩니다. 연결 그래프에 대한 spanning tree는 여러개 일 수 있습니다.\nn개의 정점을 가지는 그래프의 최소 간선의 수는 (n-1)개이고, (n-1)개로 연결되어 있으면 필연적으로 트리 형태가 되고 이것이 spanning tree가 됩니다. 따라서 spanning tree는 그래프에 있는 n개의 정점을 (n-1)개의 간선으로 연결합니다.\n1. Minimum Spanning Tree (MST) MST는 트리를 구성하는 간선들의 가중치를 합한 것이 최소가 되는 신장 트리이며 다음의 조건을 충족해야합니다.\n최소 비용의 간선으로 구성 사이클을 포함하지 않음 MST를 구하는 방법들은 greedy algorithm으로 구현이 되어 있습니다. 대표적인 것에는 Kruskal Algorithm과 Prim Algorithm이 있습니다.\n2-1. Kruskal MST Algorithm 0) 정의 Kruskal은 간선 선택을 기반으로 하는 알고리즘입니다. 이전 단계에서 만들어진 신장 트리와는 상관없이 무조건 최소 간선만을 선택하는 방법입니다.\n1) 과정 [1] 그래프의 간선들을 가중치의 오름차순으로 정렬한다.\n[2] 정렬된 간선 리스트에서 순서대로 사이클을 형성하지 않는 간선을 선택한다.\n[3] 해당 간선을 현재의 MST의 집합에 추가한다.\n그림 설명 2) code #kruskal algorithm parent = dict() # 각 정점의 root node(부모)를 표현한 배열 rank = dict() #node 초기화 def make_set(node): parent[node] = node rank[node] = 0 #해당 node의 최상위 정점을 찾는다 (가장 낮은 가중치 선택) def find(node): if parent[node] != node: parent[node] = find(parent[node]) return parent[node] #두 정점을 연결한다 def union(node1, node2): root1 = find(node1) root2 = find(node2) if root1 != root2: if rank[root1] \u0026gt; rank[root2]: parent[root2] = root1 else: parent[root1] = root2 if rank[root1] == rank[root2]: rank[root2] += 1 def kruskal(graph): minimum_spanning_tree = [] #초기화 for node in graph[\u0026#39;nodes\u0026#39;]: make_set(node) #1) 간선 weight 기반 sorting edges = graph[\u0026#39;edges\u0026#39;] edges.sort() #오름차순 정렬 #2) 간선 연결 (사이클 없게) for edge in edges: weight, node1, node2 = edge #만약 사이클이 발생하지 않는다면 (node1과 node2의 최상위 정점이 같지 않다면) if find(node1) != find(node2): #루트노드가 다르므로 union union(node1, node2) #3) 간선 추가 minimum_spanning_tree.append(edge) return minimum_spanning_tree def solution(): graph = {\u0026#39;nodes\u0026#39;: [1, 2, 3, 4], \u0026#39;edges\u0026#39;: [(1,1,2),(1,1,3),(1,2,3),(1,3,4),(3,2,4)]} #(weight,node1,node2) return kruskal(graph) solution() # 결과 : [(1, 1, 2), (1, 1, 3), (1, 3, 4)] # 가중치의 합 : 3 2-2. Prim MST Algorithm 0) 정의 Prim은 정점 선택을 기반으로 하는 알고리즘입니다. 이전 단계에서 만들어진 신장 트리를 확장하는 방법입니다.\n1) 과정 [1] 시작 단계에서는 시작 정점만이 MST(최소 비용 신장 트리) 집합에 포함된다.\n[2] 앞 단계에서 만들어진 MST집합에 인접한 정점들 중에서 최소 간선으로(가장 낮은 가중치로) 연결된 정점을 선택하여 트리를 확장한다.\n[3] (n-1)개의 간선을 가질 때까지 반복한다.\n2) code edge 탐색을 위해 min heap 을 이용한 priority queue를 사용합니다. priority queue는 우선 순위가 가장 높은 자료를 가장 먼저 꺼낼 수 있는 자료 구조입니다. python에서는 이를 구현한 heapq 라이브러리가 있습니다. #prim algorithm from collections import defaultdict from heapq import * def prim(first_node, graph): minimum_spanning_tree = [] adjacent_edges = defaultdict(list) for weight, node1, node2 in graph: adjacent_edges[node1].append((weight, node1, node2)) adjacent_edges[node2].append((weight, node2, node1)) connected = set(first_node) candidated_edge = adjacent_edges[first_node] heapify(candidated_edge) while candidated_edge: weight, node1, node2 = heappop(candidated_edge) if node2 not in connected: connected.add(node2) minimum_spanning_tree.append((weight, node1, node2)) for edge in adjacent_edges[node2]: if edge[2] not in connected: heappush(candidated_edge, edge) return minimum_spanning_tree def solution(): graph = [(1,\u0026#39;1\u0026#39;,\u0026#39;2\u0026#39;),(1,\u0026#39;1\u0026#39;,\u0026#39;3\u0026#39;),(1,\u0026#39;2\u0026#39;,\u0026#39;3\u0026#39;),(1,\u0026#39;3\u0026#39;,\u0026#39;4\u0026#39;),(3,\u0026#39;2\u0026#39;,\u0026#39;4\u0026#39;)] return prim(\u0026#39;1\u0026#39;,graph) solution() #결과 : [(1, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;), (1, \u0026#39;1\u0026#39;, \u0026#39;3\u0026#39;), (1, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;)] 참고 자료 [blog] **[알고리즘] 최소 신장 트리(MST, Minimum Spanning Tree)란** [blog] 6-5. 신장 트리와 최소 비용 신장 트리 ","permalink":"http://slow-wave.github.io/post/algorithm/algo_mst_1/","summary":"0. Spanning Tree Spanning Tree란 그래프 내의 모든 정점을 포함하는 트리입니다. 즉, 그래프에서 일부 간선을 선택해서 만든 트리입니다. 이때 그래프에 사이클이 형성이 되면 안됩니다. 연결 그래프에 대한 spanning tree는 여러개 일 수 있습니다.\nn개의 정점을 가지는 그래프의 최소 간선의 수는 (n-1)개이고, (n-1)개로 연결되어 있으면 필연적으로 트리 형태가 되고 이것이 spanning tree가 됩니다. 따라서 spanning tree는 그래프에 있는 n개의 정점을 (n-1)개의 간선으로 연결합니다.\n1. Minimum Spanning Tree (MST) MST는 트리를 구성하는 간선들의 가중치를 합한 것이 최소가 되는 신장 트리이며 다음의 조건을 충족해야합니다.","title":"[algorithm] MST(Minimum Spanning Tree)"},{"content":"0. Intro Data Structure는 데이터를 저장하고 구성하는데 사용하는 저장소입니다. 데이터에 효율적으로 접근하고 업데이트 할 수 있도록 컴퓨터에 데이터를 정렬하는 방법입니다.\nClassification of Data Structure (출처)\nLinear data structure란 데이터 요소가 순차적 또는 선형으로 배열되고 각 요소가 이전 및 다음 요소에 연결된 데이터 구조입니다. linear data structure에는 static과 dynamic 데이터 구조가 있습니다. static data structur의 경우 메모리 크기가 고정되어있고, dynamic data structure의 경우 메모리 크기가 고정되어있지 않습니다.\nNon-linear data structure란 데이터 요소가 순차적 또는 선형으로 배치되지 않은 데이터 구조입니다. 이 구조에서는 단일 실행으로 모든 요소를 순회할 수 없습니다.\n1. stack 2. queue 3. graph graph는 Nodes/Vertices(정점)와 Edges(간선)로 구성된 비선형 데이터 구조입니다. 실생활에서는 네트워크를 나타내는데 사용됩니다.\n0) graph 관련 용어 adjacent vertex(인접 정점) : 간선에 의 해 직접 연결된 정점 degree(정점의 차수) : 무방향 그래프에서 하나의 정점에 인접한 정점의 수 무방향 그래프에 존재하는 정점의 모든 차수의 합 = 그래프의 간선 수의 2배 in-degree : 방향 그래프에서 외부에서 오는 간선의 수 (내차수 라고도 부름) out-degree : 방향 그래픙에서 외부로 향하는 간선의 수 (외차수 라고도 부름) 방향 그래프에 있는 정점의 진입 차수 또는 진출 차수의 합 = 방향 그래프의 간선의 수(내차수 + 외차수) path length(경로 길이) : 경로를 구성하는 데 사용된 간선의 수 simple path (단순 경로) : 경로 중에서 반복되는 정점이 없는 경우 cycle : 단순 경로의 시작 정점과 종료 정점이 동일한 경우 1) graph의 구성 요소 Nodes/Vertices(V)\n그래프의 기본 단위입니다. Edges(E)\nedge를 그리거나 그래프의 두 노드를 연결하는데 사용합니다. 2) graph 구현 Adjacency Matrix\nV x V 크기의 2D 배열임.\n공간을 많이 차지한다는 단점이 있음. O(V^2)\n예시 그림 code\nif __name__ == \u0026#39;__main__\u0026#39;: # n is the number of vertices # m is the number of edges n, m = map(int, input().split()) adjMat = [[0 for i in range(n)]for j in range(n)] for i in range(n): u, v = map(int, input().split()) adjMat[u][v] = 1 adjMat[v][u] = 1 Adjacency List\n배열이 사용되며, 배열의 크기는 node의 수와 같음.\n예시 그림 code\nclass AdjNode: def __init__(self, data): self.vertex = data self.next = None # A class to represent a graph. A graph # is the list of the adjacency lists. # Size of the array will be the no. of the # vertices \u0026#34;V\u0026#34; class Graph: def __init__(self, vertices): self.V = vertices self.graph = [None] * self.V # Function to add an edge in an undirected graph def add_edge(self, src, dest): # Adding the node to the source node node = AdjNode(dest) node.next = self.graph[src] self.graph[src] = node # Adding the source node to the destination as # it is the undirected graph node = AdjNode(src) node.next = self.graph[dest] self.graph[dest] = node # Function to print the graph def print_graph(self): for i in range(self.V): print(\u0026#34;Adjacency list of vertex {}\\n head\u0026#34;.format(i), end=\u0026#34;\u0026#34;) temp = self.graph[i] while temp: print(\u0026#34; -\u0026gt; {}\u0026#34;.format(temp.vertex), end=\u0026#34;\u0026#34;) temp = temp.next print(\u0026#34; \\n\u0026#34;) # Driver program to the above graph class if __name__ == \u0026#34;__main__\u0026#34;: V = 5 graph = Graph(V) graph.add_edge(0, 1) graph.add_edge(0, 4) graph.add_edge(1, 2) graph.add_edge(1, 3) graph.add_edge(1, 4) graph.add_edge(2, 3) graph.add_edge(3, 4) graph.print_graph() # This code is contributed by Kanav Malhotra 3) graph의 종류 Null Graph : edge가 없는 경우 Trivial Graph : 1개의 vertex만 있고 edge가 없는 경우 Undirected Graph : 무방향 그래프 Directed Graph : 방향 그래프 Connected Graph : 모든 node가 연결되어 있음. Disconnected Graph : 1개의 node라도 끊어진 부분이 있음. Regular Graph : 모든 노드의 degree가 그래프의 다른 노드와 동일한 그래프 Complete Graph : 각 노드끼리 연결이 되어있는 그래프 Cycle Graph : 각 vertex의 degree가 2인 경우임. 그래프 전체가 순환됨. Cyclic Graph : 1개의 cycle이라도 존재하는 경우를 뜻함. Directed Acyclic Graph : cycle이 없는 방향 그래프 Bipartite Graph : 각 집합의 꼭짓점에 두 집합 사이의 간선이 포함되지 않도록 꼭짓점을 두 집합으로 나눌 수 있는 그래프 Weighted Graph : 가중치가 존재하는 그래프. 무방향/방향 가중치 그래프가 존재함. 방향을 가진 그래프를 network라고 함. 4) graph의 활용 컴퓨터의 제어 흐름을 나타내는데 사용 OS에서는 resource allocation graph로 사용 경로 최적화, 최단 경로를 찾는데 활용됨 P2P(Peer to Peer) application용 컴퓨터 네트워크에서 사용 DAG(Directed Acyclic Graph)는 가상화폐 기술에도 적용 5) graph의 장단점 장점 최단경로, 노드의 이웃을 쉽게 찾을 수 있음 DFS, BFS, MST와 같은 알고리즘을 구현하는데 사용 비선형 구조로 인해 복잡한 문제와 시각화를 이해하는데 도움이 됨. 단점 메모리 복잡도가 클 수 있음. 그래프의 곱셈 어려움. 4. Tree 0) 정의 트리는 그래프의 한 형태다. 아래는 그래프와 트리를 비교한 표이다.\nGraph Tree Structure vertices/nodes and edges의 집합임. nodes and edges의 집합임. Edges 각 노드는 몇 개의 엣지들을 가질 수 있다. 만약 n개의 노드가 있다면 (n-1)개의 edge를 갖는다. Types of Edges 방향성 or 무방향성을 가짐. 항상 방향성을 가짐. Root node root 존재하지 않음. root(parent)가 존재함. Loop Formation 싸이클이 있을 수 있음. 싸이클 없음. Traversal 그래프 탐색 방법에는 Breadth-First Search (BFS), and Depth-First Search (DFS)가 존재함. 트리 탐색 방법에는 in-order, pre-order, or post-order가 존재함. 1) 트리 탐색 방법 in-order : D → B → A → E → C → F → G pre-order : A → B → D → C → E → F → G post-order : D → B → E → G → F → C → A 이진 트리 탐색 코드 (problem) ## 백준 1991번 import sys def preorderTraversal(root): if root != \u0026#39;.\u0026#39;: sys.stdout.write(str(root)) preorderTraversal(tree[root][0]) preorderTraversal(tree[root][1]) def inorderTraversal(root): if root != \u0026#39;.\u0026#39;: inorderTraversal(tree[root][0]) sys.stdout.write(str(root)) inorderTraversal(tree[root][1]) def postorderTraversal(root): if root != \u0026#39;.\u0026#39;: postorderTraversal(tree[root][0]) postorderTraversal(tree[root][1]) sys.stdout.write(str(root)) if __name__ == \u0026#34;__main__\u0026#34;: N = int(sys.stdin.readline().strip()) tree = {} for n in range(N): root, left, right = sys.stdin.readline().strip().split() tree[root] = [left, right] preorderTraversal(\u0026#39;A\u0026#39;) sys.stdout.write(\u0026#34;\\n\u0026#34;) inorderTraversal(\u0026#39;A\u0026#39;) sys.stdout.write(\u0026#34;\\n\u0026#34;) postorderTraversal(\u0026#39;A\u0026#39;) \u0026#39;\u0026#39;\u0026#39; \u0026lt;input\u0026gt; 7 A B C B D . C E F E . . F . G D . . G . . \u0026#39;\u0026#39;\u0026#39; 참고자료 [intro]\n[geeksforgeeks] Data Structures [graph]\n[geeksforgeeks] Graph Data Structure And Algorithms [geeksforgeeks] Applications, Advantages and Disadvantages of Graph [wiki] 가중그래프 [blog] [자료구조] 그래프(Graph)란 [tree]\n[geeksforgeeks] Difference between graph and tree [blog] 파이썬으로 구현한 자료구조 - 트리 ","permalink":"http://slow-wave.github.io/post/data_structure/data_structure_0/","summary":"0. Intro Data Structure는 데이터를 저장하고 구성하는데 사용하는 저장소입니다. 데이터에 효율적으로 접근하고 업데이트 할 수 있도록 컴퓨터에 데이터를 정렬하는 방법입니다.\nClassification of Data Structure (출처)\nLinear data structure란 데이터 요소가 순차적 또는 선형으로 배열되고 각 요소가 이전 및 다음 요소에 연결된 데이터 구조입니다. linear data structure에는 static과 dynamic 데이터 구조가 있습니다. static data structur의 경우 메모리 크기가 고정되어있고, dynamic data structure의 경우 메모리 크기가 고정되어있지 않습니다.\nNon-linear data structure란 데이터 요소가 순차적 또는 선형으로 배치되지 않은 데이터 구조입니다.","title":"[data structure] 자료구조 정리"},{"content":"Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함. 사람의 시력은 여러 피질 단계로 이뤄져 있고, 각 피질 단계는 점점 더 구조화된 정보를 인식함. 단일 픽셀을 본 후 거기서부터 단순한 기하 형태를 인식하고 물체, 얼굴, 인체, 동물 등과 같이 복잡한 요소를 인식 CNN에서는 완전 연결신경망과 달리 뉴런을 kernel(filter)이라고 함. kernel은 입력 데이터와 합성곱 연산을 수행하게되는 행렬임. convolution 계산을 통해 얻은 출력을 feature map이라고 함. Convolution Layer는 Filter의 크기, Stride, padding 적용 여부, Max Pooling 크기에 따라서 출력 데이터의 Shape이 변경됨. CNN의 구조 이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있음. Convolution Layer와 Pooling Layer를 여러 겹 쌓는 형태로 구성됨. Convolution Layer - 입력데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소임. Pooling Layer - 선택 요소임. Fully Connected Layer Flatten layer - 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데이터를 배열 형태로 만드는 레이어 Convolution 합성곱 연산은 두 함수 f,g 가운데 하나의 함수를 반전(reverse), 전이(shift) 시킨 다음, 다른 하나의 함수와 곱한 결과를 적분하는 것을 의미함. Channel 이미지 픽셀 하나하나는 실수임. 컬러 사진은 천연색을 표현하기 위해, 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터임. Convolution Layer에 유입되는 입력데이터에는 한 개 이상의 필터가 적용됨. 1개 필터는 Feature Map의 채널이 됨. convolution layer에 N개의 필터가 적용된다면 출력데이터는 N개의 채널을 갖게됨. Filter \u0026amp; Stride Filter 이미지의 특징을 찾아내기 위한 공용 파라미터임. 필터는 일반적으로 (4,4)나 (3,3)과 같은 정사각 행렬로 정의됨. CNN에서 학습의 대상은 필터 파라미터임. 하나의 Convolution Layer에 크기가 같은 여러 개의 필터를 적용할 수 있음. → 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature Map의 채널이 됨. 입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 모든 채널의 합성곱의 합을 Feature map(Activation Map)으로 만듦. 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature map의 채널이 됨. Stride 지정된 간격으로 필터를 순회하는 간격을 stride라고 함. padding Convolution layer에서 Filter와 Stride의 작용으로 Feature Map의 크기는 입력데이터보다 작음. 신경망에 Kernel을 적용하면 층이 깊어지면서 데이터의 차원이 줄어듦. → Convolution Layer의 출력 데이터가 줄어드는 것을 방지하는 방법이 padding임. padding은 입력 데이터 주변을 특정값으로 채우는 것을 의미함. 보통 0으로 채워 넣음. 외각을 0 값으로 둘러싸는 특징으로부터 인공 신경망이 이미지의 외각을 인식하는 학습 효과도 있음. padding의 종류 same padding 입력과 feature map의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것임. valid padding padding 없이 순수한 입력 배열에서만 합성곱을 하여 특성맵을 만드는 경우임. → feature map의 크기가 줄어듦. Pooling Layer 데이터의 차원을 줄이거나 특정 데이터를 강조하는 용도로 사용됨. 합성곱에서 stride를 크게 하여 특성맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문임. pooling layer를 통과하면 행렬의 크기 감소 pooling layer를 통해서 채널 수 변경 없음. 학습 대상 파라미터 없음. Pooling의 종류 Max pooling - CNN에서 주로 사용하는 방법 Mean pooling Average Pooling CNN의 구성 Filter, Stride, Padding을 조절하여 특징 추출(feature extraction) 부분의 입출력 크기를 계산하고 맞추는 방법이 중요함. 그림 8: 전형적인 CNN, 출처\n참고 자료 TAEWAN.KIM 블로그(CNN, Convolutional Neural Network 요약) ","permalink":"http://slow-wave.github.io/post/deeplearning/deeplearning_1/","summary":"Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함.","title":"[deeplearing] CNN"},{"content":"데이터베이스 프로그래밍 수업의 내용을 정리한 문서입니다. 시간이 조금 지나고나서야 중요한 내용 임을 깨달아서 예전에 굿노트에 정리했던 것들을 다시 글로 기록하려고 합니다. 더 알고 싶은 부분은 조금 더 파고 들어볼 예정입니다.\n1. DB 기본 개념 1) DB vs. DBMS DB는 저장된 데이터의 모임. 데이터 그 자체 컨텐츠를 의미함. DBMS는 데이터 접근을 위한 프로그램 set임. oracle MS SQL server MySQL MariaDB 2) Typical web-based application architecture [출처]\nClient Tier - Presentation Layer 응용 프로그램의 최상단임 UI 제공 (인터넷 브라우저의 정적 데이터 제공) 주로 web server를 뜻 함 (물리적 WEB server) HTML, Javascript, CSS, Image Application Tier - Business Logic Layer 클라이언트 요청에 대해 마치 서버처럼 행동함 정보 처리의 규칙 존재(주로 동적 데이터임) middleware, backend 주로 application server 뜻함(물리적 WAS server) Data Tier - Data Access Layer DB와 엑세스해서 읽고 쓰고 관리하는 것을 포함 DB server (물리적 DB server) MySQL 3) Rational DB Domain : attribute가 가질 수 있는 값의 집합 Attribute(column) Tuple(record, row) Relation(table) DB - set of relations 4) Schema, Instance Schema : DB의 논리적 구조, 뼈대 Instance : DB의 실제 컨텐츠, DB의 상태 5) Key Key tuple을 구별하기 위한 attribute 집합 Superkey relation에서 unique하게 tuple을 식별할 수 있는 attribute 집합 Candidate Key superkey 중에서 minimal한 key Primary Key candidate key 중 하나 (relation을 정의할 때 선택) entity Integrity : Null이 될 수 없음. Foreign Key 타 relation을 참조하는 attribute referential integrity : 반드시 참조된 relation의 PK 값에 존재하거나 NULL이어야 함. 6) Entity-Relation model ERD entity : 업무상 관리가 필요한 관심사에 해당함. 저장이 되기 위한 어떤 것임. DB design에 사용됨. 7) DB Language DB language는 절차적 언어와 비절차적 언어로 구성되어 있음. Procedural (Relational algebra) Non-procedural (SQL) DDL (data definition language) : db schema를 정의하는 언어 DML (data manipulation language) : db의 data를 조작하는 언어 query DCL (data control language) : db의 constraint를 제어하는 언어 8) SQL (structed query language) relational db의 표준 DDL, DML Integrity(무결성) : 데이터 정확성, 일관성, 유효성이 유지되는 것을 의미함. TCL (Transaction Control Language) view definition authorization 출처 데이터베이스 프로그래밍 수업 메모 what is programming:티스토리 ","permalink":"http://slow-wave.github.io/post/database/db_programming_0/","summary":"데이터베이스 프로그래밍 수업의 내용을 정리한 문서입니다. 시간이 조금 지나고나서야 중요한 내용 임을 깨달아서 예전에 굿노트에 정리했던 것들을 다시 글로 기록하려고 합니다. 더 알고 싶은 부분은 조금 더 파고 들어볼 예정입니다.\n1. DB 기본 개념 1) DB vs. DBMS DB는 저장된 데이터의 모임. 데이터 그 자체 컨텐츠를 의미함. DBMS는 데이터 접근을 위한 프로그램 set임. oracle MS SQL server MySQL MariaDB 2) Typical web-based application architecture [출처]\nClient Tier - Presentation Layer 응용 프로그램의 최상단임 UI 제공 (인터넷 브라우저의 정적 데이터 제공) 주로 web server를 뜻 함 (물리적 WEB server) HTML, Javascript, CSS, Image Application Tier - Business Logic Layer 클라이언트 요청에 대해 마치 서버처럼 행동함 정보 처리의 규칙 존재(주로 동적 데이터임) middleware, backend 주로 application server 뜻함(물리적 WAS server) Data Tier - Data Access Layer DB와 엑세스해서 읽고 쓰고 관리하는 것을 포함 DB server (물리적 DB server) MySQL 3) Rational DB Domain : attribute가 가질 수 있는 값의 집합 Attribute(column) Tuple(record, row) Relation(table) DB - set of relations 4) Schema, Instance Schema : DB의 논리적 구조, 뼈대 Instance : DB의 실제 컨텐츠, DB의 상태 5) Key Key tuple을 구별하기 위한 attribute 집합 Superkey relation에서 unique하게 tuple을 식별할 수 있는 attribute 집합 Candidate Key superkey 중에서 minimal한 key Primary Key candidate key 중 하나 (relation을 정의할 때 선택) entity Integrity : Null이 될 수 없음.","title":"[database] Re-introduction to DB"},{"content":"용어 정리 coinbase : 각 블록의 첫번째 트랜잭션이며 마이닝을 위한 보상. locking script : 출력에 배치되는 지출 조건. unlocking script : 출력을 사용할 수 있도록 하는 스크립트 P2PKH : 비트코인 내에서 가장 일반적인 스크립트 형식으로 거래 유형이다. digital signature : 개인키와 공개키암호를 이용한 전자서명이다. 이를 통해 본인임을 인증하고 수신인은 메세지가 위,변조 되지 않았음을 확인한다. SIGHASH : 데이터 가운데 어떤 부분 확인하고 서명해야하는지 지정해준다. Transaction outputs Transaction output은 불연속적이고 분리할 수 없다는 특징을 갖고 있다. vout이라는 array에 존재한다.\nOutput의 구성요소\n비트코인 양 (사토시로 표시한다.)\nlocking script (비용 지출에 필요한 조건을 결정하는 암호 퍼즐)\nTransaction inputs Transaction input은 어떤 UTXO가 소비될지 식별하며 잠근 해제 스크립트를 통해 소유권 증빙을 제공한다.\ninput의 구성요소 transaction id – 사용하고자하는 UTXO가 들어있는 transaction number vout - 해당 transaction에서 몇번째 output ? scriptSig(unlocking script) – 디지털 서명과 비트코인의 소유권을 증명하는 공개키 sequence number Transaction Serialization outputs \u0026amp; inputs Serialization은 데이터 구조의 내부 표현을 한번에 1byte만큼 전송할 수 있는 형식으로 변환하는 과정이다.\n[output] Amount(8bytes) locking script size(1-9bytes) locking-script(variable) [input] Transaction Hash(32bytes) output index(4bytes) unlocking-script size(1-9bytes) unlocking-script(variable) sequence number(4bytes) Transaction fees 대부분의 거래에는 거래 수수료가 포함되어있다. 거래 수수료는 거래를 다음 블록에 포함시키기위한 보상으로 작용하며, 또 모든 거래에 적은 비용을 부과하면서 시스템이 남용되는 것을 막는다. 수수료는 Transaction의 크기에 기반해 계산된다. 수수료가 높으면 블록에 빠르게 올라간다. (수수료는 우선순위에 영향을 미친다.) 수수료 추정 알고리즘은 경쟁 거래에 의해 제공되는 용량과 수수료에 기초해 계산 수수료 = 입력 – 출력 Transaction scripts and script language UTXO에 배치된 잠금 스크립트와 잠금 해제 스크립트는 모두 script 언어로 작성된다. 트랜잭션이 검증되면 각 입력의 잠금 해제 스크립트가 해당 잠금 스크립트와 함께 실행되어 지출 조건을 충족하는지 확인한다. Turing incompleteness 블록에 조건문, 반복문 등 복잡하게 돌아가는 코드를 포함시키지 않음. Stateless verification 스크립트를 실행하는데 필요한 모든 정보가 스크립트 내에 포함되어있음. Pay-to-Public-Key-Hash (P2PKH) 비트코인 네트워크에서 처리되는 거래는 P2PKH로 출력된다. 이러한 출력안에는 일반적으로 비트코인 주소로 알려진 공개키 해시의 출력을 잠그는 잠금 스크립트가 포함되어있다. P2PKH 스크립트로 잠긴 출력은 해당 개인키로 만든 공개키와 디지털 서명을 제시하면 잠금 해제 할 수 있다. 실행 시 잠금 해제 스크립트가 잠금 스크립트로 설정된 조건과 일치하는 경우에만 인정한다. Digital Signatures(ECDSA) ECDSA는 디지털 서명 알고리즘이다. (Eliptic Curve Cryptography 기반) 기능 (1) 서명은 자신을 증명하는 것이며 자금의 소유자가 지출을 승인함을 입증한다. (2) 서명을 해서 만든 트랜잭션은 내가 보내지 않았다고 부인할 수 없다. (3) 거래에 서명한 후에는 어느 누구도 수정할 수 없으며 수정할 수 없음을 입증한다. How Digital Signatures Work 디지털 서명 구성 Create : 메세지(transaction)와 개인키를 사용해 서명을 만드는 알고리즘 Verfify : 서명을 받는 사람이면 누구나 검증할 수 있는 알고리즘. 디지털 서명 만드는 방법 Fsig는 서명 sig를 생성하는데 이는 R,S로 이루어져 있다. DER 방식으로 인코딩 Verifying the signature 서명을 검증하려면 서명(R \u0026amp; S), serialized transaction, public key, private key가 필요하다. 해당 트랜잭션의 개인키 주인만 트랜잭션을 만들 수 있다. 유효성 검사에서는 메세지가 변형되지 않았다는 것 뿐만 아니라 valid 한지도 확인한다. Signature Hash Types(SIGHASH) 서명은 SIGHASH flag를 사용해 개인키로 서명된 해시에 거래 데이터의 어느 부분이 포함되는지를 나타낸다. ","permalink":"http://slow-wave.github.io/post/blockchain/mastering_bitcoin_ch6/","summary":"용어 정리 coinbase : 각 블록의 첫번째 트랜잭션이며 마이닝을 위한 보상. locking script : 출력에 배치되는 지출 조건. unlocking script : 출력을 사용할 수 있도록 하는 스크립트 P2PKH : 비트코인 내에서 가장 일반적인 스크립트 형식으로 거래 유형이다. digital signature : 개인키와 공개키암호를 이용한 전자서명이다. 이를 통해 본인임을 인증하고 수신인은 메세지가 위,변조 되지 않았음을 확인한다. SIGHASH : 데이터 가운데 어떤 부분 확인하고 서명해야하는지 지정해준다. Transaction outputs Transaction output은 불연속적이고 분리할 수 없다는 특징을 갖고 있다.","title":"[blockchain] ch6. Transactions"},{"content":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Mnemonic codes word : Mnemonic code word는 Deterministic wallet을 도출하기위해 seed로 사용되는 임의의 숫자를 나타내는 단어 순서임. 랜덤 숫자에 비해 읽고 쓰기 쉬움. HD wallet : 비트코인의 BIP32표준으로 정의되어 현재 가장 발전된 형태의 지갑임. 하나의 마스터 시드 키에서 다수의 지갑을 생성할 수 있어 편리함. Nondeterministic Wallet (JBOK wallet, just a bunch of keys) 지갑 안에 있는 키 끼리 연관성 없음. 비트코인 주소가 필요할 때마다 개인키를 랜덤으로 만들어내며 지갑을 주기적으로 백업해야함. 이는 비효율적이므로 테스트 이외의 용도로는 권장되지 않음. Deterministic Wallet 지갑 안에 있는 모든 키는 서로 관련 있음. 개인키는 One-way hash function을 이용해 하나의 seed에서 파생됨. Seed는 BPI-39로 정의되는 Mnemonic code로 부터 만들어짐. Seed는 랜덤으로 생성된 숫자이고 인덱스 번호나 chain code와 결합되어 개인키를 도출함. Seed가 있으면 파생된 모든 키를 복구 할 수 있기 때문에 1번만 백업하면 됨. HD Wallets (BIP-32/BIP-44) Deterministic wallet의 발전된 한 형태임. BIP-32 표준에 의해 정의되고 single root seed로부터 생성됨. 트리 구조이며 트리 구조의 어떤 브랜치에는 성격을 부여할 수 있음. CKD(child key derivation) 함수는 one-hash 함수에 기반하는데 child key를 만들기위해서는 다음의 것이 필요함.\n(1) 부모의 개인키나 공개키\n(2) chain code라고 불리는 seed(256bits)\n(3) index number(32bits) Chain code는 index와 자식키를 아는 것 만으로는 다른 자식 키를 도출할 수 없도록하는데 사용됨. 초기 chain code는 시드로부터 만들어지지만 후속 자식 chain code는 각 부모 chain code로 부터 파생됨. 개인키를 공개하지 않아도 extended public key로부터 많은 공개키를 만들 수 있음. depth가 무한대로 가면 트리 탐색이 어려워짐. 특별한 키를 관리하도록 키에 의미를 부여해줌. BPI-43 : 트리 구조의 목적을 나타내는 특수 식별자를 first hardened child index로 사용함. BPI-44 : m / purpose’ / coin_type’ / account’ / change / address_index Extended keys 확장키는 Key(개인키 or 공개키)와 chain code를 결합한 것임. Base58check를 이용해 인코딩됨. Xpub로 시작하는 키는 웹페이지에 공개될 수 있음. Hardened child key derivation Xpub은 chain code를 포함하므로, 자식 개인키가 유출될 경우 chain code와 함께 사용하여 다른 자식 키들을 모두 유도할 수 있음. 이런 위험에 대처하기위해 부모 공개키와 자식 체인 코드 사이의 관계를 끊는 hardened derivation 함수를 사용함. ","permalink":"http://slow-wave.github.io/post/blockchain/mastering_bitcoin_ch5/","summary":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Mnemonic codes word : Mnemonic code word는 Deterministic wallet을 도출하기위해 seed로 사용되는 임의의 숫자를 나타내는 단어 순서임. 랜덤 숫자에 비해 읽고 쓰기 쉬움. HD wallet : 비트코인의 BIP32표준으로 정의되어 현재 가장 발전된 형태의 지갑임. 하나의 마스터 시드 키에서 다수의 지갑을 생성할 수 있어 편리함. Nondeterministic Wallet (JBOK wallet, just a bunch of keys) 지갑 안에 있는 키 끼리 연관성 없음.","title":"[blockchain] ch5.Wallets"},{"content":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Cryptography : 암호학 Public key : 공개키는 지정된 인증기관에 의해 제공되는 키 값이다. 공개키로부터 생성되는 개인키와 함께 결합되어 메시지 및 전자서명의 암호화와 복원에 사용할 수 있다. Private key : 개인키는 무작위로 추출된 숫자와 문자의 조합으로 이루어진 비밀번호와 같은 기능을 한다. elliptic curve multiplication(ECC, 타원곡선암호기술) : RSA의 대안으로 대두된 이산대수의 난해성에 기반한 공개키 암호화 알고리즘 script : 스택 기반의 프로그래밍 언어이다. 비트코인은 스크립트로 작성된 코드를 읽어 이를 실행하면서 코인 트랜잭션을 수행한다. P2SH(pay to script hash) : 공개키가 아닌 스크립트 해시에 지불하는 개념으로, 하나의 공개키로 해싱하는 것이 아닌 여러 공개키가 함께 해싱하여 출력하는 개념이다. Introduction 비트코인의 소유권은 digital keys, bitcoin addresses, digital signatures을 통해서 구성된다. digital key들은 네트워크에 저장되어있지 않고 파일안에서 소유자들에의해 저장되고 생성되거나 wallet이라고 부르는 단순한 DB에 저장된다. 소유자의 지갑안에있는 digital key들은 비트코인 프로토콜과 완전히 독립되어있으며 블록체인이나 인터넷을 통한 방법 없이 소유자의 지갑에의해 운영되고 생성될 수 있다. Key들에는 분산형 신뢰와 제어, 소유권 증명, 그리고 암호학 증명 안전 모델을 포함한다. 대부분의 비트코인 거래는 유효한 디지털 서명이 블록 체인에 포함되어야 하며, 이것은 비밀 키를 통해서만 생성될 수 있기 때문에, 그 키의 복사본을 가진 사람은 누구나 비트코인을 제어할 수 있다.\n자금을 소비하기위해 사용되는 디지털 서명은 *witness(*증인)라고도 한다. 비트코인 거래에서 witness 데이터는 사용중인 자금의 진정한 소유권을 인정한다. key들은 개인키와 공개키로 구성되는 쌍으로 제공된다. 공개키에 대해서 생각해보면 은행 계좌번호와 비슷하고 개인키는 비밀 PIN 또는 수표의 서명과 비슷하다. 비트코인 거래의 결제 부분에서, 수신자의 공개키는 디지털 지문, 즉 수표의 수익자 이름과 동일한 방식으로 사용되는 비트코인 주소로 보내진다. 대부분의 경우 비트코인 주소는 공개키에서 생성된다. 하지만 비트코인 주소들이 다 공개키를 나타내진 않는다.\n다음과 같은 내용에 대해서 알아볼 것이다.\ncryptography와 비트코인에서 사용되는 수학을 설명 어떻게 Keys가 생성, 저장, 관리되는지 Public key cryptography and cryptocurrency 공개키 암호학은 1970년대에 발명되었으며 정보보안과 컴퓨터를 위한 수학적 기반이다. 공개키 암호학의 발전 덕분에 수학적 함수들이 발견됐는데 이러한 것들을 바탕으로 암호학은 digital secrets와 unforgeable한 디지털 서명의 생성을 가능하게했다. 비트코인은 암호학의 기초로 curve multiplication을 사용한다.\n비트코인에서는 공개키 암호법을 사용하여 비트코인에 대해 엑세스를 제어하는 키 쌍을 만든다. 키 쌍은 개인키와 그로 부터 파생된 unique한 공개키로 구성된다. 공개키는 자금을 받기위해 사용되며 개인키는 자금을 소비하기위해 거래들에 싸인하기위해 사용된다.\n공개키와 개인키 사이에있는 수학적 관계가 있어 개인키를 사용하여 메시지에 서명을 생성할 수 있다. 이 서명은 개인키를 공개하지 않고 공개키에 대해 검증할 수 있다. 공개키와 서명을 통해, 비트코인 네트워크에 있는 모든 사람이 이 거래가 유효한지 확인하고 받아들일 수 있으며, 이는 전송 당시 비트코인을 양도한 사람이 이 거래를 소유하고 있었음을 확인시켜준다.\nPrivate and Public Keys\n비트코인 지갑에는 각각 개인키와 공개키로 구성된 키 쌍이 들어 있다.\n개인키(k)는 일반적으로 무작위로 선택하는 숫자다. 이전 개인키에서 단방향 암호화 함수인 elliptic curve multiplication(타원 곡선 곱셈)을 사용하여 공개키(K)를 생성한다. 공개키(K)에서 단방향 암호화 해시 함수를 사용하여 비트코인 주소(A)를 생성한다.\nPrivate keys\n개인키는 랜덤한 숫자다. 개인 키는 거래에 사용되는 펀드의 소유권을 증명하여 비트코인을 소비하는 데 필요한 서명을 만드는 데 사용된다. 개인키를 제3자에게 공개하는 것은 그들에게 그 키로 확보한 비트코인에 대한 통제권을 주는 것과 같다.\nGenerating a private key from a random number 비트코인 클라이언트로 새 키를 생성하려면 → getnewaddress 비트코인에 개인키 노출 요청 → dumprivkey Public keys 공개키는 되돌릴 수 없는 elliptic curve multiplication을 사용하여 개인키에서 계산된다. elliptic curve multiplication은 \u0026rsquo;trap door\u0026rsquo; 라고 부르는 함수의 한 종류다. 한 방향으로(곱셈)수행이 쉽고 역방향 수행(나누기)이 불가능하다. 개인키의 소유자는 공개키를 쉽게 만든 다음 다른 사람이 공개키에서 개인키를 계산할 수 없다는 것을 알고 다른 사람들과 공유할 수 있다.\nGenerating a public key K=k*G (k = 개인키, G = generator point, K = 결과 공개키이며 곡선의 점.)\n생성기 포인트는 모든 비트코인 사용자에게 항상 동일하기 때문에, 개인키 k에 G를 곱하면 항상 동일한 공개키 K가 된다. K와 K 사이의 관계는 고정적이지만, k에서 K까지 한 방향으로만 계산될 수 있다. 이것이 (K에서 파생된) 비트코인 주소를 누구와도 공유할 수 있고 사용자의 개인키(k)를 공개하지 않는 이유이다. 개인키는 공개키로 변환할 수 있지만 수학은 한가지 방식으로만 작동하므로 공개키는 개인키로 변환할 수 없다.\nBitcoin Addresses 비트코인 주소는 당신에게 돈을 보내기를 원하는 누구와도 공유될 수 있는 숫자와 문자의 연속이다. 공개 키로 생성된 주소는 숫자 \u0026ldquo;1\u0026quot;로 시작하는 일련의 숫자와 문자로 구성된다.\n비트코인 주소는 단방향 암호화 해싱을 통해 공개키에서 파생된다. \u0026ldquo;해싱알고리즘\u0026rdquo; 은 임의의 크기의 입력의 지문이나 \u0026ldquo;해시\u0026quot;를 생성하는 단방향 함수이다. 공개키로 비트코인 주소를 만드는 데 사용되는 알고리즘은 보안 해시 알고리즘(SHA)과 RACE 무결성 기본 요소 평가 메시지 다이제스트(RIPEMD), 특히 SHA256 및 RIPEMD160가 있다.\n비트코인 주소는 거의 항상 \u0026ldquo;Base58Check\u0026quot;로 인코딩되며, checksum을 사용하여 인간의 가독성을 돕고, 모호성을 방지하며, 주소 전사 및 입력의 오류로부터 보호한다.\nBase58 and Base58check encoding Base58은 텍스트 기반 바이너리 인코딩 형식으로, 비트코인에 사용하기 위해 개발되었으며 다른 많은 암호 화폐에 사용된다. 오타나 전사 오류에 대한 보안을 강화하기 위해 Base58Check는 Base58 인코딩 형식으로, 오류 검사 코드가 내장되어 있는 비트코인에 자주 사용된다. checksum은 인코딩 중인 데이터의 끝에 추가된 4bytes이다. checksum은 인코딩된 데이터의 해시로부터 파생되므로 전사 및 입력 오류를 감지하고 방지하는 데 사용할 수 있다.\nPay-to-Script Hash(P2SH) and Multisig Addresses P2SH 주소는 트랜잭션 출력을 사용할 수 있는 사용자를 정의하는 트랜잭션 스크립트에서 생성된다. P2SH 주소 인코딩에는 비트코인 주소 생성 시 사용된 것과 동일한 더블 해시 함수를 사용하는 것이 포함되며, 공용키 대신 스크립트에만 적용된다.\n현재 P2SH 기능의 가장 일반적인 구현은 Multisignature addresses이다. 기본 스크립트는 소유권을 증명하고 따라서 자금을 지출하기 위해 둘 이상의 서명을 필요로 한다.\nVanity addresses vanity 주소는 사람이 읽을 수 있는 메시지를 포함하는 유효한 비트코인 주소이다. vanity 패턴으로 시작하는 주소의 개인 키는 다른 주소보다 쉽게 찾을 수 없다.\n","permalink":"http://slow-wave.github.io/post/blockchain/mastering_bitcoin_ch4/","summary":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Cryptography : 암호학 Public key : 공개키는 지정된 인증기관에 의해 제공되는 키 값이다. 공개키로부터 생성되는 개인키와 함께 결합되어 메시지 및 전자서명의 암호화와 복원에 사용할 수 있다. Private key : 개인키는 무작위로 추출된 숫자와 문자의 조합으로 이루어진 비밀번호와 같은 기능을 한다. elliptic curve multiplication(ECC, 타원곡선암호기술) : RSA의 대안으로 대두된 이산대수의 난해성에 기반한 공개키 암호화 알고리즘 script : 스택 기반의 프로그래밍 언어이다.","title":"[blockchain] ch4.Keys, Addresses"},{"content":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Decentralized : 탈중앙화. 분산된 소규모 단위로 자율적으로 운영되는 것. Mining : 채굴. 암호화폐의 거래내역을 기록한 블록을 생성하고 그 대가로 암호화폐를 얻는 행위. Peer-to-peer network : 인터넷에 연결된 다수의 개별 사용자들이 중개기관을 거치지 않고 직접 데이터를 주고받는 것. Consensus : 악의적인 상황이 발생하더라도 네트워크를 올바른 방향으로 이끌고자 하는 다수의 노드들이 상호 검증을 거쳐 올바른 블록 생성을 이끌어내는 프로세스와 알고리즘. PoW(Proof of Work) : 작업 증명. 최초의 consensus 알고리즘. 블록 생성 시간동안 가장 많은 해시파워를 제공한 노드가 블록을 생성하도록 설계. Introduction 비트코인은 탈중앙화된 신뢰에 기반하며 비트코인에서 신뢰는 다른 참여자들간의 상호작용으로부터 달성된다. 거래가 비트코인 시스템을 통해 추적하고 분산된 합의(distributed consensus)의 메커니즘에 의해 신뢰되고 받아들여지며 최종적으로 모든 transaction의 ledger인 blockchain에 기록되는 것을 관찰할것이다. 비트코인 시스템은 키를 포함한 지갑을 갖고 있는 users, network를 통해 전파되는 transactions, miners 로 구성된다.\nTransaction Inputs and outputs 각 transaction은 하나 이상의 input을 포함하고 있는데 이것은 비트코인 계정에 대한 debit과 같다. transaction의 다른 한 쪽에는 하나 이상의 output이 있는데 이것은 비트코인 계정에 추가된 credit과 같다. input(debit) \u0026amp; output(credit)의 양은 반드시 같지는 않다. transaction은 또한 소유권 증명(proof of ownership)을 포함한다. 비트코인에서 spending은 이전 transaction의 가치를 비트코인 주소로부터 식별된 새로운 소유자에게 이전하는 거래에 서명하는 것이다.\nMaking Change 많은 비트코인 트랜잭션들은 새로운 소유자와 현재 소유자의 주소와 변경 주소 모두를 참조하는 output들을 포함할 것이다. 그 이유는 트랜잭션 input들은 통화 지폐와 같이 나눠질 수 없기 때문이다. 만약 주머니에서 가장 큰 지폐를 사용했다면 잔돈으로 가득찬다. 잔돈만 사용한다면 고액권만 갖게된다. 사람들은 무의식적으로 이 두 극단 사이의 균형을 찾고, 비트코인 지갑 개발자들은 이 균형을 프로그램하기 위해 노력한다.\ntransaction들은 transaction input에서 transaction output으로 값을 이동한다. input은 이전 transaction의 output의 참조로, 값이 어디서 왔는지 보여준다. 가치가 소유자에서 소유자로 이동될 때 chain of ownership을 만든다.\nCommon Transaction Forms 가장 일반적인 형태는 한 주소에서 다른 주소로의 지불 원래 소유자에게 반환된 \u0026lsquo;변경\u0026rsquo;을 포함한다. 이런 형식의 transaction은 하나의 input과 두개의 output을 가지고 있다. 여러 입력을 하나의 단일 output으로 통합 하나의 input을 여러 수신자를 나타내는 다량의 ouput에 분배하는 거래 Constructing a transaction-Getting the Right inputs fully-node client로 운영되는 비트코인 지갑은 블록체인 상의 모든 사용되지 않은 output의 복사본을 포함한다.\nAdding the Transaction to the ledger-Transmitting the transaction 트랜잭션이 진행되는데 필요한 모든 정보를 가지고 있기 때문에 비트코인 네트워크에서 어떻게 그리고 어디서 전송되는지는 상관할 바가 아니다.\n비트코인 네트워크는 peer-to-peer 네트워크이다. 비트코인 네트워크의 목적은 거래와 블록을 모든 참가자들에게 전파하는 것이다.\nHow it propagates 비트코인 네트워크에 참여하는 모든 시스템은 비트코인 노드라고 한다. 이전에 보지 못한 유효한 트랜잭션을 수신하는 모든 비트코인 노드는 \u0026lsquo;flooding\u0026rsquo;으로 알려진 전파기술을 통해 연결된 모든 다른 노드로 바로 포워딩된다.\nBitcoin Mining Alice의 transaction은 비트코인 네트워크에서 전파되고 있다. mining이라고 불리는 과정을 통해 검증되고 블럭에 포함되기 전까지는 블록체인의 일부가 되지 않은 것이다. 트랜잭션은 블록으로 번들되는데, 이를 증명하려면 엄청난 양의 계산이 필요하지만 입증된 대로 검증하는데는 적은 양의 연산만 필요하다.\nmining 과정은 비트코인에서 두가지 목적으로 사용된다.\nmining nodes가 비트코인의 \u0026lsquo;consensus rules(합의 규칙)\u0026lsquo;을 참조하여 모든 거래들을 검증한다. mining은 유효하지 않거나 잘못된 거래들을 거절함으로써 비트코인 거래들에 보안을 제공한다. 거의 중앙 은행이 새로운 돈을 발행하는 것과 같이 각 블록에 새로운 비트코인을 만든다. 블록당 생성되는 비트코인의 양은 제한되어있으며, 정해진 발행 일정에 따라 시간이 지남에 따라 감소한다. mining은 비용과 보상 사이에서 좋은 균형을 이룬다. 성공적인 miner는 새로운 비트코인과 거래 수수료의 형태로 보상을 수집할 것이다. 그러나 보상은 miner가 합의 규칙을 만족시키기 위해 모든 거래를 올바르게 검증한 경우에만 수집될 것이다. 이 사소한 균형은 중앙의 권위없이 비트코인의 보안을 제공한다.\n비트코인에 사용되는 \u0026lsquo;퍼즐\u0026rsquo;은 암호화 그래픽 해시를 기반으로 하며, 비대칭적으로 해결하기 어렵지만 검증하기 쉽고, 난이도 조정이 가능하다는 유사한 특징을 보인다. PoW를 위한 알고리즘은 솔루션이 사전결정된 패턴과 일치하는 솔루션이 나타날 때까지 SHA256 암호화 그래픽 알고리즘으로 블록 헤더와 난수를 반복 해시하는 것을 포함한다. 이러한 솔루션을 최초로 발견한 마이너는 경쟁에서 이겨 해당 블록을 블록체인에 게시한다. 더 많은 miner들이 비트코인 네트워크에 참여하기시작할수록 문제의 어려움은 급격히 증가한다.\nMining Transactions in Blocks 마이너는 새 블록을 구성할 때 이 풀에서나온 비식별된 거래들을 새로운 블럭에게 더하고 PoW 마이닝 알고리즘을 활용해 새로운 블럭의 유효성을 검증한다.\nSpending the Transaction 각 비트코인 클라이언트는 거래가 유효하고 사용가능한지를 확인할 수 있다. lightweight 클라이언트들은 거래가 블록체인에 있고 그 후에 채굴된 여러 블록을 가지고 있다는 것을 확인함으로써 소위말하는 단순결제검증(Simplified Payment Verification)을 수행할 수 있으며, 채굴자들이 이를 유효하다고 보장할 수있다.\n출처 해시넷 [책] Mastering Bitcoin: Programming the Open Blockchain 2nd Edition ","permalink":"http://slow-wave.github.io/post/blockchain/mastering_bitcoin_ch2/","summary":"Mastering Bitcoin: Programming the Open Blockchain 2nd Edition 책을 정리한 내용입니다.\n용어 정리 Decentralized : 탈중앙화. 분산된 소규모 단위로 자율적으로 운영되는 것. Mining : 채굴. 암호화폐의 거래내역을 기록한 블록을 생성하고 그 대가로 암호화폐를 얻는 행위. Peer-to-peer network : 인터넷에 연결된 다수의 개별 사용자들이 중개기관을 거치지 않고 직접 데이터를 주고받는 것. Consensus : 악의적인 상황이 발생하더라도 네트워크를 올바른 방향으로 이끌고자 하는 다수의 노드들이 상호 검증을 거쳐 올바른 블록 생성을 이끌어내는 프로세스와 알고리즘.","title":"[blockchain] ch2. How bitcoin works"},{"content":"다음은 블록체인에 대한 기본적인 개념을 이해할 수 있었던 But how does bitcoin actually work? 영상을 보고 정리한 내용입니다.**\n블록체인을 소유하고 있는건 어떤 의미일까? 비트코인을 만든다면?\n먼저 친구들과의 금전 거래 내역을 공동의 장부에 기록한다. 장부를 믿으면 되니깐, 친구들과 세상에 대한 신뢰의 필요성은 점점 줄어든다. 신뢰가 없어도 장부로 거래를 운영할 수 있다면 그걸 암호화 화폐라고 부르지 않을까?\n비트코인 = 최초의 암호화 화폐 은행 대신에 암호학에서 탄생된 몇 가지 수학 원리를 이용해서 거래 주체들 사이에 신뢰가 필요하지 않은 똑똑한 분산 확인 시스템이 있다.\n장부(ledger)와 디지털서명(digital signature) 돈을 주고 받을 때는 누구나 볼 수 있는 공동 장부에 기록한다. 그리고 모두 모여서 거래 내역을 보고 정산을 한다.\n이 시스템의 프로토콜을 간단히 정리하면 다음과 같다.\n누구든 장부에 기록 가능하다. 매달 말 일에 모여서 정산한다. 문제점1. 아무나 기록할 수 있다. 공동 장부에 기록된 내용들이 돈을 보내는 사람의 의도대로 진실되게 기록되어있다는 것을 어떻게 믿을 수 있을까? ⇒ 디지털 서명\n돈을 보낸다는 거래 기록에 서명 같은 효과를 가지는 무언가를 추가할 수 있어야한다. 물론 위조도 불가능해야한다.\n위조를 막기위해서는 private key - public key를 생성한다. 디지털 서명은 보통 256개의 0과 1의 조합으로 만들어진 하나의 값이다. (디지털 서명의 값 = 문서의 내용 + 비밀키를 조합하는 함수에 의해 만들어짐.) →누군가 디지털 서명값을 훔쳐도 다른 문서에 대한 증표로는 사용될 수 없음.\n디지털 서명과 관련된 두번째 함수는 디지털 서명값이 유효한지 확인하는데 사용된다. 두번째 함수는 단순하게 참 또는 거짓만을 결과값으로 반환한다. 비밀키를 모른다면 유효한 디지털 서명값을 찾아낼 수 없다. 비밀키를 모르면 아무 값이나 디지털 서명값으로 정하고, 공개키와 함께 계산해서 디지털 서명값이 유효한지 확인하는 것을 반복하는 것 외에는 방법이 없다. 이 경우의 수는 2^256 개이므로 디지털 서명값이 유효하다고 확인되는 것은 충분히 확신해도 된다.\n문제점2. 디지털 서명값을 위조할 수는 없지만, 동일한 거래 내역 자체는 여러번 복사할 수 있다. → 메시지에 거래별로 유일한 식별자인 ID값을 포함해야한다. 그렇게하면 메시지 내용이 다르므로 디지털 서명값도 달라져 복사해도 다른 곳에 쓸 수 없게 된다.\n문제점3. 어떤 사람이 수천 달러 지불한다는 거래기록을 장부에 남기고 먹튀를 한다면? → 자기들이 미리 적립해둔 금액 이상으로는 지출할 수 없게 한다. → 그 시점까지의 거래 내역 전부를 알아야만 한다는 제약이 생긴다.\n장부는 해당 통화의 모든 거래 이력만을 가지고 있을 뿐, 환전을 기록하지는 않는다. 비트코인에서도 사람들이 현금으로 비트코인을 사더라도, 장부에 실질적인 돈이 들어오는 것은 아니다.\n장부에 새로운 내용을 추가하는 것도 중앙의 누군가가 통제하는 걸까? 중앙의 누군가에게 의지하지 않으려면 모든 사람들이 장부의 복사본을 가지고 있어야된다. 장부를 가지고 있는 모든 사람들에게 거래를 알려야한다. 문제점4. 수많은 장부 중에서 어떤 장부가 올바른 장부인지를 어떻게 알 수 있을까? 우리 뿐만아니라 다른 모든 사람들도 똑같은 거래를 똑같은 순서로 그들의 장부에 기록해서 모든 사람들의 장부 내용이 언제나 완전히 같다는 것을 확신할 수 있을까? → 가장 많은 계산 작업을 포함하는 장부가 신뢰할만한 좋은 장부다. (암호화 해쉬함수) 무엇을 신뢰할 것인가를 판단하는 기준을 계산 작업에 둔다면, 거래 내역을 속이거나 장부의 충돌을 막기위해서는 정해진 시간 내에 처리가 불가능할만큼 엄청난 양의 계산이 필요하게 만들 수 있다.\n매직넘버를 찾아내는 일은 엄청난 계산이 필요하지만 매직 넘버가 맞는 값인지 확인하는 것은 별로 많은 양의 계산이 필요하지 않다.\n→ 작업 증명 (PoW)\n비트코인 논문의 핵심 아이디어는 장부를 가진 모든 사람들은 가장 많은 계산 작업이 포함된 장부를 믿으면 된다는 것이다. 장부는 블록 단위로 나누어서 구성되어있고, 블록에는 일정한 수의 거래 내역이 작업증명(매직넘버)과 함께 담겨 있으며 그 블록의 해쉬값은 정해진 만큼의 여러 자리수의 0으로 시작한다.\n거래는 지불하는 송금자의 디지털 서명이 있어야만 유효한 거래로 인식되는 것처럼 블록도 마찬가지로 작업 증명이 있어야만 유효한 블록으로 인식될 수 있다. 더 나아가서 블록들의 순서까지 보장하려면 각 블록이 자기보다 앞에있는 이전 블록의 해쉬값을 포함하게하면된다.\n→ 블록은 이렇게 앞의 블록의 해쉬값을 통해 앞뒤가 연쇄적으로 연결되어있기 때문에 그냥 장부라고 부르지 않고 블록체인이라고 한다.\n체인을 이루도록 변경된 규약에 의해, 이제는 누구든지 블록을 생성할 수 있게되었다. 누구든지 브로드캐스팅 되는 거래 정보를 접수하고 접수한 거래 정보를 모아서 블록을 만들고 그 블록의 해쉬값이 60개의 0으로 시작하게하는 매직 넘버를 찾기 위해 엄청난 양의 계산작업을 수행하고 마침내 그 매직 넘버를 찾아내서 그 블록을 브로드캐스팅하면 블록의 생성자가 된다.\n블록 보상 블록을 생성하고 보상을 받는 것을 채굴이라고 한다. 채굴자들이 실제로 하는 일은 브로드캐스팅 되는 거래 정보를 수집하고, 블록을 새로 생성해서, 생성한 새 블록을 다시 브로드캐스팅하고 보상을 받는 일이다. ","permalink":"http://slow-wave.github.io/post/blockchain/blockchain_intro/","summary":"다음은 블록체인에 대한 기본적인 개념을 이해할 수 있었던 But how does bitcoin actually work? 영상을 보고 정리한 내용입니다.**\n블록체인을 소유하고 있는건 어떤 의미일까? 비트코인을 만든다면?\n먼저 친구들과의 금전 거래 내역을 공동의 장부에 기록한다. 장부를 믿으면 되니깐, 친구들과 세상에 대한 신뢰의 필요성은 점점 줄어든다. 신뢰가 없어도 장부로 거래를 운영할 수 있다면 그걸 암호화 화폐라고 부르지 않을까?\n비트코인 = 최초의 암호화 화폐 은행 대신에 암호학에서 탄생된 몇 가지 수학 원리를 이용해서 거래 주체들 사이에 신뢰가 필요하지 않은 똑똑한 분산 확인 시스템이 있다.","title":"[blockchain] blockchain의 개념"},{"content":"[Leetcode] 21. Merge Two Sorted Lists 문제 링크\n이 문제는 제목 그대로 2개의 리스트를 정렬해서 결합하는 문제입니다. 구현되어있는 ListNode class를 이용해서 mergeTwoLists method를 완성하면 됩니다.\n풀이 과정 다음의 조건을 갖고 있다고 가정하고 실행 과정을 정리해보겠습니다.\n# Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next a = [1,2,4] b = [1,3,4] dummy = cur = ListNode(0) Code (python) # Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next class Solution: def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -\u0026gt; Optional[ListNode]: dummy = cur = ListNode(0) while list1 and list2: if list1.val \u0026lt; list2.val: cur.next = list1 list1 = list1.next else: cur.next = list2 list2 = list2.next cur = cur.next cur.next = list1 or list2 return dummy.next 자료 [1] python 변수 할당의 개념\n[2] Leetcode solution 1\n","permalink":"http://slow-wave.github.io/post/problem_solving/ps_linkedlist_1/","summary":"[Leetcode] 21. Merge Two Sorted Lists 문제 링크\n이 문제는 제목 그대로 2개의 리스트를 정렬해서 결합하는 문제입니다. 구현되어있는 ListNode class를 이용해서 mergeTwoLists method를 완성하면 됩니다.\n풀이 과정 다음의 조건을 갖고 있다고 가정하고 실행 과정을 정리해보겠습니다.\n# Definition for singly-linked list. # class ListNode: # def __init__(self, val=0, next=None): # self.val = val # self.next = next a = [1,2,4] b = [1,3,4] dummy = cur = ListNode(0) Code (python) # Definition for singly-linked list.","title":"[Leetcode] Linked List 1 - 21. Merge Two Sorted Lists"},{"content":" Web개발의 이해 1-1. HTTP 프로토콜의 이해 1-2. browser의 동작 1-3. 웹서버 1-4. WAS \u0026lsquo;[boostcourse 웹프로그래밍 풀스택]은\u0026rsquo; 네이버 부스트코스의 “웹프로그래밍(풀스택)” 강의를 듣고 공부한 내용을 정리한 시리즈입니다. 일단 저는 Spring 프레임워크를 배워보고 싶어서 이 강의를 수강하게 되었습니다. 전공 공부를 할 때 프로그래밍 언어나 프레임워크 등을 익히는데 가장 효과적이고 재밌었던 방법은 직접 구현 해보는 방법이었습니다. 저는 Node.js 프레임워크와 Java, Javascript 언어를 공부한 경험이 있어서 (기억은 가물가물하지만;) 해당 강의 수강에 도전하게 되었습니다.\n깊게 설명해주시는 것은 아니지만 관련해서 공부하면 좋을 주제들을 많이 던져주는 강의라고 생각합니다. 그래서 원래 강의안의 전체적인 구조를 그대로 가져오되, 개인적으로 깊게 파고 들어본 내용을 더해서 정리하려고 합니다.\n1-1. HTTP 프로토콜의 이해 HTTP (Hypertext Transfer Protocol) 정의 HTTP는 서버와 클라이언트가 인터넷 상에서 데이터를 주고받기 위한 프로토콜입니다. 프로토콜은 상호 간에 정의한 규칙을 의미하며 특정 기기 간에 데이터를 주고받기 위해 정의되었습니다. 오늘날에는 거의 모든 파일 형식을 HTTP 형식을 이용해 전송 가능합니다.\nHTTP 특징 HTTP 통신은 connectionless를 기본 동작으로 가집니다. connection을 유지하게되면 지속적으로 resource가 사용되기 때문입니다. 따라서 connection 유지는 최소화되는 것이 좋습니다.\nHTTP 작동 방식 HTTP 프로토콜로 데이터를 주고 받기 위해서는 Request를 보내고 Response를 받아야합니다. Client는 요청을 보내는 쪽을 의미하며 웹 관점에서는 브라우저를 의미합니다. Server는 요청을 받는 쪽을 의미하며 일반적으로 데이터를 보내주는 원격지의 컴퓨터를 의미합니다.\nServer-Client 모델 Server-Client는 1:N 구조로 연결되어 있으며 클라이언트의 요청이 있을 때 서버가 응답하는 단방향 통신입니다. 즉, 한 대의 서버에 다수의 클라이언트가 접속하여 서비스를 이용합니다. 다수의 사용자들이 공동으로 열람·복사·수정·관리하는 데이터를 여러 곳에 분산시키지 않고 단일한 중앙 서버에 저장하여 관리함으로써 데이터의 유일성과 통일성을 보장할 수 있습니다.\nHTTP 프로토콜로 클라이언트가 서버에 요청을 보내고 성공적으로 데이터를 받게되면 동시에 서버와의 연결이 해체되고 보내진 데이터의 결과도 동시에 잃어버리게 됩니다. 이를 Stateless protocol 이라고 부르며 문제를 해결하기 위해 cookie, session, token 기술이 등장했습니다.\nClient란? 네트워크를 이용하여 서버 시스템에 연결된 PC나 스마트폰 등 사용자 측을 의미합니다. Client는 서버에서 받아온 데이터를 단말기 화면에 표시하고 사용자의 요청을 서버에 전달하기 위해 웹브라우저를 사용합니다.\nserver란? 통신망 상에서 다른 컴퓨터에 대해서 회선, 디스크 장치에 대한 접속을 제어하는 소프트웨어 혹은 컴퓨터입니다. web server, WAS, DB server 등이 있습니다.\n참고 자료 [1] 프런트엔드 개발자가 알아야하는 HTTP 프로토콜 Part 1\n[2] 서버-클라이언트\n[3] Http Stateless / cookie / session / token\n[4] Client-Server Model\n[5] HTTP(Hypertext Transfer Protocol)의 특징\n","permalink":"http://slow-wave.github.io/post/fullstack_boostcourse/web_boostcourse_0/","summary":"Web개발의 이해 1-1. HTTP 프로토콜의 이해 1-2. browser의 동작 1-3. 웹서버 1-4. WAS \u0026lsquo;[boostcourse 웹프로그래밍 풀스택]은\u0026rsquo; 네이버 부스트코스의 “웹프로그래밍(풀스택)” 강의를 듣고 공부한 내용을 정리한 시리즈입니다. 일단 저는 Spring 프레임워크를 배워보고 싶어서 이 강의를 수강하게 되었습니다. 전공 공부를 할 때 프로그래밍 언어나 프레임워크 등을 익히는데 가장 효과적이고 재밌었던 방법은 직접 구현 해보는 방법이었습니다. 저는 Node.js 프레임워크와 Java, Javascript 언어를 공부한 경험이 있어서 (기억은 가물가물하지만;) 해당 강의 수강에 도전하게 되었습니다.\n깊게 설명해주시는 것은 아니지만 관련해서 공부하면 좋을 주제들을 많이 던져주는 강의라고 생각합니다.","title":"[boostcourse 웹프로그래밍 풀스택] 1-1. HTTP 프로토콜의 이해"},{"content":"[programmers] 순위 (문제 링크) 이 문제는 그래프로 분류되어 있습니다. 어떻게 그래프로 접근해야하는지 아이디어가 생각나지 않아서 어려웠던 문제입니다. 구글링을 해봤을 때 플로이드 와샬(Floyd-Warshall) 알고리즘을 이용해서 구현을 하신 답안이 많았지만 DFS로 구현했습니다. 플로이드 와샬의 경우 각 정점에서 다른 모든 정점까지의 최단경로를 구할 수 있는 알고리즘인데 이보다는 DFS가 효율적이라고 생각했습니다. 실제로 플로이드 와샬의 시간 복잡도는 O(n^3)입니다.\n풀이 방법 n = 5 results = [[4, 3], [4, 2], [3, 2], [1, 2], [2, 5]] results의 정보를 가지고 확실한 순위를 알 수 있는 노드의 수를 찾아내는 문제입니다. 자기 자신을 제외하고 모든 노드에 대해서 승패 여부를 알 수 있을 때만 확실한 순위를 알 수 있습니다.\n만약 5번 노드가 1~4번 노드에 대해서 패배했다면 순위는 5위가 됩니다. 만약 2번 노드가 1,3,4에게 패배하고 5에게 승리했다면 순위는 4위가 됩니다.\n따라서 주어진 정보를 가지고 노드 전체에 대한 승패를 표시하면 답을 구할 수 있습니다.\n자세한 풀이 과정은 다음과 같습니다. 최종 graph의 형태는 다음과 같습니다. 확실한 순위를 알 수 있는 노드는 2,5번으로 총 2개 입니다.\nCode (python) def dfs(graph): #1~N번 노드에 대해서 for target in range(1,n+1): #target 노드가 이긴 노드들을 담음 stack = [i for i, rst in enumerate(graph[target]) if rst == 1] while stack: lose = stack.pop() for i, rst in enumerate(graph[lose]): # a \u0026gt; b and b \u0026gt; c 면 a \u0026gt; c 임으로 이를 표시함. if not graph[target][i] and rst == 1: graph[target][i], graph[i][target] = 1, -1 stack.append(i) return graph def solution(n,results): answer = 0 #승패를 기록하는 graph 생성 graph = [[0]*(n+1) for _ in range(n+1)] #승패 기록 for win, lose in results: graph[win][lose] = 1 graph[lose][win] = -1 graph = dfs(graph) for i in range(1,n+1): #자기 자신을 제외하고 모든 노드에 승패 표시가 되어있다면 if graph[i][1:].count(0) == 1: answer += 1 return answer ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_bfs_dfs_3/","summary":"[programmers] 순위 (문제 링크) 이 문제는 그래프로 분류되어 있습니다. 어떻게 그래프로 접근해야하는지 아이디어가 생각나지 않아서 어려웠던 문제입니다. 구글링을 해봤을 때 플로이드 와샬(Floyd-Warshall) 알고리즘을 이용해서 구현을 하신 답안이 많았지만 DFS로 구현했습니다. 플로이드 와샬의 경우 각 정점에서 다른 모든 정점까지의 최단경로를 구할 수 있는 알고리즘인데 이보다는 DFS가 효율적이라고 생각했습니다. 실제로 플로이드 와샬의 시간 복잡도는 O(n^3)입니다.\n풀이 방법 n = 5 results = [[4, 3], [4, 2], [3, 2], [1, 2], [2, 5]] results의 정보를 가지고 확실한 순위를 알 수 있는 노드의 수를 찾아내는 문제입니다.","title":"[programmers] DFS/BFS 4- 순위"},{"content":"[백준] 2667번 단지 번호 붙이기 (문제 링크) 풀이 방법 graph에서 연결 요소(connected component)의 수를 찾고 연결 요소 안의 node 수를 카운트하는 문제입니다. deque로 BFS를 구현해서 해결했습니다.\n[0] graph와 (x,y) 좌표의 방문 여부를 표시하는 visited (list)를 생성합니다.\n[1] graph 전체를 순회하면서 graph(x,y) 값이 1인 경우에 bfs 함수를 실행합니다.\n[1-1] (x,y)를 push한 queue를 생성합니다. [1-2] queue에서 원소를 pop 합니다. [1-3] pop한 원소를 기준값으로 해서 상하좌우를 살핍니다. 만약 값이 1이고 아직 방문하지 않았다면 push 하고, 방문 표시합니다. *이 과정은 빈 queue가 될 때까지 반복합니다. [2] bfs 함수가 실행된 횟수와 bfs 함수 내부에서 queue에 좌표를 push 할 때마다 count한 횟수를 출력합니다.\nCode (python) from collections import deque def bfs(root): #단지 내의 apt 수 저장하는 변수 cnt = 1 queue = deque([root]) #queue에 원소가 있는 동안 while queue: #x,y pop x,y = queue.popleft() #(x,y)를 기준으로 상,하,좌,우 확인 for i in range(4): nx = x + dx[i] ny = y + dy[i] #만약 nx,ny가 범위값 밖에 있다면 continue if nx \u0026lt; 0 or ny \u0026lt; 0 or nx \u0026gt;= n or ny \u0026gt;= n: continue #graph(nx,ny)값이 1이고 아직 방문하지 않았다면 if graph[nx][ny]==1 and not visited[nx][ny]: #방문 표시 visited[nx][ny] = True #stack에 표시 queue.append((nx,ny)) #apt 수 증가 cnt += 1 return cnt #입력 n = int(input()) graph,result = [],[] for _ in range(n): line = input() graph.append([int(i) for i in line]) #방문 표시 리스트 생성 visited = [[False]*n for i in range(n)] #상하좌우 이동을 위한 dx,dy 좌표 dx = [1, -1, 0, 0] dy = [0, 0, -1, 1] #graph의 모든 좌표에 대해서 확인 for x in range(n): for y in range(n): #만약 graph(x,y)값이 1이고 아직 방문하지 않았다면 if graph[x][y] == 1 and not visited[x][y]: #방문 표시 visited[x][y] = True #반환되는 단지 내의 apt 수를 저장 apt_n = bfs((x,y)) #result 리스트에 더함 result.append(apt_n) #오름차순으로 정렬 result.sort() #총 apt 단지 수 출력 print(len(result)) #단지 내의 아파트 수 출력 print(*result, sep=\u0026#39;\\n\u0026#39;) ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_bfs_dfs_2/","summary":"[백준] 2667번 단지 번호 붙이기 (문제 링크) 풀이 방법 graph에서 연결 요소(connected component)의 수를 찾고 연결 요소 안의 node 수를 카운트하는 문제입니다. deque로 BFS를 구현해서 해결했습니다.\n[0] graph와 (x,y) 좌표의 방문 여부를 표시하는 visited (list)를 생성합니다.\n[1] graph 전체를 순회하면서 graph(x,y) 값이 1인 경우에 bfs 함수를 실행합니다.\n[1-1] (x,y)를 push한 queue를 생성합니다. [1-2] queue에서 원소를 pop 합니다. [1-3] pop한 원소를 기준값으로 해서 상하좌우를 살핍니다. 만약 값이 1이고 아직 방문하지 않았다면 push 하고, 방문 표시합니다.","title":"[백준] DFS/BFS 3- 2667번 단지 번호 붙이기"},{"content":"[백준] 2178번 미로탐색 (문제 링크) 풀이 방법 (1,1) ~ (N,M) 까지의 최단 경로를 구하는 문제이므로 BFS를 활용해서 구현합니다. 이 문제에서 BFS를 활용하여 구현하는 이유는 다음과 같습니다.\nCode (python) from collections import deque def bfs(root): queue = deque([root]) #큐를 생성해서 root push while queue: x,y = queue.popleft() #pop - 기본 좌표가 나옴 #상하좌우 이동 for i in range(4): nx = x + dx[i] ny = y + dy[i] #좌표 밖을 벗어나면 넘어감 if nx \u0026lt; 0 or ny \u0026lt; 0 or nx \u0026gt;= N or ny \u0026gt;= M: continue if graph[nx][ny] == 1: #만약 이동한 좌표의 값이 1이라면 graph[nx][ny] = graph[x][y] + 1 #이동한 좌표의 값에 기본 좌표 값에 1을 더함 queue.append([nx,ny]) #좌표를 queue에 push return graph[N-1][M-1] #도착 지점 좌표의 값을 리턴함 graph,root = [],[0,0] N,M = map(int,input().split()) #graph 만들기 for i in range(N): line = input() graph.append([int(i) for i in line]) #좌표 상화좌우 이동을 위한 dx,dy dx = [-1,1,0,0] dy = [0,0,-1,1] print(bfs(root)) ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_bfs_dfs_1/","summary":"[백준] 2178번 미로탐색 (문제 링크) 풀이 방법 (1,1) ~ (N,M) 까지의 최단 경로를 구하는 문제이므로 BFS를 활용해서 구현합니다. 이 문제에서 BFS를 활용하여 구현하는 이유는 다음과 같습니다.\nCode (python) from collections import deque def bfs(root): queue = deque([root]) #큐를 생성해서 root push while queue: x,y = queue.popleft() #pop - 기본 좌표가 나옴 #상하좌우 이동 for i in range(4): nx = x + dx[i] ny = y + dy[i] #좌표 밖을 벗어나면 넘어감 if nx \u0026lt; 0 or ny \u0026lt; 0 or nx \u0026gt;= N or ny \u0026gt;= M: continue if graph[nx][ny] == 1: #만약 이동한 좌표의 값이 1이라면 graph[nx][ny] = graph[x][y] + 1 #이동한 좌표의 값에 기본 좌표 값에 1을 더함 queue.","title":"[백준] DFS/BFS 2- 2178번 미로탐색"},{"content":"[백준] 1260번 DFS와 BFS (문제 링크) 기본적인 그래프 탐색 문제 입니다. DFS는 stack을 활용해서 구현하고, BFS는 queue를 활용해 구현합니다.\n방문할 수 있는 정점이 여러 개인 경우 숫자가 적은 것을 먼저 방문하라는 조건을 고려해야 합니다!\n풀이 방법 Graph \u0026lt;input\u0026gt; 4 5 1 1 2 1 3 1 4 2 4 3 4 위의 testcase로 만들어진 그래프의 모양은 다음과 같습니다.\nDFS 방식으로 그래프 탐색 stack 자료구조에서 pop을 하면 나중에 들어온 것이 먼저 나옵니다.\n인접한 node를 push 할 때 내림차순 정렬해서(3 → 2) 숫자가 작은 node가 먼저 pop 되게 합니다.\nBFS 방식으로 그래프 탐색 queue에서 pop을 하면 처음에 들어온 것이 먼저 나갑니다.\n인접한 node를 push 하기 전에 오름차순 정렬해서(2 → 3) 숫자가 작은 node가 먼저 pop 되게 합니다.\nCode (python) from collections import deque import sys #DFS def DFS(graph, root, visited =[]): stack = [root] #stack을 생성하고 root push while stack: n = stack.pop() if n not in visited: visited.append(n) #visited에 표시 if n in graph: temp = list(set(graph[n]) - set(visited)) temp.sort(reverse = True) #내림차순으로 졍럴 - stack의 Top에 숫자가 작은 것이 위치하게된다. stack += temp #stack에 push return \u0026#34; \u0026#34;.join(str(i) for i in visited) #BFS def BFS(graph, root, visited = []): queue = deque([root]) #queue를 생성하고 root push while queue: n = queue.popleft() if n not in visited: visited.append(n) #visited에 표시 if n in graph: temp = list(set(graph[n]) - set(visited)) temp.sort() #오름차순으로 졍럴 - queue의 Bottom에 숫자가 작은 것이 위치하게된다. queue += temp #queue에 push return \u0026#34; \u0026#34;.join(str(i) for i in visited) input = sys.stdin.readline #N,M,V 입력 받기 N, M, V = map(int,input().split()) #그래프 만들기 - 각 노드마다 연결된 노드를 표시해준다. graph = {} for i in range(M): n1, n2 = map(int,input().split()) graph[n1] = graph.get(n1,[]) + [n2] graph[n2] = graph.get(n2,[]) + [n1] print(DFS(graph, V)) print(BFS(graph, V)) ","permalink":"http://slow-wave.github.io/post/problem_solving/ps_bfs_dfs_0/","summary":"[백준] 1260번 DFS와 BFS (문제 링크) 기본적인 그래프 탐색 문제 입니다. DFS는 stack을 활용해서 구현하고, BFS는 queue를 활용해 구현합니다.\n방문할 수 있는 정점이 여러 개인 경우 숫자가 적은 것을 먼저 방문하라는 조건을 고려해야 합니다!\n풀이 방법 Graph \u0026lt;input\u0026gt; 4 5 1 1 2 1 3 1 4 2 4 3 4 위의 testcase로 만들어진 그래프의 모양은 다음과 같습니다.\nDFS 방식으로 그래프 탐색 stack 자료구조에서 pop을 하면 나중에 들어온 것이 먼저 나옵니다.","title":"[백준] DFS/BFS 1- 1260번 DFS와 BFS"},{"content":"Graph Search graph search 방법에는 DFS, BFS 2가지 종류가 있다.\nDFS(Depth-First-Search) 정의 root node 혹은 다른 임의의 node에서 시작해서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방식이다.\nbinary tree를 순회할 때 사용했던 다음의 순회 방법이 DFS에 속한다.\ninorder preorder postorder 구현 방법 stack을 이용해서 구현 처음에는 스택에 노드가 없으니깐 시작할 노드를 넣는다. stack에서 노드를 하나 꺼내서 해당 node의 child node를 전부 스택에 넣고 꺼낸 노드는 출력한다. child node를 stack에 넣을 때 한번 stack에 넣었던 node는 다시 넣지 않는다. recursion 이용한 순회 방법 (DFS의 경우 재귀 호출을 이용하면 코드가 간결해진다.) 노드에 방문하면 데이터를 출력하고 자식들을 순서대로 재귀호출한다. 자식들이 호출받으면 자기를 출력하고 자식들을 호출 만약 재귀호출을 다녀와서 출력하면 자식들이 먼저 출력하니깐 거꾸로 올라가게됨. 자식이 1개 이상인 경우 stack은 쌓고 나서 호출 → 자식 중에서 나중에 들어간 node가 먼저 출력된다. 재귀 호출은 정방향으로 출력하기 때문에 다르다. 연결 관계를 입력할 때 어떤 노드와의 입력관계를 먼저 입력했느냐로 결정된다. (예시 - L 먼저 입력 됐다고 가정) 활용 모든 노드를 방문 할 때, 완전 탐색을 할 때 사용한다. 시간 복잡도 BFS(Breadth-First-Search) 정의 Root node 혹은 다른 임의의 node에서 시작해서 인접한 node를 먼저 탐색하는 방법이다.\n구현 방법 queue를 이용해서 구현한다.\n처음에는 queue에 node가 없으니깐 시작할 node를 넣는다. queue에서 node를 하나 꺼내서 해당 node의 child node를 전부 스택에 넣고 꺼낸 노드는 출력한다. 활용 최단 경로를 찾을 때 사용한다. (가중치가 0,1인 경우에만 활용할 수 있다.)\n","permalink":"http://slow-wave.github.io/post/algorithm/algo_bfs_vs_dfs/","summary":"Graph Search graph search 방법에는 DFS, BFS 2가지 종류가 있다.\nDFS(Depth-First-Search) 정의 root node 혹은 다른 임의의 node에서 시작해서 다음 분기(branch)로 넘어가기 전에 해당 분기를 완벽하게 탐색하는 방식이다.\nbinary tree를 순회할 때 사용했던 다음의 순회 방법이 DFS에 속한다.\ninorder preorder postorder 구현 방법 stack을 이용해서 구현 처음에는 스택에 노드가 없으니깐 시작할 노드를 넣는다. stack에서 노드를 하나 꺼내서 해당 node의 child node를 전부 스택에 넣고 꺼낸 노드는 출력한다. child node를 stack에 넣을 때 한번 stack에 넣었던 node는 다시 넣지 않는다.","title":"[algorithm] DFS vs. BFS"}]