<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[deeplearing] CNN | slow-wave blog</title><meta name=keywords content="deeplearing"><meta name=description content="Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함."><meta name=author content="Me"><link rel=canonical href=http://slow-wave.github.io/post/deeplearning/deeplearning_1/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-6F557TM67S"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-6F557TM67S",{anonymize_ip:!1})}</script><meta property="og:title" content="[deeplearing] CNN"><meta property="og:description" content="Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함."><meta property="og:type" content="article"><meta property="og:url" content="http://slow-wave.github.io/post/deeplearning/deeplearning_1/"><meta property="og:image" content="http://slow-wave.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-10-11T16:04:21+09:00"><meta property="article:modified_time" content="2022-10-11T16:04:21+09:00"><meta property="og:site_name" content="slow-wave blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://slow-wave.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="[deeplearing] CNN"><meta name=twitter:description content="Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://slow-wave.github.io/post/"},{"@type":"ListItem","position":2,"name":"[deeplearing] CNN","item":"http://slow-wave.github.io/post/deeplearning/deeplearning_1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[deeplearing] CNN","name":"[deeplearing] CNN","description":"Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함.","keywords":["deeplearing"],"articleBody":"Fully Connected Layer fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨. 한 장의 컬러 사진은 3차원 데이터임. (R,G,B) 따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함. 평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계 이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임. CNN(Convolution neural networks)이란? 합성곱(convolution) 이라는 연산을 사용하는 신경망 이미지 분류 작업에서 좋은 성능을 보여줌. 시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함. 사람의 시력은 여러 피질 단계로 이뤄져 있고, 각 피질 단계는 점점 더 구조화된 정보를 인식함. 단일 픽셀을 본 후 거기서부터 단순한 기하 형태를 인식하고 물체, 얼굴, 인체, 동물 등과 같이 복잡한 요소를 인식 CNN에서는 완전 연결신경망과 달리 뉴런을 kernel(filter)이라고 함. kernel은 입력 데이터와 합성곱 연산을 수행하게되는 행렬임. convolution 계산을 통해 얻은 출력을 feature map이라고 함. Convolution Layer는 Filter의 크기, Stride, padding 적용 여부, Max Pooling 크기에 따라서 출력 데이터의 Shape이 변경됨. CNN의 구조 이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있음. Convolution Layer와 Pooling Layer를 여러 겹 쌓는 형태로 구성됨. Convolution Layer - 입력데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소임. Pooling Layer - 선택 요소임. Fully Connected Layer Flatten layer - 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데이터를 배열 형태로 만드는 레이어 Convolution 합성곱 연산은 두 함수 f,g 가운데 하나의 함수를 반전(reverse), 전이(shift) 시킨 다음, 다른 하나의 함수와 곱한 결과를 적분하는 것을 의미함. Channel 이미지 픽셀 하나하나는 실수임. 컬러 사진은 천연색을 표현하기 위해, 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터임. Convolution Layer에 유입되는 입력데이터에는 한 개 이상의 필터가 적용됨. 1개 필터는 Feature Map의 채널이 됨. convolution layer에 N개의 필터가 적용된다면 출력데이터는 N개의 채널을 갖게됨. Filter \u0026 Stride Filter 이미지의 특징을 찾아내기 위한 공용 파라미터임. 필터는 일반적으로 (4,4)나 (3,3)과 같은 정사각 행렬로 정의됨. CNN에서 학습의 대상은 필터 파라미터임. 하나의 Convolution Layer에 크기가 같은 여러 개의 필터를 적용할 수 있음. → 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature Map의 채널이 됨. 입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 모든 채널의 합성곱의 합을 Feature map(Activation Map)으로 만듦. 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature map의 채널이 됨. Stride 지정된 간격으로 필터를 순회하는 간격을 stride라고 함. padding Convolution layer에서 Filter와 Stride의 작용으로 Feature Map의 크기는 입력데이터보다 작음. 신경망에 Kernel을 적용하면 층이 깊어지면서 데이터의 차원이 줄어듦. → Convolution Layer의 출력 데이터가 줄어드는 것을 방지하는 방법이 padding임. padding은 입력 데이터 주변을 특정값으로 채우는 것을 의미함. 보통 0으로 채워 넣음. 외각을 0 값으로 둘러싸는 특징으로부터 인공 신경망이 이미지의 외각을 인식하는 학습 효과도 있음. padding의 종류 same padding 입력과 feature map의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것임. valid padding padding 없이 순수한 입력 배열에서만 합성곱을 하여 특성맵을 만드는 경우임. → feature map의 크기가 줄어듦. Pooling Layer 데이터의 차원을 줄이거나 특정 데이터를 강조하는 용도로 사용됨. 합성곱에서 stride를 크게 하여 특성맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문임. pooling layer를 통과하면 행렬의 크기 감소 pooling layer를 통해서 채널 수 변경 없음. 학습 대상 파라미터 없음. Pooling의 종류 Max pooling - CNN에서 주로 사용하는 방법 Mean pooling Average Pooling CNN의 구성 Filter, Stride, Padding을 조절하여 특징 추출(feature extraction) 부분의 입출력 크기를 계산하고 맞추는 방법이 중요함. 그림 8: 전형적인 CNN, 출처\n참고 자료 TAEWAN.KIM 블로그(CNN, Convolutional Neural Network 요약) ","wordCount":"528","inLanguage":"en","datePublished":"2022-10-11T16:04:21+09:00","dateModified":"2022-10-11T16:04:21+09:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://slow-wave.github.io/post/deeplearning/deeplearning_1/"},"publisher":{"@type":"Organization","name":"slow-wave blog","logo":{"@type":"ImageObject","url":"http://slow-wave.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://slow-wave.github.io/ accesskey=h title="Home (Alt + H)"><img src=http://slow-wave.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://slow-wave.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=http://slow-wave.github.io/tags/ title=tags><span>tags</span></a></li><li><a href=http://slow-wave.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://slow-wave.github.io/>Home</a>&nbsp;»&nbsp;<a href=http://slow-wave.github.io/post/>Posts</a></div><h1 class=post-title>[deeplearing] CNN</h1><div class=post-meta><span title='2022-10-11 16:04:21 +0900 KST'>October 11, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;528 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/post/deeplearning/deeplearning_1.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#fully-connected-layer>Fully Connected Layer</a></li><li><a href=#cnnconvolution-neural-networks이란>CNN(Convolution neural networks)이란?</a></li><li><a href=#cnn의-구조>CNN의 구조</a></li><li><a href=#convolution>Convolution</a></li><li><a href=#channel>Channel</a></li><li><a href=#filter--stride>Filter & Stride</a><ul><li><a href=#filter>Filter</a></li><li><a href=#stride>Stride</a></li></ul></li><li><a href=#padding>padding</a><ul><li><a href=#padding의-종류>padding의 종류</a></li></ul></li><li><a href=#pooling-layer>Pooling Layer</a><ul><li><a href=#pooling의-종류>Pooling의 종류</a></li></ul></li><li><a href=#cnn의-구성>CNN의 구성</a><ul><li><a href=#참고-자료>참고 자료</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=fully-connected-layer>Fully Connected Layer<a hidden class=anchor aria-hidden=true href=#fully-connected-layer>#</a></h2><ul><li>fully connected layer만으로 구성된 인공신경망의 입력데이터는 1차원(배열) 형태로 한정됨.</li><li>한 장의 컬러 사진은 3차원 데이터임. (R,G,B)</li><li>따라서 사진 데이터로 Fully Connected 신경망을 학습시켜야할 경우, 3차원을 1차원으로 평면화시켜야함.<ul><li>평면화를 시키면 공간 정보 손실 발생 → 신경망이 특징을 추출 및 학습할 때 정확도 높이는데 한계</li><li>이미지의 공간 정보를 유지한 상태로 학습이 가능한 모델이 CNN임.</li></ul></li></ul><h2 id=cnnconvolution-neural-networks이란>CNN(Convolution neural networks)이란?<a hidden class=anchor aria-hidden=true href=#cnnconvolution-neural-networks이란>#</a></h2><ul><li>합성곱(convolution) 이라는 연산을 사용하는 신경망</li><li>이미지 분류 작업에서 좋은 성능을 보여줌.</li><li>시각 피질에 대한 실험에서 얻은 데이터에서 영감을 얻은 특별한 구조를 사용함.<ul><li>사람의 시력은 여러 피질 단계로 이뤄져 있고, 각 피질 단계는 점점 더 구조화된 정보를 인식함.</li><li>단일 픽셀을 본 후 거기서부터 단순한 기하 형태를 인식하고 물체, 얼굴, 인체, 동물 등과 같이 복잡한 요소를 인식</li></ul></li><li>CNN에서는 완전 연결신경망과 달리 뉴런을 kernel(filter)이라고 함.<ul><li>kernel은 입력 데이터와 합성곱 연산을 수행하게되는 행렬임.</li></ul></li><li>convolution 계산을 통해 얻은 출력을 feature map이라고 함.</li><li>Convolution Layer는 Filter의 크기, Stride, padding 적용 여부, Max Pooling 크기에 따라서 출력 데이터의 Shape이 변경됨.</li></ul><h2 id=cnn의-구조>CNN의 구조<a hidden class=anchor aria-hidden=true href=#cnn의-구조>#</a></h2><ul><li>이미지의 특징을 추출하는 부분과 클래스를 분류하는 부분으로 나눌 수 있음.</li><li>Convolution Layer와 Pooling Layer를 여러 겹 쌓는 형태로 구성됨.<ul><li>Convolution Layer - 입력데이터에 필터를 적용 후 활성화 함수를 반영하는 필수 요소임.</li><li>Pooling Layer - 선택 요소임.</li></ul></li><li>Fully Connected Layer</li><li>Flatten layer - 이미지의 특징을 추출하는 부분과 이미지를 분류하는 부분 사이에 이미지 형태의 데이터를 배열 형태로 만드는 레이어</li></ul><h2 id=convolution>Convolution<a hidden class=anchor aria-hidden=true href=#convolution>#</a></h2><ul><li>합성곱 연산은 두 함수 f,g 가운데 하나의 함수를 반전(reverse), 전이(shift) 시킨 다음, 다른 하나의 함수와 곱한 결과를 적분하는 것을 의미함.</li></ul><h2 id=channel>Channel<a hidden class=anchor aria-hidden=true href=#channel>#</a></h2><ul><li>이미지 픽셀 하나하나는 실수임. 컬러 사진은 천연색을 표현하기 위해, 각 픽셀을 RGB 3개의 실수로 표현한 3차원 데이터임.</li><li>Convolution Layer에 유입되는 입력데이터에는 한 개 이상의 필터가 적용됨.</li><li>1개 필터는 Feature Map의 채널이 됨.<ul><li>convolution layer에 N개의 필터가 적용된다면 출력데이터는 N개의 채널을 갖게됨.</li></ul></li></ul><h2 id=filter--stride>Filter & Stride<a hidden class=anchor aria-hidden=true href=#filter--stride>#</a></h2><h3 id=filter>Filter<a hidden class=anchor aria-hidden=true href=#filter>#</a></h3><ul><li>이미지의 특징을 찾아내기 위한 공용 파라미터임.</li><li>필터는 일반적으로 (4,4)나 (3,3)과 같은 정사각 행렬로 정의됨.</li><li>CNN에서 학습의 대상은 필터 파라미터임.</li><li>하나의 Convolution Layer에 크기가 같은 여러 개의 필터를 적용할 수 있음. → 입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature Map의 채널이 됨.</li><li>입력 데이터를 지정된 간격으로 순회하며 채널별로 합성곱을 하고 모든 채널의 합성곱의 합을 Feature map(Activation Map)으로 만듦.</li><li>입력 데이터에 적용한 필터의 개수는 출력 데이터인 Feature map의 채널이 됨.</li></ul><h3 id=stride>Stride<a hidden class=anchor aria-hidden=true href=#stride>#</a></h3><ul><li>지정된 간격으로 필터를 순회하는 간격을 stride라고 함.</li></ul><h2 id=padding>padding<a hidden class=anchor aria-hidden=true href=#padding>#</a></h2><ul><li>Convolution layer에서 Filter와 Stride의 작용으로 Feature Map의 크기는 입력데이터보다 작음.</li><li>신경망에 Kernel을 적용하면 층이 깊어지면서 데이터의 차원이 줄어듦. → Convolution Layer의 출력 데이터가 줄어드는 것을 방지하는 방법이 padding임.</li><li>padding은 입력 데이터 주변을 특정값으로 채우는 것을 의미함.<ul><li>보통 0으로 채워 넣음.</li></ul></li><li>외각을 0 값으로 둘러싸는 특징으로부터 인공 신경망이 이미지의 외각을 인식하는 학습 효과도 있음.</li></ul><h3 id=padding의-종류>padding의 종류<a hidden class=anchor aria-hidden=true href=#padding의-종류>#</a></h3><ul><li>same padding<ul><li>입력과 feature map의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것임.</li></ul></li><li>valid padding<ul><li>padding 없이 순수한 입력 배열에서만 합성곱을 하여 특성맵을 만드는 경우임. → feature map의 크기가 줄어듦.</li></ul></li></ul><h2 id=pooling-layer>Pooling Layer<a hidden class=anchor aria-hidden=true href=#pooling-layer>#</a></h2><ul><li>데이터의 차원을 줄이거나 특정 데이터를 강조하는 용도로 사용됨.</li><li>합성곱에서 stride를 크게 하여 특성맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문임.</li><li>pooling layer를 통과하면 행렬의 크기 감소</li><li>pooling layer를 통해서 채널 수 변경 없음.</li><li>학습 대상 파라미터 없음.</li></ul><h3 id=pooling의-종류>Pooling의 종류<a hidden class=anchor aria-hidden=true href=#pooling의-종류>#</a></h3><ul><li>Max pooling - CNN에서 주로 사용하는 방법</li><li>Mean pooling</li><li>Average Pooling</li></ul><h2 id=cnn의-구성>CNN의 구성<a hidden class=anchor aria-hidden=true href=#cnn의-구성>#</a></h2><ul><li>Filter, Stride, Padding을 조절하여 특징 추출(feature extraction) 부분의 입출력 크기를 계산하고 맞추는 방법이 중요함.</li></ul><figure><img loading=lazy src=/images/deeplearning/deeplearning_1/1.png></figure><p><strong>그림 8</strong>: 전형적인 CNN, <a href=https://www.researchgate.net/figure/Architecture-of-our-unsupervised-CNN-Network-contains-three-stages-each-of-which_28343325>출처</a></p><h3 id=참고-자료>참고 자료<a hidden class=anchor aria-hidden=true href=#참고-자료>#</a></h3><ul><li><strong><a href=http://taewan.kim/post/cnn/>TAEWAN.KIM 블로그</a>(CNN, Convolutional Neural Network 요약)</strong></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://slow-wave.github.io/tags/deeplearing/>deeplearing</a></li></ul><nav class=paginav><a class=prev href=http://slow-wave.github.io/post/data_structure/ds_intro/><span class=title>« Prev</span><br><span>[data structure] 자료구조 정리</span></a>
<a class=next href=http://slow-wave.github.io/post/database/db_programming_0/><span class=title>Next »</span><br><span>[database] Re-introduction to DB</span></a></nav></footer><script src=https://utteranc.es/client.js repo=slow-wave/blog_comments issue-term=pathname theme=github-dark crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=http://slow-wave.github.io/>slow-wave blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>